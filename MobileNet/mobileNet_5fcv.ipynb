{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66254296-1038-4e33-87ea-18786169d54b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 406 images belonging to 3 classes.\n",
      "Testing batch_size=16, dropout=0.3, lr=0.0005\n",
      "\n",
      "Fold 1\n",
      "Epoch 1/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 401ms/step - accuracy: 0.4114 - loss: 1.1023 - val_accuracy: 0.6951 - val_loss: 0.6799\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 348ms/step - accuracy: 0.6934 - loss: 0.6302 - val_accuracy: 0.7805 - val_loss: 0.4992\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 336ms/step - accuracy: 0.8115 - loss: 0.4658 - val_accuracy: 0.8293 - val_loss: 0.4724\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 335ms/step - accuracy: 0.8587 - loss: 0.3246 - val_accuracy: 0.8049 - val_loss: 0.4561\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 338ms/step - accuracy: 0.9381 - loss: 0.2069 - val_accuracy: 0.8171 - val_loss: 0.4719\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 367ms/step - accuracy: 0.9322 - loss: 0.2245 - val_accuracy: 0.8415 - val_loss: 0.4363\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 368ms/step - accuracy: 0.9602 - loss: 0.1692 - val_accuracy: 0.8537 - val_loss: 0.4194\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 387ms/step - accuracy: 0.9812 - loss: 0.1142 - val_accuracy: 0.8293 - val_loss: 0.4167\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 359ms/step - accuracy: 0.9912 - loss: 0.1120 - val_accuracy: 0.7805 - val_loss: 0.5375\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 342ms/step - accuracy: 0.9975 - loss: 0.0917 - val_accuracy: 0.8171 - val_loss: 0.4911\n",
      "Fold 1 Accuracy: 81.71%\n",
      "Fold 1 Loss: 0.4911\n",
      "\n",
      "Fold 2\n",
      "Epoch 1/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 363ms/step - accuracy: 0.4683 - loss: 1.1050 - val_accuracy: 0.6296 - val_loss: 0.6735\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 333ms/step - accuracy: 0.7560 - loss: 0.5847 - val_accuracy: 0.7901 - val_loss: 0.4502\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 343ms/step - accuracy: 0.8508 - loss: 0.3999 - val_accuracy: 0.7531 - val_loss: 0.4845\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 336ms/step - accuracy: 0.8798 - loss: 0.3198 - val_accuracy: 0.8025 - val_loss: 0.4061\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 338ms/step - accuracy: 0.9360 - loss: 0.2396 - val_accuracy: 0.8272 - val_loss: 0.4284\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 343ms/step - accuracy: 0.9407 - loss: 0.2021 - val_accuracy: 0.8148 - val_loss: 0.3892\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 333ms/step - accuracy: 0.9684 - loss: 0.1716 - val_accuracy: 0.8272 - val_loss: 0.4291\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 338ms/step - accuracy: 0.9744 - loss: 0.1321 - val_accuracy: 0.8272 - val_loss: 0.4279\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 336ms/step - accuracy: 0.9908 - loss: 0.1041 - val_accuracy: 0.8272 - val_loss: 0.4345\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 330ms/step - accuracy: 0.9859 - loss: 0.0920 - val_accuracy: 0.8148 - val_loss: 0.4053\n",
      "Fold 2 Accuracy: 81.48%\n",
      "Fold 2 Loss: 0.4053\n",
      "\n",
      "Fold 3\n",
      "Epoch 1/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 358ms/step - accuracy: 0.3755 - loss: 1.2287 - val_accuracy: 0.6790 - val_loss: 0.6590\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 337ms/step - accuracy: 0.7727 - loss: 0.5230 - val_accuracy: 0.7407 - val_loss: 0.5567\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 335ms/step - accuracy: 0.8301 - loss: 0.4139 - val_accuracy: 0.7901 - val_loss: 0.5031\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 346ms/step - accuracy: 0.9101 - loss: 0.2535 - val_accuracy: 0.7901 - val_loss: 0.4744\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 333ms/step - accuracy: 0.9263 - loss: 0.2342 - val_accuracy: 0.7284 - val_loss: 0.5740\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 333ms/step - accuracy: 0.9704 - loss: 0.1768 - val_accuracy: 0.7407 - val_loss: 0.4893\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 329ms/step - accuracy: 0.9864 - loss: 0.1176 - val_accuracy: 0.7901 - val_loss: 0.4740\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 331ms/step - accuracy: 0.9718 - loss: 0.1195 - val_accuracy: 0.7778 - val_loss: 0.4687\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 333ms/step - accuracy: 0.9947 - loss: 0.0747 - val_accuracy: 0.7531 - val_loss: 0.5053\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 331ms/step - accuracy: 0.9978 - loss: 0.0817 - val_accuracy: 0.7531 - val_loss: 0.5326\n",
      "Fold 3 Accuracy: 75.31%\n",
      "Fold 3 Loss: 0.5326\n",
      "\n",
      "Fold 4\n",
      "Epoch 1/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 397ms/step - accuracy: 0.4976 - loss: 1.1295 - val_accuracy: 0.7654 - val_loss: 0.6627\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 381ms/step - accuracy: 0.7621 - loss: 0.5258 - val_accuracy: 0.7160 - val_loss: 0.8310\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 358ms/step - accuracy: 0.8128 - loss: 0.3854 - val_accuracy: 0.7901 - val_loss: 0.6697\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 359ms/step - accuracy: 0.9012 - loss: 0.2839 - val_accuracy: 0.7778 - val_loss: 0.6813\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 352ms/step - accuracy: 0.9094 - loss: 0.2698 - val_accuracy: 0.7654 - val_loss: 0.6765\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 360ms/step - accuracy: 0.9458 - loss: 0.2173 - val_accuracy: 0.7901 - val_loss: 0.6700\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 344ms/step - accuracy: 0.9496 - loss: 0.1586 - val_accuracy: 0.8025 - val_loss: 0.6695\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 338ms/step - accuracy: 0.9673 - loss: 0.1197 - val_accuracy: 0.8148 - val_loss: 0.6924\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 342ms/step - accuracy: 0.9759 - loss: 0.1264 - val_accuracy: 0.8148 - val_loss: 0.6659\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 340ms/step - accuracy: 0.9837 - loss: 0.1054 - val_accuracy: 0.8272 - val_loss: 0.7002\n",
      "Fold 4 Accuracy: 82.72%\n",
      "Fold 4 Loss: 0.7002\n",
      "\n",
      "Fold 5\n",
      "Epoch 1/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 368ms/step - accuracy: 0.4319 - loss: 1.1247 - val_accuracy: 0.7284 - val_loss: 0.6786\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 328ms/step - accuracy: 0.7865 - loss: 0.5279 - val_accuracy: 0.7037 - val_loss: 0.5688\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 336ms/step - accuracy: 0.8206 - loss: 0.4462 - val_accuracy: 0.7654 - val_loss: 0.4896\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 341ms/step - accuracy: 0.8500 - loss: 0.3826 - val_accuracy: 0.8025 - val_loss: 0.4604\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 329ms/step - accuracy: 0.9529 - loss: 0.2191 - val_accuracy: 0.8519 - val_loss: 0.4375\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 335ms/step - accuracy: 0.9145 - loss: 0.2178 - val_accuracy: 0.8148 - val_loss: 0.4651\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 332ms/step - accuracy: 0.9181 - loss: 0.1809 - val_accuracy: 0.7654 - val_loss: 0.5203\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 331ms/step - accuracy: 0.9728 - loss: 0.1292 - val_accuracy: 0.8642 - val_loss: 0.3988\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 332ms/step - accuracy: 0.9740 - loss: 0.1019 - val_accuracy: 0.8272 - val_loss: 0.4222\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 351ms/step - accuracy: 0.9832 - loss: 0.0891 - val_accuracy: 0.8025 - val_loss: 0.5100\n",
      "Fold 5 Accuracy: 80.25%\n",
      "Fold 5 Loss: 0.5100\n",
      "Mean Accuracy: 80.29%, Mean Loss: 0.5278\n",
      "\n",
      "Testing batch_size=16, dropout=0.3, lr=0.001\n",
      "\n",
      "Fold 1\n",
      "Epoch 1/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 362ms/step - accuracy: 0.4597 - loss: 1.3607 - val_accuracy: 0.7073 - val_loss: 0.7154\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 335ms/step - accuracy: 0.7748 - loss: 0.5297 - val_accuracy: 0.7317 - val_loss: 0.5188\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 331ms/step - accuracy: 0.8746 - loss: 0.3901 - val_accuracy: 0.8415 - val_loss: 0.4329\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 331ms/step - accuracy: 0.8953 - loss: 0.2833 - val_accuracy: 0.8537 - val_loss: 0.4444\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 329ms/step - accuracy: 0.9429 - loss: 0.1744 - val_accuracy: 0.8171 - val_loss: 0.4127\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 332ms/step - accuracy: 0.9694 - loss: 0.1337 - val_accuracy: 0.8537 - val_loss: 0.4089\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 330ms/step - accuracy: 0.9513 - loss: 0.1470 - val_accuracy: 0.8537 - val_loss: 0.4585\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 328ms/step - accuracy: 0.9693 - loss: 0.1141 - val_accuracy: 0.8537 - val_loss: 0.3956\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 336ms/step - accuracy: 0.9813 - loss: 0.1090 - val_accuracy: 0.8415 - val_loss: 0.4538\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 340ms/step - accuracy: 0.9996 - loss: 0.0586 - val_accuracy: 0.8537 - val_loss: 0.3909\n",
      "Fold 1 Accuracy: 85.37%\n",
      "Fold 1 Loss: 0.3909\n",
      "\n",
      "Fold 2\n",
      "Epoch 1/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 374ms/step - accuracy: 0.4806 - loss: 1.1888 - val_accuracy: 0.7901 - val_loss: 0.4958\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 333ms/step - accuracy: 0.7631 - loss: 0.5790 - val_accuracy: 0.7531 - val_loss: 0.6540\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 335ms/step - accuracy: 0.8197 - loss: 0.4757 - val_accuracy: 0.8025 - val_loss: 0.5296\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 358ms/step - accuracy: 0.8715 - loss: 0.4067 - val_accuracy: 0.8148 - val_loss: 0.4093\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 361ms/step - accuracy: 0.9320 - loss: 0.1951 - val_accuracy: 0.7778 - val_loss: 0.4397\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 335ms/step - accuracy: 0.9638 - loss: 0.1475 - val_accuracy: 0.8272 - val_loss: 0.3850\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 340ms/step - accuracy: 0.9807 - loss: 0.1192 - val_accuracy: 0.8148 - val_loss: 0.3663\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 338ms/step - accuracy: 0.9985 - loss: 0.0835 - val_accuracy: 0.7778 - val_loss: 0.4385\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 335ms/step - accuracy: 0.9889 - loss: 0.0728 - val_accuracy: 0.8148 - val_loss: 0.4136\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 334ms/step - accuracy: 0.9878 - loss: 0.0604 - val_accuracy: 0.8148 - val_loss: 0.4520\n",
      "Fold 2 Accuracy: 81.48%\n",
      "Fold 2 Loss: 0.4520\n",
      "\n",
      "Fold 3\n",
      "Epoch 1/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 362ms/step - accuracy: 0.4686 - loss: 1.2526 - val_accuracy: 0.6173 - val_loss: 0.8184\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 336ms/step - accuracy: 0.7783 - loss: 0.5145 - val_accuracy: 0.7284 - val_loss: 0.5406\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 340ms/step - accuracy: 0.8611 - loss: 0.3365 - val_accuracy: 0.7778 - val_loss: 0.6407\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 339ms/step - accuracy: 0.9143 - loss: 0.2514 - val_accuracy: 0.7778 - val_loss: 0.4916\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 335ms/step - accuracy: 0.9407 - loss: 0.1772 - val_accuracy: 0.7901 - val_loss: 0.5204\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 333ms/step - accuracy: 0.9647 - loss: 0.1312 - val_accuracy: 0.7901 - val_loss: 0.5281\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 333ms/step - accuracy: 0.9596 - loss: 0.1172 - val_accuracy: 0.7901 - val_loss: 0.4762\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 334ms/step - accuracy: 0.9718 - loss: 0.0973 - val_accuracy: 0.7531 - val_loss: 0.5476\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 352ms/step - accuracy: 0.9777 - loss: 0.0586 - val_accuracy: 0.8025 - val_loss: 0.5040\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 354ms/step - accuracy: 0.9901 - loss: 0.0587 - val_accuracy: 0.7901 - val_loss: 0.5855\n",
      "Fold 3 Accuracy: 79.01%\n",
      "Fold 3 Loss: 0.5855\n",
      "\n",
      "Fold 4\n",
      "Epoch 1/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 362ms/step - accuracy: 0.4456 - loss: 1.3174 - val_accuracy: 0.7160 - val_loss: 0.8041\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 337ms/step - accuracy: 0.7948 - loss: 0.5735 - val_accuracy: 0.7654 - val_loss: 0.6403\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 331ms/step - accuracy: 0.8721 - loss: 0.3121 - val_accuracy: 0.7778 - val_loss: 0.6505\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 331ms/step - accuracy: 0.9322 - loss: 0.2238 - val_accuracy: 0.8025 - val_loss: 0.6687\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 336ms/step - accuracy: 0.9386 - loss: 0.2013 - val_accuracy: 0.7778 - val_loss: 0.6667\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 334ms/step - accuracy: 0.9755 - loss: 0.1115 - val_accuracy: 0.8025 - val_loss: 0.7135\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 334ms/step - accuracy: 0.9655 - loss: 0.1159 - val_accuracy: 0.8025 - val_loss: 0.7526\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 334ms/step - accuracy: 0.9920 - loss: 0.0964 - val_accuracy: 0.8395 - val_loss: 0.7419\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 354ms/step - accuracy: 0.9953 - loss: 0.0535 - val_accuracy: 0.8272 - val_loss: 0.7852\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 334ms/step - accuracy: 0.9956 - loss: 0.0519 - val_accuracy: 0.8148 - val_loss: 0.7948\n",
      "Fold 4 Accuracy: 81.48%\n",
      "Fold 4 Loss: 0.7948\n",
      "\n",
      "Fold 5\n",
      "Epoch 1/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 361ms/step - accuracy: 0.4248 - loss: 1.4568 - val_accuracy: 0.5185 - val_loss: 1.0387\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 352ms/step - accuracy: 0.6737 - loss: 0.6659 - val_accuracy: 0.7901 - val_loss: 0.4999\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 354ms/step - accuracy: 0.8829 - loss: 0.3440 - val_accuracy: 0.7901 - val_loss: 0.4995\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 349ms/step - accuracy: 0.9092 - loss: 0.2725 - val_accuracy: 0.7778 - val_loss: 0.4753\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 333ms/step - accuracy: 0.9298 - loss: 0.2046 - val_accuracy: 0.7778 - val_loss: 0.5822\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 335ms/step - accuracy: 0.9367 - loss: 0.1730 - val_accuracy: 0.8148 - val_loss: 0.4849\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 334ms/step - accuracy: 0.9781 - loss: 0.1245 - val_accuracy: 0.7901 - val_loss: 0.4843\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 327ms/step - accuracy: 0.9878 - loss: 0.0766 - val_accuracy: 0.8025 - val_loss: 0.5005\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 334ms/step - accuracy: 0.9982 - loss: 0.0629 - val_accuracy: 0.7778 - val_loss: 0.5279\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 334ms/step - accuracy: 0.9591 - loss: 0.1089 - val_accuracy: 0.7901 - val_loss: 0.5222\n",
      "Fold 5 Accuracy: 79.01%\n",
      "Fold 5 Loss: 0.5222\n",
      "Mean Accuracy: 81.27%, Mean Loss: 0.5491\n",
      "\n",
      "Testing batch_size=16, dropout=0.5, lr=0.0005\n",
      "\n",
      "Fold 1\n",
      "Epoch 1/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 370ms/step - accuracy: 0.3777 - loss: 1.4025 - val_accuracy: 0.7195 - val_loss: 0.6705\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 338ms/step - accuracy: 0.6180 - loss: 0.7402 - val_accuracy: 0.7195 - val_loss: 0.5748\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 338ms/step - accuracy: 0.7671 - loss: 0.5079 - val_accuracy: 0.7195 - val_loss: 0.6269\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 334ms/step - accuracy: 0.8221 - loss: 0.4308 - val_accuracy: 0.7927 - val_loss: 0.4688\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 334ms/step - accuracy: 0.8514 - loss: 0.3556 - val_accuracy: 0.8049 - val_loss: 0.4560\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 339ms/step - accuracy: 0.8821 - loss: 0.2714 - val_accuracy: 0.7927 - val_loss: 0.4698\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 355ms/step - accuracy: 0.8966 - loss: 0.2810 - val_accuracy: 0.8415 - val_loss: 0.4405\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 359ms/step - accuracy: 0.9239 - loss: 0.2127 - val_accuracy: 0.7927 - val_loss: 0.4362\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 348ms/step - accuracy: 0.9369 - loss: 0.1902 - val_accuracy: 0.8537 - val_loss: 0.4201\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 338ms/step - accuracy: 0.9608 - loss: 0.1679 - val_accuracy: 0.8415 - val_loss: 0.4409\n",
      "Fold 1 Accuracy: 84.15%\n",
      "Fold 1 Loss: 0.4409\n",
      "\n",
      "Fold 2\n",
      "Epoch 1/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 368ms/step - accuracy: 0.4150 - loss: 1.2826 - val_accuracy: 0.7037 - val_loss: 0.6522\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 333ms/step - accuracy: 0.6989 - loss: 0.6520 - val_accuracy: 0.7901 - val_loss: 0.4897\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 336ms/step - accuracy: 0.7388 - loss: 0.5637 - val_accuracy: 0.7901 - val_loss: 0.5238\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 338ms/step - accuracy: 0.7979 - loss: 0.4267 - val_accuracy: 0.8395 - val_loss: 0.4288\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 329ms/step - accuracy: 0.8765 - loss: 0.3312 - val_accuracy: 0.8272 - val_loss: 0.4073\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 337ms/step - accuracy: 0.9165 - loss: 0.2782 - val_accuracy: 0.8272 - val_loss: 0.4219\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 337ms/step - accuracy: 0.9146 - loss: 0.2639 - val_accuracy: 0.8272 - val_loss: 0.3920\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 335ms/step - accuracy: 0.9348 - loss: 0.2123 - val_accuracy: 0.8395 - val_loss: 0.3916\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 336ms/step - accuracy: 0.9705 - loss: 0.1500 - val_accuracy: 0.8519 - val_loss: 0.4076\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 335ms/step - accuracy: 0.9452 - loss: 0.1822 - val_accuracy: 0.8148 - val_loss: 0.4185\n",
      "Fold 2 Accuracy: 81.48%\n",
      "Fold 2 Loss: 0.4185\n",
      "\n",
      "Fold 3\n",
      "Epoch 1/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 370ms/step - accuracy: 0.3781 - loss: 1.4396 - val_accuracy: 0.6914 - val_loss: 0.6798\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 334ms/step - accuracy: 0.6685 - loss: 0.7135 - val_accuracy: 0.6914 - val_loss: 0.5744\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 340ms/step - accuracy: 0.7928 - loss: 0.4823 - val_accuracy: 0.7407 - val_loss: 0.5918\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 335ms/step - accuracy: 0.8285 - loss: 0.4187 - val_accuracy: 0.7407 - val_loss: 0.5329\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 336ms/step - accuracy: 0.9030 - loss: 0.3207 - val_accuracy: 0.7284 - val_loss: 0.5348\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 337ms/step - accuracy: 0.8994 - loss: 0.2698 - val_accuracy: 0.8272 - val_loss: 0.5059\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 335ms/step - accuracy: 0.9622 - loss: 0.1836 - val_accuracy: 0.7901 - val_loss: 0.6377\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 332ms/step - accuracy: 0.9295 - loss: 0.2427 - val_accuracy: 0.7901 - val_loss: 0.5181\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 339ms/step - accuracy: 0.9521 - loss: 0.1821 - val_accuracy: 0.7531 - val_loss: 0.5113\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 343ms/step - accuracy: 0.9818 - loss: 0.1309 - val_accuracy: 0.7778 - val_loss: 0.4895\n",
      "Fold 3 Accuracy: 77.78%\n",
      "Fold 3 Loss: 0.4895\n",
      "\n",
      "Fold 4\n",
      "Epoch 1/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 368ms/step - accuracy: 0.4752 - loss: 1.1948 - val_accuracy: 0.6914 - val_loss: 0.6878\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 333ms/step - accuracy: 0.7738 - loss: 0.5677 - val_accuracy: 0.7284 - val_loss: 0.6231\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 337ms/step - accuracy: 0.7799 - loss: 0.4893 - val_accuracy: 0.7407 - val_loss: 0.6565\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 339ms/step - accuracy: 0.8705 - loss: 0.3765 - val_accuracy: 0.7778 - val_loss: 0.6671\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 341ms/step - accuracy: 0.8753 - loss: 0.3011 - val_accuracy: 0.7654 - val_loss: 0.6756\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 363ms/step - accuracy: 0.8673 - loss: 0.3025 - val_accuracy: 0.7901 - val_loss: 0.6852\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 359ms/step - accuracy: 0.9523 - loss: 0.1922 - val_accuracy: 0.7654 - val_loss: 0.7080\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 342ms/step - accuracy: 0.9426 - loss: 0.2040 - val_accuracy: 0.7901 - val_loss: 0.6441\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 337ms/step - accuracy: 0.9402 - loss: 0.1749 - val_accuracy: 0.8025 - val_loss: 0.6854\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 337ms/step - accuracy: 0.9664 - loss: 0.1388 - val_accuracy: 0.7531 - val_loss: 0.6733\n",
      "Fold 4 Accuracy: 75.31%\n",
      "Fold 4 Loss: 0.6733\n",
      "\n",
      "Fold 5\n",
      "Epoch 1/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 373ms/step - accuracy: 0.4192 - loss: 1.2378 - val_accuracy: 0.7160 - val_loss: 0.6942\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 343ms/step - accuracy: 0.7305 - loss: 0.6859 - val_accuracy: 0.7037 - val_loss: 0.5842\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 347ms/step - accuracy: 0.7951 - loss: 0.5291 - val_accuracy: 0.7654 - val_loss: 0.5431\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 344ms/step - accuracy: 0.8772 - loss: 0.3808 - val_accuracy: 0.7531 - val_loss: 0.5843\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 346ms/step - accuracy: 0.8690 - loss: 0.3422 - val_accuracy: 0.8148 - val_loss: 0.4899\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 339ms/step - accuracy: 0.8924 - loss: 0.2925 - val_accuracy: 0.7531 - val_loss: 0.5656\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 346ms/step - accuracy: 0.9160 - loss: 0.2294 - val_accuracy: 0.8148 - val_loss: 0.4644\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 343ms/step - accuracy: 0.9325 - loss: 0.2173 - val_accuracy: 0.7901 - val_loss: 0.4921\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 340ms/step - accuracy: 0.9355 - loss: 0.1997 - val_accuracy: 0.7901 - val_loss: 0.4496\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 355ms/step - accuracy: 0.9445 - loss: 0.1795 - val_accuracy: 0.8025 - val_loss: 0.4652\n",
      "Fold 5 Accuracy: 80.25%\n",
      "Fold 5 Loss: 0.4652\n",
      "Mean Accuracy: 79.79%, Mean Loss: 0.4975\n",
      "\n",
      "Testing batch_size=16, dropout=0.5, lr=0.001\n",
      "\n",
      "Fold 1\n",
      "Epoch 1/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 373ms/step - accuracy: 0.4217 - loss: 1.2637 - val_accuracy: 0.7195 - val_loss: 0.5860\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 341ms/step - accuracy: 0.7396 - loss: 0.5479 - val_accuracy: 0.6341 - val_loss: 0.7572\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 337ms/step - accuracy: 0.7961 - loss: 0.4903 - val_accuracy: 0.6951 - val_loss: 0.6605\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 337ms/step - accuracy: 0.8333 - loss: 0.3839 - val_accuracy: 0.7317 - val_loss: 0.6388\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 341ms/step - accuracy: 0.8240 - loss: 0.3751 - val_accuracy: 0.6951 - val_loss: 0.6519\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 335ms/step - accuracy: 0.8909 - loss: 0.2683 - val_accuracy: 0.7805 - val_loss: 0.4853\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 346ms/step - accuracy: 0.9418 - loss: 0.2118 - val_accuracy: 0.8415 - val_loss: 0.4186\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 339ms/step - accuracy: 0.9518 - loss: 0.1569 - val_accuracy: 0.8171 - val_loss: 0.4313\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 338ms/step - accuracy: 0.9357 - loss: 0.1765 - val_accuracy: 0.7805 - val_loss: 0.5261\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 341ms/step - accuracy: 0.9465 - loss: 0.1687 - val_accuracy: 0.8902 - val_loss: 0.3909\n",
      "Fold 1 Accuracy: 89.02%\n",
      "Fold 1 Loss: 0.3909\n",
      "\n",
      "Fold 2\n",
      "Epoch 1/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 368ms/step - accuracy: 0.3902 - loss: 1.4690 - val_accuracy: 0.7407 - val_loss: 0.6192\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 338ms/step - accuracy: 0.7641 - loss: 0.5688 - val_accuracy: 0.8025 - val_loss: 0.4903\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 341ms/step - accuracy: 0.8432 - loss: 0.3968 - val_accuracy: 0.8272 - val_loss: 0.4487\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 375ms/step - accuracy: 0.8703 - loss: 0.3514 - val_accuracy: 0.8025 - val_loss: 0.4881\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 359ms/step - accuracy: 0.9135 - loss: 0.2953 - val_accuracy: 0.8148 - val_loss: 0.5086\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 337ms/step - accuracy: 0.9446 - loss: 0.2211 - val_accuracy: 0.8519 - val_loss: 0.5089\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 343ms/step - accuracy: 0.9332 - loss: 0.2271 - val_accuracy: 0.8025 - val_loss: 0.4596\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 337ms/step - accuracy: 0.9505 - loss: 0.1797 - val_accuracy: 0.8272 - val_loss: 0.4443\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 337ms/step - accuracy: 0.9493 - loss: 0.1340 - val_accuracy: 0.8025 - val_loss: 0.4977\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 338ms/step - accuracy: 0.9583 - loss: 0.1284 - val_accuracy: 0.8642 - val_loss: 0.3999\n",
      "Fold 2 Accuracy: 86.42%\n",
      "Fold 2 Loss: 0.3999\n",
      "\n",
      "Fold 3\n",
      "Epoch 1/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 371ms/step - accuracy: 0.5094 - loss: 1.2494 - val_accuracy: 0.7037 - val_loss: 0.6629\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 340ms/step - accuracy: 0.7801 - loss: 0.6209 - val_accuracy: 0.8148 - val_loss: 0.4833\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 338ms/step - accuracy: 0.8269 - loss: 0.4394 - val_accuracy: 0.7531 - val_loss: 0.6686\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 336ms/step - accuracy: 0.8577 - loss: 0.3376 - val_accuracy: 0.7778 - val_loss: 0.4803\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 337ms/step - accuracy: 0.8740 - loss: 0.2860 - val_accuracy: 0.8272 - val_loss: 0.4816\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 339ms/step - accuracy: 0.9416 - loss: 0.1713 - val_accuracy: 0.8025 - val_loss: 0.4911\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 336ms/step - accuracy: 0.9427 - loss: 0.1592 - val_accuracy: 0.8272 - val_loss: 0.4789\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 340ms/step - accuracy: 0.9622 - loss: 0.1323 - val_accuracy: 0.8148 - val_loss: 0.5010\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 362ms/step - accuracy: 0.9606 - loss: 0.1077 - val_accuracy: 0.8148 - val_loss: 0.5043\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 360ms/step - accuracy: 0.9768 - loss: 0.0877 - val_accuracy: 0.8148 - val_loss: 0.5335\n",
      "Fold 3 Accuracy: 81.48%\n",
      "Fold 3 Loss: 0.5335\n",
      "\n",
      "Fold 4\n",
      "Epoch 1/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 369ms/step - accuracy: 0.4500 - loss: 1.3421 - val_accuracy: 0.7037 - val_loss: 0.8116\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 337ms/step - accuracy: 0.8044 - loss: 0.4903 - val_accuracy: 0.7531 - val_loss: 0.6812\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 335ms/step - accuracy: 0.8243 - loss: 0.4354 - val_accuracy: 0.7284 - val_loss: 0.6568\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 342ms/step - accuracy: 0.8416 - loss: 0.3628 - val_accuracy: 0.7901 - val_loss: 0.6689\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 336ms/step - accuracy: 0.9117 - loss: 0.2596 - val_accuracy: 0.8272 - val_loss: 0.7004\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 338ms/step - accuracy: 0.9320 - loss: 0.2088 - val_accuracy: 0.7901 - val_loss: 0.6507\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 339ms/step - accuracy: 0.9317 - loss: 0.2003 - val_accuracy: 0.8272 - val_loss: 0.6930\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 341ms/step - accuracy: 0.9461 - loss: 0.1648 - val_accuracy: 0.7778 - val_loss: 0.7699\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 333ms/step - accuracy: 0.9447 - loss: 0.1459 - val_accuracy: 0.8025 - val_loss: 0.7503\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 339ms/step - accuracy: 0.9651 - loss: 0.1061 - val_accuracy: 0.8148 - val_loss: 0.7390\n",
      "Fold 4 Accuracy: 81.48%\n",
      "Fold 4 Loss: 0.7390\n",
      "\n",
      "Fold 5\n",
      "Epoch 1/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 372ms/step - accuracy: 0.5139 - loss: 1.1098 - val_accuracy: 0.6790 - val_loss: 0.6915\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 371ms/step - accuracy: 0.7252 - loss: 0.6379 - val_accuracy: 0.6914 - val_loss: 0.6723\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 369ms/step - accuracy: 0.8091 - loss: 0.4804 - val_accuracy: 0.7160 - val_loss: 0.6402\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 343ms/step - accuracy: 0.9006 - loss: 0.3372 - val_accuracy: 0.7654 - val_loss: 0.4905\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 345ms/step - accuracy: 0.8567 - loss: 0.2652 - val_accuracy: 0.8025 - val_loss: 0.4798\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 344ms/step - accuracy: 0.9537 - loss: 0.1760 - val_accuracy: 0.8272 - val_loss: 0.4406\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 343ms/step - accuracy: 0.9474 - loss: 0.1470 - val_accuracy: 0.8025 - val_loss: 0.4119\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 343ms/step - accuracy: 0.9558 - loss: 0.1573 - val_accuracy: 0.8395 - val_loss: 0.4203\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 348ms/step - accuracy: 0.9661 - loss: 0.1496 - val_accuracy: 0.7531 - val_loss: 0.5497\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 354ms/step - accuracy: 0.9777 - loss: 0.1096 - val_accuracy: 0.7778 - val_loss: 0.4728\n",
      "Fold 5 Accuracy: 77.78%\n",
      "Fold 5 Loss: 0.4728\n",
      "Mean Accuracy: 83.24%, Mean Loss: 0.5073\n",
      "\n",
      "Testing batch_size=32, dropout=0.3, lr=0.0005\n",
      "\n",
      "Fold 1\n",
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 730ms/step - accuracy: 0.4165 - loss: 1.1623 - val_accuracy: 0.5854 - val_loss: 0.7661\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 671ms/step - accuracy: 0.7547 - loss: 0.6510 - val_accuracy: 0.7195 - val_loss: 0.6256\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 680ms/step - accuracy: 0.8271 - loss: 0.4637 - val_accuracy: 0.7317 - val_loss: 0.6285\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 664ms/step - accuracy: 0.8796 - loss: 0.3693 - val_accuracy: 0.8049 - val_loss: 0.4761\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 671ms/step - accuracy: 0.9058 - loss: 0.2918 - val_accuracy: 0.8049 - val_loss: 0.4666\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 689ms/step - accuracy: 0.9202 - loss: 0.2621 - val_accuracy: 0.8415 - val_loss: 0.4447\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 705ms/step - accuracy: 0.9346 - loss: 0.2249 - val_accuracy: 0.8537 - val_loss: 0.4584\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 685ms/step - accuracy: 0.9451 - loss: 0.1816 - val_accuracy: 0.8049 - val_loss: 0.4560\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 664ms/step - accuracy: 0.9423 - loss: 0.1888 - val_accuracy: 0.8171 - val_loss: 0.4210\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 671ms/step - accuracy: 0.9634 - loss: 0.1450 - val_accuracy: 0.8415 - val_loss: 0.4095\n",
      "Fold 1 Accuracy: 84.15%\n",
      "Fold 1 Loss: 0.4095\n",
      "\n",
      "Fold 2\n",
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 729ms/step - accuracy: 0.4548 - loss: 1.1351 - val_accuracy: 0.7037 - val_loss: 0.6486\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 653ms/step - accuracy: 0.7449 - loss: 0.5946 - val_accuracy: 0.7901 - val_loss: 0.5140\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 663ms/step - accuracy: 0.8032 - loss: 0.4787 - val_accuracy: 0.7778 - val_loss: 0.5371\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 668ms/step - accuracy: 0.8395 - loss: 0.4422 - val_accuracy: 0.8025 - val_loss: 0.4690\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 666ms/step - accuracy: 0.9141 - loss: 0.3030 - val_accuracy: 0.8395 - val_loss: 0.4110\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 665ms/step - accuracy: 0.8772 - loss: 0.3069 - val_accuracy: 0.8272 - val_loss: 0.3865\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 660ms/step - accuracy: 0.9411 - loss: 0.2215 - val_accuracy: 0.8395 - val_loss: 0.3881\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 661ms/step - accuracy: 0.9649 - loss: 0.1766 - val_accuracy: 0.8395 - val_loss: 0.4017\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 663ms/step - accuracy: 0.9338 - loss: 0.1714 - val_accuracy: 0.8025 - val_loss: 0.3945\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 664ms/step - accuracy: 0.9781 - loss: 0.1425 - val_accuracy: 0.8148 - val_loss: 0.4039\n",
      "Fold 2 Accuracy: 81.48%\n",
      "Fold 2 Loss: 0.4039\n",
      "\n",
      "Fold 3\n",
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 728ms/step - accuracy: 0.4320 - loss: 1.2568 - val_accuracy: 0.7037 - val_loss: 0.6800\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 658ms/step - accuracy: 0.6848 - loss: 0.6544 - val_accuracy: 0.7531 - val_loss: 0.6174\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 658ms/step - accuracy: 0.8175 - loss: 0.4511 - val_accuracy: 0.7037 - val_loss: 0.6382\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 665ms/step - accuracy: 0.8503 - loss: 0.4158 - val_accuracy: 0.7531 - val_loss: 0.6079\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 664ms/step - accuracy: 0.8650 - loss: 0.3265 - val_accuracy: 0.7531 - val_loss: 0.5405\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 665ms/step - accuracy: 0.9272 - loss: 0.2532 - val_accuracy: 0.8148 - val_loss: 0.5553\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 667ms/step - accuracy: 0.8991 - loss: 0.2481 - val_accuracy: 0.7901 - val_loss: 0.5160\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 668ms/step - accuracy: 0.9349 - loss: 0.2104 - val_accuracy: 0.7531 - val_loss: 0.5362\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 664ms/step - accuracy: 0.9354 - loss: 0.1902 - val_accuracy: 0.7901 - val_loss: 0.5290\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 663ms/step - accuracy: 0.9711 - loss: 0.1429 - val_accuracy: 0.8025 - val_loss: 0.4834\n",
      "Fold 3 Accuracy: 80.25%\n",
      "Fold 3 Loss: 0.4834\n",
      "\n",
      "Fold 4\n",
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 723ms/step - accuracy: 0.3572 - loss: 1.3405 - val_accuracy: 0.7531 - val_loss: 0.7341\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 676ms/step - accuracy: 0.7276 - loss: 0.6172 - val_accuracy: 0.7531 - val_loss: 0.7644\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 671ms/step - accuracy: 0.7979 - loss: 0.4965 - val_accuracy: 0.8025 - val_loss: 0.6155\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 692ms/step - accuracy: 0.8524 - loss: 0.3692 - val_accuracy: 0.7778 - val_loss: 0.6112\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 700ms/step - accuracy: 0.8497 - loss: 0.3372 - val_accuracy: 0.8148 - val_loss: 0.6152\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 679ms/step - accuracy: 0.9103 - loss: 0.2507 - val_accuracy: 0.7901 - val_loss: 0.6072\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 667ms/step - accuracy: 0.9597 - loss: 0.2111 - val_accuracy: 0.8025 - val_loss: 0.6489\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 665ms/step - accuracy: 0.9371 - loss: 0.1978 - val_accuracy: 0.8395 - val_loss: 0.6351\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 661ms/step - accuracy: 0.9711 - loss: 0.1461 - val_accuracy: 0.8148 - val_loss: 0.6461\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 669ms/step - accuracy: 0.9792 - loss: 0.1391 - val_accuracy: 0.8519 - val_loss: 0.6482\n",
      "Fold 4 Accuracy: 85.19%\n",
      "Fold 4 Loss: 0.6482\n",
      "\n",
      "Fold 5\n",
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 752ms/step - accuracy: 0.4594 - loss: 1.0348 - val_accuracy: 0.7284 - val_loss: 0.6569\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 681ms/step - accuracy: 0.7795 - loss: 0.6091 - val_accuracy: 0.7160 - val_loss: 0.6681\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 665ms/step - accuracy: 0.7946 - loss: 0.4619 - val_accuracy: 0.7901 - val_loss: 0.4928\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 676ms/step - accuracy: 0.8546 - loss: 0.3411 - val_accuracy: 0.7654 - val_loss: 0.5298\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 690ms/step - accuracy: 0.9106 - loss: 0.2772 - val_accuracy: 0.7407 - val_loss: 0.5885\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 665ms/step - accuracy: 0.8803 - loss: 0.2894 - val_accuracy: 0.7778 - val_loss: 0.4683\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 655ms/step - accuracy: 0.9368 - loss: 0.1993 - val_accuracy: 0.8025 - val_loss: 0.4191\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 670ms/step - accuracy: 0.9207 - loss: 0.1987 - val_accuracy: 0.8148 - val_loss: 0.4627\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 708ms/step - accuracy: 0.9533 - loss: 0.1513 - val_accuracy: 0.8272 - val_loss: 0.4113\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 712ms/step - accuracy: 0.9857 - loss: 0.1375 - val_accuracy: 0.8148 - val_loss: 0.4178\n",
      "Fold 5 Accuracy: 81.48%\n",
      "Fold 5 Loss: 0.4178\n",
      "Mean Accuracy: 82.51%, Mean Loss: 0.4726\n",
      "\n",
      "Testing batch_size=32, dropout=0.3, lr=0.001\n",
      "\n",
      "Fold 1\n",
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 725ms/step - accuracy: 0.4158 - loss: 1.3469 - val_accuracy: 0.7927 - val_loss: 0.5410\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 673ms/step - accuracy: 0.8387 - loss: 0.4867 - val_accuracy: 0.7195 - val_loss: 0.6450\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 675ms/step - accuracy: 0.8299 - loss: 0.4440 - val_accuracy: 0.6829 - val_loss: 0.8000\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 673ms/step - accuracy: 0.7235 - loss: 0.6786 - val_accuracy: 0.6707 - val_loss: 0.6495\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 661ms/step - accuracy: 0.8440 - loss: 0.3666 - val_accuracy: 0.7683 - val_loss: 0.5362\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 671ms/step - accuracy: 0.8854 - loss: 0.2897 - val_accuracy: 0.8537 - val_loss: 0.4149\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 666ms/step - accuracy: 0.9168 - loss: 0.2232 - val_accuracy: 0.8171 - val_loss: 0.4631\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 660ms/step - accuracy: 0.9619 - loss: 0.1460 - val_accuracy: 0.8537 - val_loss: 0.3727\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 674ms/step - accuracy: 0.9703 - loss: 0.1402 - val_accuracy: 0.8171 - val_loss: 0.4306\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 669ms/step - accuracy: 0.9767 - loss: 0.1024 - val_accuracy: 0.8415 - val_loss: 0.4152\n",
      "Fold 1 Accuracy: 84.15%\n",
      "Fold 1 Loss: 0.4152\n",
      "\n",
      "Fold 2\n",
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 739ms/step - accuracy: 0.4310 - loss: 1.3064 - val_accuracy: 0.6667 - val_loss: 0.7764\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 696ms/step - accuracy: 0.7688 - loss: 0.5607 - val_accuracy: 0.7654 - val_loss: 0.5507\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 684ms/step - accuracy: 0.8244 - loss: 0.4083 - val_accuracy: 0.8148 - val_loss: 0.4739\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 663ms/step - accuracy: 0.9079 - loss: 0.2569 - val_accuracy: 0.8025 - val_loss: 0.4102\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 656ms/step - accuracy: 0.9283 - loss: 0.2278 - val_accuracy: 0.8025 - val_loss: 0.4494\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 656ms/step - accuracy: 0.9252 - loss: 0.2114 - val_accuracy: 0.7654 - val_loss: 0.4964\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 664ms/step - accuracy: 0.9260 - loss: 0.2096 - val_accuracy: 0.8148 - val_loss: 0.4520\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 681ms/step - accuracy: 0.9767 - loss: 0.1353 - val_accuracy: 0.8148 - val_loss: 0.4456\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 662ms/step - accuracy: 0.9632 - loss: 0.1279 - val_accuracy: 0.7901 - val_loss: 0.5167\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 661ms/step - accuracy: 0.9783 - loss: 0.1119 - val_accuracy: 0.8272 - val_loss: 0.4702\n",
      "Fold 2 Accuracy: 82.72%\n",
      "Fold 2 Loss: 0.4702\n",
      "\n",
      "Fold 3\n",
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 719ms/step - accuracy: 0.4997 - loss: 1.0601 - val_accuracy: 0.6667 - val_loss: 0.6213\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 667ms/step - accuracy: 0.7853 - loss: 0.5201 - val_accuracy: 0.7284 - val_loss: 0.5260\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 668ms/step - accuracy: 0.8547 - loss: 0.3917 - val_accuracy: 0.7654 - val_loss: 0.4866\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 667ms/step - accuracy: 0.8770 - loss: 0.2950 - val_accuracy: 0.7407 - val_loss: 0.5244\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 671ms/step - accuracy: 0.9395 - loss: 0.2149 - val_accuracy: 0.8025 - val_loss: 0.4934\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 686ms/step - accuracy: 0.9565 - loss: 0.1434 - val_accuracy: 0.8395 - val_loss: 0.4667\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 703ms/step - accuracy: 0.9649 - loss: 0.1294 - val_accuracy: 0.8025 - val_loss: 0.4890\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 699ms/step - accuracy: 0.9757 - loss: 0.1147 - val_accuracy: 0.8272 - val_loss: 0.4500\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 668ms/step - accuracy: 0.9799 - loss: 0.0886 - val_accuracy: 0.8025 - val_loss: 0.4826\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 666ms/step - accuracy: 0.9966 - loss: 0.0675 - val_accuracy: 0.8025 - val_loss: 0.5147\n",
      "Fold 3 Accuracy: 80.25%\n",
      "Fold 3 Loss: 0.5147\n",
      "\n",
      "Fold 4\n",
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 738ms/step - accuracy: 0.4349 - loss: 1.2807 - val_accuracy: 0.7407 - val_loss: 0.7099\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 669ms/step - accuracy: 0.7737 - loss: 0.5550 - val_accuracy: 0.7037 - val_loss: 0.7478\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 663ms/step - accuracy: 0.8308 - loss: 0.3793 - val_accuracy: 0.7654 - val_loss: 0.6516\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 664ms/step - accuracy: 0.8979 - loss: 0.2690 - val_accuracy: 0.7778 - val_loss: 0.6926\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 663ms/step - accuracy: 0.8965 - loss: 0.2554 - val_accuracy: 0.7778 - val_loss: 0.7144\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 665ms/step - accuracy: 0.9619 - loss: 0.1456 - val_accuracy: 0.7901 - val_loss: 0.7302\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 662ms/step - accuracy: 0.9537 - loss: 0.1324 - val_accuracy: 0.7654 - val_loss: 0.8486\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 671ms/step - accuracy: 0.9817 - loss: 0.1169 - val_accuracy: 0.8148 - val_loss: 0.7475\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 673ms/step - accuracy: 0.9603 - loss: 0.1171 - val_accuracy: 0.8025 - val_loss: 0.7474\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 660ms/step - accuracy: 0.9909 - loss: 0.0696 - val_accuracy: 0.8025 - val_loss: 0.8563\n",
      "Fold 4 Accuracy: 80.25%\n",
      "Fold 4 Loss: 0.8563\n",
      "\n",
      "Fold 5\n",
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 720ms/step - accuracy: 0.5304 - loss: 1.1171 - val_accuracy: 0.6049 - val_loss: 0.8868\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 664ms/step - accuracy: 0.7565 - loss: 0.5352 - val_accuracy: 0.6790 - val_loss: 0.6416\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 673ms/step - accuracy: 0.7927 - loss: 0.4598 - val_accuracy: 0.7901 - val_loss: 0.4578\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 664ms/step - accuracy: 0.8973 - loss: 0.2908 - val_accuracy: 0.7778 - val_loss: 0.4573\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 669ms/step - accuracy: 0.8981 - loss: 0.2533 - val_accuracy: 0.8025 - val_loss: 0.5108\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 667ms/step - accuracy: 0.9324 - loss: 0.2085 - val_accuracy: 0.8025 - val_loss: 0.4320\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 660ms/step - accuracy: 0.9854 - loss: 0.1325 - val_accuracy: 0.8148 - val_loss: 0.4216\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 667ms/step - accuracy: 0.9766 - loss: 0.1390 - val_accuracy: 0.7901 - val_loss: 0.3992\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 663ms/step - accuracy: 0.9624 - loss: 0.1316 - val_accuracy: 0.7901 - val_loss: 0.4797\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 662ms/step - accuracy: 0.9683 - loss: 0.1163 - val_accuracy: 0.8272 - val_loss: 0.4295\n",
      "Fold 5 Accuracy: 82.72%\n",
      "Fold 5 Loss: 0.4295\n",
      "Mean Accuracy: 82.01%, Mean Loss: 0.5372\n",
      "\n",
      "Testing batch_size=32, dropout=0.5, lr=0.0005\n",
      "\n",
      "Fold 1\n",
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 744ms/step - accuracy: 0.3249 - loss: 1.3600 - val_accuracy: 0.6951 - val_loss: 0.6754\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 672ms/step - accuracy: 0.7025 - loss: 0.7278 - val_accuracy: 0.8171 - val_loss: 0.5703\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 679ms/step - accuracy: 0.8153 - loss: 0.5007 - val_accuracy: 0.7805 - val_loss: 0.5235\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 709ms/step - accuracy: 0.8281 - loss: 0.3959 - val_accuracy: 0.7683 - val_loss: 0.4682\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 690ms/step - accuracy: 0.8579 - loss: 0.3936 - val_accuracy: 0.7927 - val_loss: 0.4371\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 666ms/step - accuracy: 0.8488 - loss: 0.3781 - val_accuracy: 0.7927 - val_loss: 0.4782\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 667ms/step - accuracy: 0.8882 - loss: 0.2956 - val_accuracy: 0.8049 - val_loss: 0.4369\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 673ms/step - accuracy: 0.9136 - loss: 0.2457 - val_accuracy: 0.7927 - val_loss: 0.4480\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 672ms/step - accuracy: 0.8934 - loss: 0.2723 - val_accuracy: 0.8171 - val_loss: 0.4296\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 668ms/step - accuracy: 0.9123 - loss: 0.2341 - val_accuracy: 0.8049 - val_loss: 0.5074\n",
      "Fold 1 Accuracy: 80.49%\n",
      "Fold 1 Loss: 0.5074\n",
      "\n",
      "Fold 2\n",
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 727ms/step - accuracy: 0.4488 - loss: 1.1243 - val_accuracy: 0.7160 - val_loss: 0.6857\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 680ms/step - accuracy: 0.6836 - loss: 0.7136 - val_accuracy: 0.7654 - val_loss: 0.5556\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 664ms/step - accuracy: 0.8494 - loss: 0.4497 - val_accuracy: 0.8148 - val_loss: 0.4895\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 672ms/step - accuracy: 0.8407 - loss: 0.4168 - val_accuracy: 0.8395 - val_loss: 0.4249\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 667ms/step - accuracy: 0.8579 - loss: 0.3501 - val_accuracy: 0.8519 - val_loss: 0.4036\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 679ms/step - accuracy: 0.8687 - loss: 0.3544 - val_accuracy: 0.8025 - val_loss: 0.3976\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 676ms/step - accuracy: 0.9298 - loss: 0.2400 - val_accuracy: 0.8519 - val_loss: 0.4125\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 694ms/step - accuracy: 0.9163 - loss: 0.2440 - val_accuracy: 0.8148 - val_loss: 0.4289\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 703ms/step - accuracy: 0.9275 - loss: 0.2506 - val_accuracy: 0.8889 - val_loss: 0.4123\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 677ms/step - accuracy: 0.9551 - loss: 0.1851 - val_accuracy: 0.8272 - val_loss: 0.4253\n",
      "Fold 2 Accuracy: 82.72%\n",
      "Fold 2 Loss: 0.4253\n",
      "\n",
      "Fold 3\n",
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 733ms/step - accuracy: 0.3953 - loss: 1.4647 - val_accuracy: 0.6049 - val_loss: 0.8872\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 672ms/step - accuracy: 0.6125 - loss: 0.7943 - val_accuracy: 0.7778 - val_loss: 0.5742\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 659ms/step - accuracy: 0.8011 - loss: 0.5354 - val_accuracy: 0.7901 - val_loss: 0.5135\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 667ms/step - accuracy: 0.8122 - loss: 0.4211 - val_accuracy: 0.8272 - val_loss: 0.5135\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 666ms/step - accuracy: 0.8320 - loss: 0.4037 - val_accuracy: 0.7778 - val_loss: 0.4786\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 666ms/step - accuracy: 0.8500 - loss: 0.3635 - val_accuracy: 0.8395 - val_loss: 0.4822\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 666ms/step - accuracy: 0.9249 - loss: 0.2657 - val_accuracy: 0.7901 - val_loss: 0.4544\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 671ms/step - accuracy: 0.9440 - loss: 0.2418 - val_accuracy: 0.8272 - val_loss: 0.4704\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 665ms/step - accuracy: 0.9414 - loss: 0.2170 - val_accuracy: 0.8148 - val_loss: 0.4507\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 665ms/step - accuracy: 0.9263 - loss: 0.2253 - val_accuracy: 0.7901 - val_loss: 0.4753\n",
      "Fold 3 Accuracy: 79.01%\n",
      "Fold 3 Loss: 0.4753\n",
      "\n",
      "Fold 4\n",
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 760ms/step - accuracy: 0.4157 - loss: 1.3153 - val_accuracy: 0.6914 - val_loss: 0.7025\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 683ms/step - accuracy: 0.6520 - loss: 0.7525 - val_accuracy: 0.7284 - val_loss: 0.6647\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 669ms/step - accuracy: 0.7158 - loss: 0.6167 - val_accuracy: 0.7531 - val_loss: 0.6292\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 665ms/step - accuracy: 0.7892 - loss: 0.4607 - val_accuracy: 0.7901 - val_loss: 0.6509\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 666ms/step - accuracy: 0.8308 - loss: 0.4031 - val_accuracy: 0.7778 - val_loss: 0.6229\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 681ms/step - accuracy: 0.8904 - loss: 0.3419 - val_accuracy: 0.7407 - val_loss: 0.6800\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 664ms/step - accuracy: 0.8939 - loss: 0.3284 - val_accuracy: 0.8025 - val_loss: 0.6343\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 659ms/step - accuracy: 0.9151 - loss: 0.2623 - val_accuracy: 0.8025 - val_loss: 0.6773\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 676ms/step - accuracy: 0.9234 - loss: 0.2642 - val_accuracy: 0.7531 - val_loss: 0.6603\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 667ms/step - accuracy: 0.9303 - loss: 0.2471 - val_accuracy: 0.8025 - val_loss: 0.6564\n",
      "Fold 4 Accuracy: 80.25%\n",
      "Fold 4 Loss: 0.6564\n",
      "\n",
      "Fold 5\n",
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 760ms/step - accuracy: 0.4878 - loss: 1.1339 - val_accuracy: 0.7531 - val_loss: 0.6455\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 695ms/step - accuracy: 0.6790 - loss: 0.6907 - val_accuracy: 0.8148 - val_loss: 0.5342\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 668ms/step - accuracy: 0.7867 - loss: 0.5248 - val_accuracy: 0.8148 - val_loss: 0.5008\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 684ms/step - accuracy: 0.8267 - loss: 0.4024 - val_accuracy: 0.7901 - val_loss: 0.4828\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 679ms/step - accuracy: 0.8473 - loss: 0.3888 - val_accuracy: 0.7654 - val_loss: 0.4847\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 704ms/step - accuracy: 0.8408 - loss: 0.3988 - val_accuracy: 0.7901 - val_loss: 0.4868\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 715ms/step - accuracy: 0.9157 - loss: 0.2861 - val_accuracy: 0.8148 - val_loss: 0.4330\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 666ms/step - accuracy: 0.9342 - loss: 0.2271 - val_accuracy: 0.8025 - val_loss: 0.4444\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 684ms/step - accuracy: 0.8993 - loss: 0.2652 - val_accuracy: 0.8148 - val_loss: 0.4390\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 671ms/step - accuracy: 0.9360 - loss: 0.2007 - val_accuracy: 0.8148 - val_loss: 0.4201\n",
      "Fold 5 Accuracy: 81.48%\n",
      "Fold 5 Loss: 0.4201\n",
      "Mean Accuracy: 80.79%, Mean Loss: 0.4969\n",
      "\n",
      "Testing batch_size=32, dropout=0.5, lr=0.001\n",
      "\n",
      "Fold 1\n",
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 725ms/step - accuracy: 0.4525 - loss: 1.1367 - val_accuracy: 0.6829 - val_loss: 0.6043\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 671ms/step - accuracy: 0.7073 - loss: 0.7658 - val_accuracy: 0.7927 - val_loss: 0.5613\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 655ms/step - accuracy: 0.8197 - loss: 0.4435 - val_accuracy: 0.8171 - val_loss: 0.4862\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 666ms/step - accuracy: 0.8227 - loss: 0.3736 - val_accuracy: 0.7805 - val_loss: 0.4905\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 666ms/step - accuracy: 0.8702 - loss: 0.3560 - val_accuracy: 0.7561 - val_loss: 0.4950\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 661ms/step - accuracy: 0.8737 - loss: 0.2878 - val_accuracy: 0.7073 - val_loss: 0.6807\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 668ms/step - accuracy: 0.9112 - loss: 0.2241 - val_accuracy: 0.8293 - val_loss: 0.4598\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 662ms/step - accuracy: 0.9539 - loss: 0.1850 - val_accuracy: 0.8171 - val_loss: 0.4500\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 659ms/step - accuracy: 0.9394 - loss: 0.1594 - val_accuracy: 0.8537 - val_loss: 0.4860\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 690ms/step - accuracy: 0.9426 - loss: 0.1520 - val_accuracy: 0.8293 - val_loss: 0.4520\n",
      "Fold 1 Accuracy: 82.93%\n",
      "Fold 1 Loss: 0.4520\n",
      "\n",
      "Fold 2\n",
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 723ms/step - accuracy: 0.4021 - loss: 1.4036 - val_accuracy: 0.7160 - val_loss: 0.6316\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 680ms/step - accuracy: 0.7330 - loss: 0.6597 - val_accuracy: 0.7901 - val_loss: 0.4092\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 669ms/step - accuracy: 0.8005 - loss: 0.4883 - val_accuracy: 0.7901 - val_loss: 0.4642\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 657ms/step - accuracy: 0.8530 - loss: 0.3792 - val_accuracy: 0.7778 - val_loss: 0.4825\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 664ms/step - accuracy: 0.8928 - loss: 0.3039 - val_accuracy: 0.8272 - val_loss: 0.4194\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 663ms/step - accuracy: 0.9101 - loss: 0.2594 - val_accuracy: 0.8025 - val_loss: 0.5223\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 659ms/step - accuracy: 0.8859 - loss: 0.2706 - val_accuracy: 0.8272 - val_loss: 0.4295\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 667ms/step - accuracy: 0.9157 - loss: 0.2021 - val_accuracy: 0.7531 - val_loss: 0.4668\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 664ms/step - accuracy: 0.9100 - loss: 0.2499 - val_accuracy: 0.7901 - val_loss: 0.4710\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 657ms/step - accuracy: 0.9414 - loss: 0.1636 - val_accuracy: 0.8148 - val_loss: 0.4708\n",
      "Fold 2 Accuracy: 81.48%\n",
      "Fold 2 Loss: 0.4708\n",
      "\n",
      "Fold 3\n",
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 726ms/step - accuracy: 0.3685 - loss: 1.5169 - val_accuracy: 0.6049 - val_loss: 0.7903\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 669ms/step - accuracy: 0.6902 - loss: 0.7203 - val_accuracy: 0.6914 - val_loss: 0.6171\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 705ms/step - accuracy: 0.8280 - loss: 0.4472 - val_accuracy: 0.7407 - val_loss: 0.5683\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 699ms/step - accuracy: 0.8739 - loss: 0.3609 - val_accuracy: 0.7284 - val_loss: 0.5388\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 661ms/step - accuracy: 0.8742 - loss: 0.3318 - val_accuracy: 0.7901 - val_loss: 0.5623\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 668ms/step - accuracy: 0.8985 - loss: 0.2723 - val_accuracy: 0.7654 - val_loss: 0.5701\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 673ms/step - accuracy: 0.9275 - loss: 0.2134 - val_accuracy: 0.7160 - val_loss: 0.5111\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 660ms/step - accuracy: 0.9386 - loss: 0.1892 - val_accuracy: 0.7407 - val_loss: 0.5396\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 667ms/step - accuracy: 0.9335 - loss: 0.1879 - val_accuracy: 0.7778 - val_loss: 0.5568\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 669ms/step - accuracy: 0.9574 - loss: 0.1416 - val_accuracy: 0.7531 - val_loss: 0.5083\n",
      "Fold 3 Accuracy: 75.31%\n",
      "Fold 3 Loss: 0.5083\n",
      "\n",
      "Fold 4\n",
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 734ms/step - accuracy: 0.4086 - loss: 1.3461 - val_accuracy: 0.5802 - val_loss: 0.8309\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 658ms/step - accuracy: 0.7441 - loss: 0.6126 - val_accuracy: 0.7778 - val_loss: 0.6444\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 664ms/step - accuracy: 0.7906 - loss: 0.4676 - val_accuracy: 0.7654 - val_loss: 0.6981\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 670ms/step - accuracy: 0.8621 - loss: 0.3461 - val_accuracy: 0.7901 - val_loss: 0.7330\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 667ms/step - accuracy: 0.8568 - loss: 0.3319 - val_accuracy: 0.7901 - val_loss: 0.6628\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 665ms/step - accuracy: 0.9013 - loss: 0.2658 - val_accuracy: 0.7901 - val_loss: 0.6679\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 683ms/step - accuracy: 0.8857 - loss: 0.2487 - val_accuracy: 0.8148 - val_loss: 0.6278\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 701ms/step - accuracy: 0.9683 - loss: 0.1499 - val_accuracy: 0.7901 - val_loss: 0.7572\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 687ms/step - accuracy: 0.9396 - loss: 0.1845 - val_accuracy: 0.8025 - val_loss: 0.6684\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 663ms/step - accuracy: 0.9614 - loss: 0.1295 - val_accuracy: 0.8148 - val_loss: 0.6819\n",
      "Fold 4 Accuracy: 81.48%\n",
      "Fold 4 Loss: 0.6819\n",
      "\n",
      "Fold 5\n",
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 720ms/step - accuracy: 0.4344 - loss: 1.2910 - val_accuracy: 0.7901 - val_loss: 0.6169\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 672ms/step - accuracy: 0.7766 - loss: 0.5513 - val_accuracy: 0.7778 - val_loss: 0.4894\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 657ms/step - accuracy: 0.8298 - loss: 0.3727 - val_accuracy: 0.7901 - val_loss: 0.4931\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 674ms/step - accuracy: 0.8446 - loss: 0.3551 - val_accuracy: 0.7407 - val_loss: 0.6207\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 667ms/step - accuracy: 0.8898 - loss: 0.2969 - val_accuracy: 0.7531 - val_loss: 0.5654\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 664ms/step - accuracy: 0.9150 - loss: 0.2735 - val_accuracy: 0.7778 - val_loss: 0.4529\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 669ms/step - accuracy: 0.9108 - loss: 0.2485 - val_accuracy: 0.8148 - val_loss: 0.4319\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 667ms/step - accuracy: 0.9382 - loss: 0.1760 - val_accuracy: 0.7531 - val_loss: 0.5281\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 666ms/step - accuracy: 0.9431 - loss: 0.1734 - val_accuracy: 0.8148 - val_loss: 0.4622\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 662ms/step - accuracy: 0.9757 - loss: 0.1432 - val_accuracy: 0.8395 - val_loss: 0.3965\n",
      "Fold 5 Accuracy: 83.95%\n",
      "Fold 5 Loss: 0.3965\n",
      "Mean Accuracy: 81.03%, Mean Loss: 0.5019\n",
      "\n",
      "Best Parameters:\n",
      "{'batch_size': 16, 'dropout': 0.5, 'learning_rate': 0.001, 'accuracy': 0.8323697686195374}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import itertools\n",
    "\n",
    "# ---- Load and Preprocess Data ----\n",
    "train_dir = 'D:/Lung_cancer/train'  # Training directory path\n",
    "target_size = (224, 224)  # Input size for MobileNet\n",
    "num_classes = 3\n",
    "\n",
    "# Extract file paths and labels\n",
    "train_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=target_size,\n",
    "    batch_size=32,  # Temporary batch size\n",
    "    class_mode='categorical',\n",
    "    shuffle=False  # To keep track of indices\n",
    ")\n",
    "X = np.array(train_generator.filepaths)  # File paths of images\n",
    "y = np.array(train_generator.classes)    # Corresponding class labels\n",
    "\n",
    "# ---- Hyperparameter Search Space ----\n",
    "batch_sizes = [16, 32]\n",
    "dropout_rates = [0.3, 0.5]\n",
    "learning_rates = [0.0005, 0.001]\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "best_params = {}\n",
    "best_accuracy = 0\n",
    "\n",
    "# Iterate over all combinations of hyperparameters\n",
    "for batch_size, dropout_rate, learning_rate in itertools.product(batch_sizes, dropout_rates, learning_rates):\n",
    "    print(f\"Testing batch_size={batch_size}, dropout={dropout_rate}, lr={learning_rate}\")\n",
    "    \n",
    "    fold_accuracies = []\n",
    "    fold_losses = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
    "        print(f\"\\nFold {fold + 1}\")\n",
    "        \n",
    "        # Split into training and validation sets\n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "        \n",
    "        # Load data dynamically\n",
    "        def load_data(file_paths, labels):\n",
    "            images = []\n",
    "            for file in file_paths:\n",
    "                img = load_img(file, target_size=target_size)\n",
    "                img = img_to_array(img)\n",
    "                images.append(img)\n",
    "            images = np.array(images) / 255.0\n",
    "            labels = np.eye(num_classes)[labels]\n",
    "            return images, labels\n",
    "        \n",
    "        X_train_images, y_train_labels = load_data(X_train, y_train)\n",
    "        X_val_images, y_val_labels = load_data(X_val, y_val)\n",
    "        \n",
    "        # ---- Define and Compile Model ----\n",
    "        base_model = MobileNet(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "        base_model.trainable = False\n",
    "        \n",
    "        x = base_model.output\n",
    "        x = layers.GlobalAveragePooling2D()(x)\n",
    "        x = layers.Dense(512, activation='relu')(x)\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "        output = layers.Dense(num_classes, activation='softmax')(x)\n",
    "        model = models.Model(inputs=base_model.input, outputs=output)\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer=Adam(learning_rate=learning_rate),\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "        # ---- Train Model ----\n",
    "        history = model.fit(\n",
    "            X_train_images, y_train_labels,\n",
    "            validation_data=(X_val_images, y_val_labels),\n",
    "            epochs=10,\n",
    "            batch_size=batch_size,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # ---- Evaluate Model ----\n",
    "        val_loss, val_accuracy = model.evaluate(X_val_images, y_val_labels, verbose=0)\n",
    "        print(f\"Fold {fold + 1} Accuracy: {val_accuracy * 100:.2f}%\")\n",
    "        print(f\"Fold {fold + 1} Loss: {val_loss:.4f}\")\n",
    "        \n",
    "        fold_accuracies.append(val_accuracy)\n",
    "        fold_losses.append(val_loss)\n",
    "    \n",
    "    # Compute mean accuracy for the current hyperparameter combination\n",
    "    mean_accuracy = np.mean(fold_accuracies)\n",
    "    mean_loss = np.mean(fold_losses)\n",
    "    \n",
    "    print(f\"Mean Accuracy: {mean_accuracy * 100:.2f}%, Mean Loss: {mean_loss:.4f}\\n\")\n",
    "    \n",
    "    # Store best hyperparameters\n",
    "    if mean_accuracy > best_accuracy:\n",
    "        best_accuracy = mean_accuracy\n",
    "        best_params = {\n",
    "            \"batch_size\": batch_size,\n",
    "            \"dropout\": dropout_rate,\n",
    "            \"learning_rate\": learning_rate,\n",
    "            \"accuracy\": best_accuracy\n",
    "        }\n",
    "\n",
    "# ---- Final Best Parameters ----\n",
    "print(\"Best Parameters:\")\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea6d8f3-770f-4db9-a994-0f9fbadd80a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
