{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73299e39-ecfe-49ac-b128-92ddecf1c526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 406 images belonging to 3 classes.\n",
      "Testing batch_size=16, dropout=0.3, lr=0.0005\n",
      "\n",
      "Fold 1\n",
      "Epoch 1/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 481ms/step - accuracy: 0.4625 - loss: 1.2328 - val_accuracy: 0.6707 - val_loss: 0.6743\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 393ms/step - accuracy: 0.7602 - loss: 0.5988 - val_accuracy: 0.6220 - val_loss: 0.8890\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 393ms/step - accuracy: 0.8110 - loss: 0.5128 - val_accuracy: 0.7805 - val_loss: 0.5577\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 419ms/step - accuracy: 0.8907 - loss: 0.3090 - val_accuracy: 0.7195 - val_loss: 0.5551\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 422ms/step - accuracy: 0.9196 - loss: 0.2664 - val_accuracy: 0.7561 - val_loss: 0.5473\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 408ms/step - accuracy: 0.9456 - loss: 0.2117 - val_accuracy: 0.7439 - val_loss: 0.5477\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 394ms/step - accuracy: 0.9625 - loss: 0.1648 - val_accuracy: 0.7073 - val_loss: 0.5438\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 394ms/step - accuracy: 0.9668 - loss: 0.1338 - val_accuracy: 0.7683 - val_loss: 0.5206\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 392ms/step - accuracy: 0.9758 - loss: 0.1056 - val_accuracy: 0.7317 - val_loss: 0.4819\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 387ms/step - accuracy: 0.9830 - loss: 0.1123 - val_accuracy: 0.7317 - val_loss: 0.5830\n",
      "Fold 1 Accuracy: 73.17%\n",
      "Fold 1 Loss: 0.5830\n",
      "\n",
      "Fold 2\n",
      "Epoch 1/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 460ms/step - accuracy: 0.4504 - loss: 1.1467 - val_accuracy: 0.7160 - val_loss: 0.7044\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 400ms/step - accuracy: 0.7638 - loss: 0.5765 - val_accuracy: 0.7160 - val_loss: 0.6403\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 401ms/step - accuracy: 0.8234 - loss: 0.4292 - val_accuracy: 0.7901 - val_loss: 0.5527\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 406ms/step - accuracy: 0.8681 - loss: 0.3345 - val_accuracy: 0.7778 - val_loss: 0.5636\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 419ms/step - accuracy: 0.9380 - loss: 0.2479 - val_accuracy: 0.7778 - val_loss: 0.5383\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 435ms/step - accuracy: 0.9423 - loss: 0.1970 - val_accuracy: 0.8025 - val_loss: 0.5279\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 428ms/step - accuracy: 0.9612 - loss: 0.1737 - val_accuracy: 0.7778 - val_loss: 0.5398\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 417ms/step - accuracy: 0.9826 - loss: 0.1194 - val_accuracy: 0.8025 - val_loss: 0.4996\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 402ms/step - accuracy: 0.9743 - loss: 0.1207 - val_accuracy: 0.7778 - val_loss: 0.6675\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 391ms/step - accuracy: 0.9596 - loss: 0.1407 - val_accuracy: 0.7778 - val_loss: 0.5785\n",
      "Fold 2 Accuracy: 77.78%\n",
      "Fold 2 Loss: 0.5785\n",
      "\n",
      "Fold 3\n",
      "Epoch 1/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 469ms/step - accuracy: 0.4555 - loss: 1.1987 - val_accuracy: 0.6296 - val_loss: 0.7154\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 399ms/step - accuracy: 0.7291 - loss: 0.5755 - val_accuracy: 0.7407 - val_loss: 0.5970\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 399ms/step - accuracy: 0.8481 - loss: 0.4252 - val_accuracy: 0.7407 - val_loss: 0.5501\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 404ms/step - accuracy: 0.9085 - loss: 0.3063 - val_accuracy: 0.7778 - val_loss: 0.5141\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 400ms/step - accuracy: 0.8919 - loss: 0.3283 - val_accuracy: 0.7778 - val_loss: 0.5425\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 405ms/step - accuracy: 0.8974 - loss: 0.2531 - val_accuracy: 0.7901 - val_loss: 0.4882\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 400ms/step - accuracy: 0.9685 - loss: 0.1735 - val_accuracy: 0.7160 - val_loss: 0.5887\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 431ms/step - accuracy: 0.9747 - loss: 0.1394 - val_accuracy: 0.7531 - val_loss: 0.5053\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 423ms/step - accuracy: 0.9853 - loss: 0.1253 - val_accuracy: 0.7531 - val_loss: 0.5192\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 419ms/step - accuracy: 0.9836 - loss: 0.0978 - val_accuracy: 0.7778 - val_loss: 0.4938\n",
      "Fold 3 Accuracy: 77.78%\n",
      "Fold 3 Loss: 0.4938\n",
      "\n",
      "Fold 4\n",
      "Epoch 1/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 456ms/step - accuracy: 0.4191 - loss: 1.2275 - val_accuracy: 0.6543 - val_loss: 0.8135\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 417ms/step - accuracy: 0.7617 - loss: 0.5620 - val_accuracy: 0.7407 - val_loss: 0.6856\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 409ms/step - accuracy: 0.8265 - loss: 0.4216 - val_accuracy: 0.7284 - val_loss: 0.6815\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 397ms/step - accuracy: 0.8461 - loss: 0.3417 - val_accuracy: 0.7901 - val_loss: 0.6161\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 403ms/step - accuracy: 0.9239 - loss: 0.2494 - val_accuracy: 0.7901 - val_loss: 0.6205\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 401ms/step - accuracy: 0.9298 - loss: 0.1997 - val_accuracy: 0.7901 - val_loss: 0.5909\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 400ms/step - accuracy: 0.9642 - loss: 0.1499 - val_accuracy: 0.7654 - val_loss: 0.6142\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 399ms/step - accuracy: 0.9654 - loss: 0.1449 - val_accuracy: 0.7901 - val_loss: 0.6014\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 400ms/step - accuracy: 0.9669 - loss: 0.1332 - val_accuracy: 0.7901 - val_loss: 0.5747\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 417ms/step - accuracy: 0.9989 - loss: 0.0841 - val_accuracy: 0.8148 - val_loss: 0.5788\n",
      "Fold 4 Accuracy: 81.48%\n",
      "Fold 4 Loss: 0.5788\n",
      "\n",
      "Fold 5\n",
      "Epoch 1/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 458ms/step - accuracy: 0.4811 - loss: 1.2676 - val_accuracy: 0.6914 - val_loss: 0.7264\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 409ms/step - accuracy: 0.7600 - loss: 0.5781 - val_accuracy: 0.7037 - val_loss: 0.6651\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 405ms/step - accuracy: 0.7629 - loss: 0.5237 - val_accuracy: 0.7901 - val_loss: 0.5667\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 407ms/step - accuracy: 0.8786 - loss: 0.3556 - val_accuracy: 0.7284 - val_loss: 0.6671\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 411ms/step - accuracy: 0.9312 - loss: 0.1980 - val_accuracy: 0.7160 - val_loss: 0.6390\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 401ms/step - accuracy: 0.9144 - loss: 0.2278 - val_accuracy: 0.8148 - val_loss: 0.5968\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 404ms/step - accuracy: 0.9614 - loss: 0.1633 - val_accuracy: 0.8025 - val_loss: 0.5299\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 435ms/step - accuracy: 0.9749 - loss: 0.1370 - val_accuracy: 0.7531 - val_loss: 0.6715\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 403ms/step - accuracy: 0.9808 - loss: 0.1105 - val_accuracy: 0.7901 - val_loss: 0.6013\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 398ms/step - accuracy: 0.9899 - loss: 0.0892 - val_accuracy: 0.8025 - val_loss: 0.5488\n",
      "Fold 5 Accuracy: 80.25%\n",
      "Fold 5 Loss: 0.5488\n",
      "Mean Accuracy: 78.09%, Mean Loss: 0.5566\n",
      "\n",
      "Testing batch_size=16, dropout=0.3, lr=0.001\n",
      "\n",
      "Fold 1\n",
      "Epoch 1/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 492ms/step - accuracy: 0.4423 - loss: 1.2107 - val_accuracy: 0.7195 - val_loss: 0.6660\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 408ms/step - accuracy: 0.7352 - loss: 0.6593 - val_accuracy: 0.6707 - val_loss: 0.7475\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 399ms/step - accuracy: 0.8027 - loss: 0.4616 - val_accuracy: 0.7073 - val_loss: 0.6194\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 402ms/step - accuracy: 0.8542 - loss: 0.3395 - val_accuracy: 0.7805 - val_loss: 0.5729\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 395ms/step - accuracy: 0.9177 - loss: 0.2389 - val_accuracy: 0.7439 - val_loss: 0.5138\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 400ms/step - accuracy: 0.8786 - loss: 0.2456 - val_accuracy: 0.7439 - val_loss: 0.5650\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 399ms/step - accuracy: 0.9345 - loss: 0.1830 - val_accuracy: 0.7561 - val_loss: 0.4619\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 400ms/step - accuracy: 0.9668 - loss: 0.1187 - val_accuracy: 0.7561 - val_loss: 0.4681\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 400ms/step - accuracy: 0.9849 - loss: 0.0856 - val_accuracy: 0.7317 - val_loss: 0.6171\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 408ms/step - accuracy: 0.9423 - loss: 0.1303 - val_accuracy: 0.7805 - val_loss: 0.4970\n",
      "Fold 1 Accuracy: 78.05%\n",
      "Fold 1 Loss: 0.4970\n",
      "\n",
      "Fold 2\n",
      "Epoch 1/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 473ms/step - accuracy: 0.4360 - loss: 1.3517 - val_accuracy: 0.7160 - val_loss: 0.6386\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 408ms/step - accuracy: 0.7675 - loss: 0.5010 - val_accuracy: 0.6543 - val_loss: 0.7426\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 424ms/step - accuracy: 0.8256 - loss: 0.4404 - val_accuracy: 0.7037 - val_loss: 0.6846\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 438ms/step - accuracy: 0.8783 - loss: 0.3141 - val_accuracy: 0.7284 - val_loss: 0.6227\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 417ms/step - accuracy: 0.9056 - loss: 0.2633 - val_accuracy: 0.6790 - val_loss: 0.7596\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 406ms/step - accuracy: 0.8917 - loss: 0.2610 - val_accuracy: 0.7778 - val_loss: 0.4993\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 411ms/step - accuracy: 0.9763 - loss: 0.1228 - val_accuracy: 0.8025 - val_loss: 0.4733\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 403ms/step - accuracy: 0.9821 - loss: 0.1027 - val_accuracy: 0.7901 - val_loss: 0.5013\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 420ms/step - accuracy: 0.9931 - loss: 0.0750 - val_accuracy: 0.8148 - val_loss: 0.5190\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 410ms/step - accuracy: 0.9901 - loss: 0.0665 - val_accuracy: 0.7778 - val_loss: 0.5141\n",
      "Fold 2 Accuracy: 77.78%\n",
      "Fold 2 Loss: 0.5141\n",
      "\n",
      "Fold 3\n",
      "Epoch 1/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 458ms/step - accuracy: 0.4488 - loss: 1.2994 - val_accuracy: 0.7407 - val_loss: 0.6547\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 407ms/step - accuracy: 0.7195 - loss: 0.6529 - val_accuracy: 0.6667 - val_loss: 0.7729\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 399ms/step - accuracy: 0.8147 - loss: 0.4683 - val_accuracy: 0.7901 - val_loss: 0.5584\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 407ms/step - accuracy: 0.8401 - loss: 0.3799 - val_accuracy: 0.7531 - val_loss: 0.4822\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 416ms/step - accuracy: 0.9459 - loss: 0.2074 - val_accuracy: 0.7531 - val_loss: 0.4766\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 429ms/step - accuracy: 0.9556 - loss: 0.1494 - val_accuracy: 0.7531 - val_loss: 0.5032\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 441ms/step - accuracy: 0.9655 - loss: 0.1421 - val_accuracy: 0.7901 - val_loss: 0.5507\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 400ms/step - accuracy: 0.9620 - loss: 0.1218 - val_accuracy: 0.7901 - val_loss: 0.4510\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 404ms/step - accuracy: 0.9910 - loss: 0.0810 - val_accuracy: 0.8025 - val_loss: 0.4988\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 402ms/step - accuracy: 1.0000 - loss: 0.0588 - val_accuracy: 0.7901 - val_loss: 0.4685\n",
      "Fold 3 Accuracy: 79.01%\n",
      "Fold 3 Loss: 0.4685\n",
      "\n",
      "Fold 4\n",
      "Epoch 1/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 457ms/step - accuracy: 0.4330 - loss: 1.3628 - val_accuracy: 0.7901 - val_loss: 0.7228\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 414ms/step - accuracy: 0.7571 - loss: 0.5745 - val_accuracy: 0.7901 - val_loss: 0.6512\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 405ms/step - accuracy: 0.8669 - loss: 0.3944 - val_accuracy: 0.7654 - val_loss: 0.5790\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 405ms/step - accuracy: 0.8728 - loss: 0.3225 - val_accuracy: 0.7531 - val_loss: 0.7197\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 402ms/step - accuracy: 0.8699 - loss: 0.3274 - val_accuracy: 0.7531 - val_loss: 0.6194\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 403ms/step - accuracy: 0.9367 - loss: 0.2213 - val_accuracy: 0.8025 - val_loss: 0.5877\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 411ms/step - accuracy: 0.9626 - loss: 0.1386 - val_accuracy: 0.8272 - val_loss: 0.5485\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 433ms/step - accuracy: 0.9764 - loss: 0.0971 - val_accuracy: 0.7901 - val_loss: 0.7020\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 429ms/step - accuracy: 0.9807 - loss: 0.0833 - val_accuracy: 0.8272 - val_loss: 0.5889\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 403ms/step - accuracy: 0.9901 - loss: 0.0726 - val_accuracy: 0.8148 - val_loss: 0.6171\n",
      "Fold 4 Accuracy: 81.48%\n",
      "Fold 4 Loss: 0.6171\n",
      "\n",
      "Fold 5\n",
      "Epoch 1/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 471ms/step - accuracy: 0.4790 - loss: 1.4072 - val_accuracy: 0.6420 - val_loss: 0.7793\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 418ms/step - accuracy: 0.7685 - loss: 0.5805 - val_accuracy: 0.6667 - val_loss: 0.7479\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 409ms/step - accuracy: 0.8569 - loss: 0.3492 - val_accuracy: 0.7531 - val_loss: 0.6075\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 414ms/step - accuracy: 0.8979 - loss: 0.3197 - val_accuracy: 0.7531 - val_loss: 0.6579\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 411ms/step - accuracy: 0.9279 - loss: 0.2008 - val_accuracy: 0.7654 - val_loss: 0.5926\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 413ms/step - accuracy: 0.9144 - loss: 0.2038 - val_accuracy: 0.7160 - val_loss: 0.7441\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 411ms/step - accuracy: 0.9369 - loss: 0.1818 - val_accuracy: 0.7407 - val_loss: 0.6755\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 409ms/step - accuracy: 0.9919 - loss: 0.0711 - val_accuracy: 0.7531 - val_loss: 0.6101\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 415ms/step - accuracy: 0.9941 - loss: 0.0654 - val_accuracy: 0.7407 - val_loss: 0.6506\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 444ms/step - accuracy: 0.9945 - loss: 0.0624 - val_accuracy: 0.7654 - val_loss: 0.6434\n",
      "Fold 5 Accuracy: 76.54%\n",
      "Fold 5 Loss: 0.6434\n",
      "Mean Accuracy: 78.57%, Mean Loss: 0.5480\n",
      "\n",
      "Testing batch_size=16, dropout=0.5, lr=0.0005\n",
      "\n",
      "Fold 1\n",
      "Epoch 1/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 457ms/step - accuracy: 0.3990 - loss: 1.4311 - val_accuracy: 0.6707 - val_loss: 0.8097\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 404ms/step - accuracy: 0.6987 - loss: 0.7086 - val_accuracy: 0.6098 - val_loss: 0.9315\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 415ms/step - accuracy: 0.7500 - loss: 0.5409 - val_accuracy: 0.6341 - val_loss: 0.8411\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 410ms/step - accuracy: 0.8030 - loss: 0.4786 - val_accuracy: 0.7073 - val_loss: 0.6490\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 403ms/step - accuracy: 0.8703 - loss: 0.3187 - val_accuracy: 0.7561 - val_loss: 0.5389\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 415ms/step - accuracy: 0.8664 - loss: 0.3192 - val_accuracy: 0.7195 - val_loss: 0.5900\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 408ms/step - accuracy: 0.8595 - loss: 0.3435 - val_accuracy: 0.7073 - val_loss: 0.5715\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 405ms/step - accuracy: 0.9280 - loss: 0.2210 - val_accuracy: 0.7195 - val_loss: 0.5935\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 406ms/step - accuracy: 0.9236 - loss: 0.2168 - val_accuracy: 0.7317 - val_loss: 0.5454\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 404ms/step - accuracy: 0.9323 - loss: 0.1866 - val_accuracy: 0.7073 - val_loss: 0.5811\n",
      "Fold 1 Accuracy: 70.73%\n",
      "Fold 1 Loss: 0.5811\n",
      "\n",
      "Fold 2\n",
      "Epoch 1/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 459ms/step - accuracy: 0.4545 - loss: 1.2339 - val_accuracy: 0.5185 - val_loss: 0.8641\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 448ms/step - accuracy: 0.6487 - loss: 0.7808 - val_accuracy: 0.6914 - val_loss: 0.6891\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 450ms/step - accuracy: 0.7608 - loss: 0.5312 - val_accuracy: 0.7654 - val_loss: 0.6042\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 402ms/step - accuracy: 0.8477 - loss: 0.3833 - val_accuracy: 0.8025 - val_loss: 0.5967\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 412ms/step - accuracy: 0.8508 - loss: 0.3758 - val_accuracy: 0.7901 - val_loss: 0.5892\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 406ms/step - accuracy: 0.8477 - loss: 0.3859 - val_accuracy: 0.8148 - val_loss: 0.5758\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 401ms/step - accuracy: 0.9137 - loss: 0.2751 - val_accuracy: 0.8025 - val_loss: 0.5279\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 412ms/step - accuracy: 0.9231 - loss: 0.2594 - val_accuracy: 0.7901 - val_loss: 0.5024\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 417ms/step - accuracy: 0.9262 - loss: 0.2005 - val_accuracy: 0.8025 - val_loss: 0.4773\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 403ms/step - accuracy: 0.9469 - loss: 0.1492 - val_accuracy: 0.7901 - val_loss: 0.5398\n",
      "Fold 2 Accuracy: 79.01%\n",
      "Fold 2 Loss: 0.5398\n",
      "\n",
      "Fold 3\n",
      "Epoch 1/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 471ms/step - accuracy: 0.4175 - loss: 1.3729 - val_accuracy: 0.6296 - val_loss: 0.7115\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 447ms/step - accuracy: 0.6967 - loss: 0.7749 - val_accuracy: 0.6914 - val_loss: 0.6603\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 469ms/step - accuracy: 0.7481 - loss: 0.6212 - val_accuracy: 0.7160 - val_loss: 0.5806\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 417ms/step - accuracy: 0.8032 - loss: 0.5018 - val_accuracy: 0.7407 - val_loss: 0.6317\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 420ms/step - accuracy: 0.8025 - loss: 0.4786 - val_accuracy: 0.7531 - val_loss: 0.5844\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 421ms/step - accuracy: 0.8552 - loss: 0.3934 - val_accuracy: 0.7654 - val_loss: 0.4931\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 418ms/step - accuracy: 0.8908 - loss: 0.3262 - val_accuracy: 0.7531 - val_loss: 0.5742\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 426ms/step - accuracy: 0.9122 - loss: 0.2365 - val_accuracy: 0.7531 - val_loss: 0.5356\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 417ms/step - accuracy: 0.9363 - loss: 0.2233 - val_accuracy: 0.7654 - val_loss: 0.4641\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 420ms/step - accuracy: 0.9357 - loss: 0.1967 - val_accuracy: 0.7901 - val_loss: 0.4544\n",
      "Fold 3 Accuracy: 79.01%\n",
      "Fold 3 Loss: 0.4544\n",
      "\n",
      "Fold 4\n",
      "Epoch 1/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 469ms/step - accuracy: 0.3938 - loss: 1.4503 - val_accuracy: 0.6049 - val_loss: 0.9860\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 413ms/step - accuracy: 0.7082 - loss: 0.7828 - val_accuracy: 0.7531 - val_loss: 0.7524\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 408ms/step - accuracy: 0.7524 - loss: 0.6066 - val_accuracy: 0.8272 - val_loss: 0.6113\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 442ms/step - accuracy: 0.7868 - loss: 0.4988 - val_accuracy: 0.7654 - val_loss: 0.6323\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 435ms/step - accuracy: 0.8482 - loss: 0.3967 - val_accuracy: 0.7901 - val_loss: 0.6065\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 413ms/step - accuracy: 0.8633 - loss: 0.3313 - val_accuracy: 0.7654 - val_loss: 0.6201\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 409ms/step - accuracy: 0.8582 - loss: 0.3254 - val_accuracy: 0.7778 - val_loss: 0.5894\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 411ms/step - accuracy: 0.8911 - loss: 0.2875 - val_accuracy: 0.7901 - val_loss: 0.5671\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 406ms/step - accuracy: 0.9280 - loss: 0.2041 - val_accuracy: 0.7778 - val_loss: 0.5808\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 406ms/step - accuracy: 0.9378 - loss: 0.1837 - val_accuracy: 0.7654 - val_loss: 0.6224\n",
      "Fold 4 Accuracy: 76.54%\n",
      "Fold 4 Loss: 0.6224\n",
      "\n",
      "Fold 5\n",
      "Epoch 1/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 464ms/step - accuracy: 0.4312 - loss: 1.3206 - val_accuracy: 0.6173 - val_loss: 0.8239\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 412ms/step - accuracy: 0.6306 - loss: 0.7233 - val_accuracy: 0.6296 - val_loss: 0.7572\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 400ms/step - accuracy: 0.7626 - loss: 0.5554 - val_accuracy: 0.7407 - val_loss: 0.6208\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 410ms/step - accuracy: 0.8235 - loss: 0.4424 - val_accuracy: 0.7037 - val_loss: 0.6849\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 405ms/step - accuracy: 0.8674 - loss: 0.3861 - val_accuracy: 0.7531 - val_loss: 0.6697\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 426ms/step - accuracy: 0.9021 - loss: 0.3028 - val_accuracy: 0.7531 - val_loss: 0.6455\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 449ms/step - accuracy: 0.9155 - loss: 0.2655 - val_accuracy: 0.7531 - val_loss: 0.5556\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 416ms/step - accuracy: 0.9467 - loss: 0.2187 - val_accuracy: 0.7160 - val_loss: 0.5848\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 406ms/step - accuracy: 0.9311 - loss: 0.2056 - val_accuracy: 0.7778 - val_loss: 0.5898\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 420ms/step - accuracy: 0.9354 - loss: 0.1830 - val_accuracy: 0.7778 - val_loss: 0.5620\n",
      "Fold 5 Accuracy: 77.78%\n",
      "Fold 5 Loss: 0.5620\n",
      "Mean Accuracy: 76.62%, Mean Loss: 0.5519\n",
      "\n",
      "Testing batch_size=16, dropout=0.5, lr=0.001\n",
      "\n",
      "Fold 1\n",
      "Epoch 1/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 467ms/step - accuracy: 0.4409 - loss: 1.3936 - val_accuracy: 0.7439 - val_loss: 0.6986\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 418ms/step - accuracy: 0.6857 - loss: 0.7206 - val_accuracy: 0.7073 - val_loss: 0.6486\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 420ms/step - accuracy: 0.7823 - loss: 0.5456 - val_accuracy: 0.6463 - val_loss: 0.8142\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 417ms/step - accuracy: 0.7959 - loss: 0.5122 - val_accuracy: 0.7561 - val_loss: 0.5797\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 412ms/step - accuracy: 0.8586 - loss: 0.3199 - val_accuracy: 0.7683 - val_loss: 0.5083\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 418ms/step - accuracy: 0.8768 - loss: 0.3087 - val_accuracy: 0.7805 - val_loss: 0.4814\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 409ms/step - accuracy: 0.9320 - loss: 0.2361 - val_accuracy: 0.7927 - val_loss: 0.4896\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 438ms/step - accuracy: 0.9320 - loss: 0.1844 - val_accuracy: 0.7683 - val_loss: 0.5459\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 454ms/step - accuracy: 0.9712 - loss: 0.1523 - val_accuracy: 0.7561 - val_loss: 0.5246\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 420ms/step - accuracy: 0.9718 - loss: 0.1187 - val_accuracy: 0.7317 - val_loss: 0.5812\n",
      "Fold 1 Accuracy: 73.17%\n",
      "Fold 1 Loss: 0.5812\n",
      "\n",
      "Fold 2\n",
      "Epoch 1/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 462ms/step - accuracy: 0.4326 - loss: 1.3262 - val_accuracy: 0.7037 - val_loss: 0.7752\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 406ms/step - accuracy: 0.6446 - loss: 0.8599 - val_accuracy: 0.6914 - val_loss: 0.7433\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 420ms/step - accuracy: 0.8017 - loss: 0.4540 - val_accuracy: 0.7778 - val_loss: 0.6103\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 408ms/step - accuracy: 0.8206 - loss: 0.4078 - val_accuracy: 0.7778 - val_loss: 0.6286\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 401ms/step - accuracy: 0.8758 - loss: 0.3173 - val_accuracy: 0.7778 - val_loss: 0.5581\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 408ms/step - accuracy: 0.8796 - loss: 0.2822 - val_accuracy: 0.7901 - val_loss: 0.5966\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 404ms/step - accuracy: 0.8628 - loss: 0.3264 - val_accuracy: 0.7778 - val_loss: 0.5717\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 404ms/step - accuracy: 0.9040 - loss: 0.2471 - val_accuracy: 0.8025 - val_loss: 0.4944\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 405ms/step - accuracy: 0.9218 - loss: 0.2002 - val_accuracy: 0.7407 - val_loss: 0.5354\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 417ms/step - accuracy: 0.9291 - loss: 0.1837 - val_accuracy: 0.7901 - val_loss: 0.4680\n",
      "Fold 2 Accuracy: 79.01%\n",
      "Fold 2 Loss: 0.4680\n",
      "\n",
      "Fold 3\n",
      "Epoch 1/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 459ms/step - accuracy: 0.4120 - loss: 2.0259 - val_accuracy: 0.7037 - val_loss: 0.7051\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 411ms/step - accuracy: 0.6802 - loss: 0.7216 - val_accuracy: 0.7531 - val_loss: 0.5620\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 405ms/step - accuracy: 0.7278 - loss: 0.5772 - val_accuracy: 0.7778 - val_loss: 0.5050\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 406ms/step - accuracy: 0.8459 - loss: 0.4497 - val_accuracy: 0.7778 - val_loss: 0.5306\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 405ms/step - accuracy: 0.8294 - loss: 0.3909 - val_accuracy: 0.7778 - val_loss: 0.4604\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 402ms/step - accuracy: 0.9092 - loss: 0.2801 - val_accuracy: 0.7531 - val_loss: 0.6296\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 403ms/step - accuracy: 0.9106 - loss: 0.2327 - val_accuracy: 0.7531 - val_loss: 0.4638\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 399ms/step - accuracy: 0.9324 - loss: 0.1839 - val_accuracy: 0.7654 - val_loss: 0.4968\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 402ms/step - accuracy: 0.9441 - loss: 0.1762 - val_accuracy: 0.8025 - val_loss: 0.4965\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 404ms/step - accuracy: 0.9378 - loss: 0.1662 - val_accuracy: 0.7778 - val_loss: 0.4560\n",
      "Fold 3 Accuracy: 77.78%\n",
      "Fold 3 Loss: 0.4560\n",
      "\n",
      "Fold 4\n",
      "Epoch 1/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 488ms/step - accuracy: 0.4405 - loss: 1.3435 - val_accuracy: 0.7284 - val_loss: 0.7969\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 412ms/step - accuracy: 0.7292 - loss: 0.7125 - val_accuracy: 0.7037 - val_loss: 0.7271\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 401ms/step - accuracy: 0.8080 - loss: 0.5134 - val_accuracy: 0.7284 - val_loss: 0.8095\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 400ms/step - accuracy: 0.8074 - loss: 0.4647 - val_accuracy: 0.7901 - val_loss: 0.6051\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 404ms/step - accuracy: 0.8762 - loss: 0.2714 - val_accuracy: 0.7531 - val_loss: 0.6340\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 405ms/step - accuracy: 0.8514 - loss: 0.3275 - val_accuracy: 0.8148 - val_loss: 0.6195\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 403ms/step - accuracy: 0.9459 - loss: 0.1941 - val_accuracy: 0.8025 - val_loss: 0.6762\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 403ms/step - accuracy: 0.9035 - loss: 0.2355 - val_accuracy: 0.8148 - val_loss: 0.6354\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 396ms/step - accuracy: 0.9281 - loss: 0.2209 - val_accuracy: 0.7778 - val_loss: 0.6827\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 400ms/step - accuracy: 0.9322 - loss: 0.2057 - val_accuracy: 0.7778 - val_loss: 0.6849\n",
      "Fold 4 Accuracy: 77.78%\n",
      "Fold 4 Loss: 0.6849\n",
      "\n",
      "Fold 5\n",
      "Epoch 1/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 463ms/step - accuracy: 0.4803 - loss: 1.2083 - val_accuracy: 0.6049 - val_loss: 0.7230\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 421ms/step - accuracy: 0.6753 - loss: 0.8388 - val_accuracy: 0.7037 - val_loss: 0.6638\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 420ms/step - accuracy: 0.7762 - loss: 0.5614 - val_accuracy: 0.6667 - val_loss: 0.6802\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 434ms/step - accuracy: 0.8200 - loss: 0.4652 - val_accuracy: 0.7531 - val_loss: 0.6716\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 418ms/step - accuracy: 0.8180 - loss: 0.3872 - val_accuracy: 0.6790 - val_loss: 0.6275\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 406ms/step - accuracy: 0.8970 - loss: 0.2365 - val_accuracy: 0.7778 - val_loss: 0.6128\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 400ms/step - accuracy: 0.9215 - loss: 0.2187 - val_accuracy: 0.7654 - val_loss: 0.5390\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 408ms/step - accuracy: 0.9309 - loss: 0.1951 - val_accuracy: 0.7654 - val_loss: 0.5716\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 407ms/step - accuracy: 0.9420 - loss: 0.1738 - val_accuracy: 0.7654 - val_loss: 0.5870\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 409ms/step - accuracy: 0.9298 - loss: 0.1504 - val_accuracy: 0.7531 - val_loss: 0.7188\n",
      "Fold 5 Accuracy: 75.31%\n",
      "Fold 5 Loss: 0.7188\n",
      "Mean Accuracy: 76.61%, Mean Loss: 0.5818\n",
      "\n",
      "Testing batch_size=32, dropout=0.3, lr=0.0005\n",
      "\n",
      "Fold 1\n",
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 947ms/step - accuracy: 0.4310 - loss: 1.1739 - val_accuracy: 0.6585 - val_loss: 0.7617\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 829ms/step - accuracy: 0.6885 - loss: 0.7135 - val_accuracy: 0.7195 - val_loss: 0.5718\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 825ms/step - accuracy: 0.7643 - loss: 0.5423 - val_accuracy: 0.6951 - val_loss: 0.5959\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 824ms/step - accuracy: 0.8368 - loss: 0.4144 - val_accuracy: 0.8293 - val_loss: 0.5081\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 856ms/step - accuracy: 0.9126 - loss: 0.2847 - val_accuracy: 0.8049 - val_loss: 0.5288\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 886ms/step - accuracy: 0.9153 - loss: 0.2823 - val_accuracy: 0.7805 - val_loss: 0.4762\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 854ms/step - accuracy: 0.9171 - loss: 0.2523 - val_accuracy: 0.8293 - val_loss: 0.4312\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 833ms/step - accuracy: 0.9289 - loss: 0.2173 - val_accuracy: 0.8293 - val_loss: 0.4372\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 809ms/step - accuracy: 0.9718 - loss: 0.1665 - val_accuracy: 0.8293 - val_loss: 0.4517\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 828ms/step - accuracy: 0.9525 - loss: 0.1689 - val_accuracy: 0.7683 - val_loss: 0.4979\n",
      "Fold 1 Accuracy: 76.83%\n",
      "Fold 1 Loss: 0.4979\n",
      "\n",
      "Fold 2\n",
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 926ms/step - accuracy: 0.4869 - loss: 1.1757 - val_accuracy: 0.5926 - val_loss: 0.8874\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 811ms/step - accuracy: 0.6389 - loss: 0.7643 - val_accuracy: 0.7407 - val_loss: 0.6742\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 809ms/step - accuracy: 0.7837 - loss: 0.5338 - val_accuracy: 0.7160 - val_loss: 0.6313\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 817ms/step - accuracy: 0.8396 - loss: 0.3956 - val_accuracy: 0.7284 - val_loss: 0.5983\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 820ms/step - accuracy: 0.8399 - loss: 0.3716 - val_accuracy: 0.7407 - val_loss: 0.6285\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 813ms/step - accuracy: 0.8867 - loss: 0.3016 - val_accuracy: 0.7901 - val_loss: 0.5207\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 854ms/step - accuracy: 0.8822 - loss: 0.2614 - val_accuracy: 0.7407 - val_loss: 0.5697\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 851ms/step - accuracy: 0.9455 - loss: 0.1920 - val_accuracy: 0.8025 - val_loss: 0.5597\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 832ms/step - accuracy: 0.9359 - loss: 0.2134 - val_accuracy: 0.7778 - val_loss: 0.5315\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 809ms/step - accuracy: 0.9828 - loss: 0.1467 - val_accuracy: 0.7531 - val_loss: 0.5395\n",
      "Fold 2 Accuracy: 75.31%\n",
      "Fold 2 Loss: 0.5395\n",
      "\n",
      "Fold 3\n",
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 923ms/step - accuracy: 0.4605 - loss: 1.2218 - val_accuracy: 0.7037 - val_loss: 0.6719\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 806ms/step - accuracy: 0.7002 - loss: 0.6415 - val_accuracy: 0.7654 - val_loss: 0.6228\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 805ms/step - accuracy: 0.7961 - loss: 0.5423 - val_accuracy: 0.8025 - val_loss: 0.5343\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 807ms/step - accuracy: 0.8556 - loss: 0.4301 - val_accuracy: 0.7901 - val_loss: 0.4810\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 810ms/step - accuracy: 0.8458 - loss: 0.3440 - val_accuracy: 0.7778 - val_loss: 0.5401\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 807ms/step - accuracy: 0.9001 - loss: 0.2909 - val_accuracy: 0.7654 - val_loss: 0.5603\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 817ms/step - accuracy: 0.9041 - loss: 0.2571 - val_accuracy: 0.7531 - val_loss: 0.4785\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 800ms/step - accuracy: 0.9649 - loss: 0.1723 - val_accuracy: 0.7531 - val_loss: 0.4722\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 852ms/step - accuracy: 0.9576 - loss: 0.1724 - val_accuracy: 0.7654 - val_loss: 0.4675\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 845ms/step - accuracy: 0.9667 - loss: 0.1367 - val_accuracy: 0.7654 - val_loss: 0.6065\n",
      "Fold 3 Accuracy: 76.54%\n",
      "Fold 3 Loss: 0.6065\n",
      "\n",
      "Fold 4\n",
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 936ms/step - accuracy: 0.3668 - loss: 1.4839 - val_accuracy: 0.5432 - val_loss: 1.0684\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 815ms/step - accuracy: 0.6568 - loss: 0.7469 - val_accuracy: 0.6667 - val_loss: 0.7567\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 817ms/step - accuracy: 0.7245 - loss: 0.5510 - val_accuracy: 0.7037 - val_loss: 0.6969\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 832ms/step - accuracy: 0.8048 - loss: 0.4381 - val_accuracy: 0.7531 - val_loss: 0.7311\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 811ms/step - accuracy: 0.8514 - loss: 0.3811 - val_accuracy: 0.7531 - val_loss: 0.7216\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 811ms/step - accuracy: 0.8515 - loss: 0.3245 - val_accuracy: 0.7407 - val_loss: 0.6615\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 795ms/step - accuracy: 0.8899 - loss: 0.2430 - val_accuracy: 0.7284 - val_loss: 0.6849\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 822ms/step - accuracy: 0.9213 - loss: 0.2231 - val_accuracy: 0.7778 - val_loss: 0.7196\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 808ms/step - accuracy: 0.9110 - loss: 0.2661 - val_accuracy: 0.7778 - val_loss: 0.6273\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 824ms/step - accuracy: 0.9684 - loss: 0.1474 - val_accuracy: 0.8025 - val_loss: 0.6042\n",
      "Fold 4 Accuracy: 80.25%\n",
      "Fold 4 Loss: 0.6042\n",
      "\n",
      "Fold 5\n",
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 926ms/step - accuracy: 0.4461 - loss: 1.1781 - val_accuracy: 0.5802 - val_loss: 0.9577\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 821ms/step - accuracy: 0.7082 - loss: 0.6895 - val_accuracy: 0.6173 - val_loss: 0.7369\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 817ms/step - accuracy: 0.7751 - loss: 0.5259 - val_accuracy: 0.7037 - val_loss: 0.6480\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 798ms/step - accuracy: 0.8923 - loss: 0.3615 - val_accuracy: 0.7407 - val_loss: 0.6341\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 796ms/step - accuracy: 0.8670 - loss: 0.3854 - val_accuracy: 0.7407 - val_loss: 0.6044\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 806ms/step - accuracy: 0.8533 - loss: 0.3316 - val_accuracy: 0.7407 - val_loss: 0.6604\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 798ms/step - accuracy: 0.8875 - loss: 0.3130 - val_accuracy: 0.7654 - val_loss: 0.5689\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 799ms/step - accuracy: 0.9540 - loss: 0.1925 - val_accuracy: 0.7284 - val_loss: 0.6523\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 802ms/step - accuracy: 0.9775 - loss: 0.1407 - val_accuracy: 0.7778 - val_loss: 0.5577\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 850ms/step - accuracy: 0.9828 - loss: 0.1189 - val_accuracy: 0.7901 - val_loss: 0.5522\n",
      "Fold 5 Accuracy: 79.01%\n",
      "Fold 5 Loss: 0.5522\n",
      "Mean Accuracy: 77.59%, Mean Loss: 0.5600\n",
      "\n",
      "Testing batch_size=32, dropout=0.3, lr=0.001\n",
      "\n",
      "Fold 1\n",
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 964ms/step - accuracy: 0.4831 - loss: 1.2814 - val_accuracy: 0.5976 - val_loss: 0.8769\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 817ms/step - accuracy: 0.6897 - loss: 0.7720 - val_accuracy: 0.7683 - val_loss: 0.5858\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 792ms/step - accuracy: 0.8090 - loss: 0.5129 - val_accuracy: 0.7439 - val_loss: 0.5460\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 805ms/step - accuracy: 0.8789 - loss: 0.3780 - val_accuracy: 0.7683 - val_loss: 0.5334\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 811ms/step - accuracy: 0.9172 - loss: 0.2646 - val_accuracy: 0.7805 - val_loss: 0.5114\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 802ms/step - accuracy: 0.9540 - loss: 0.1931 - val_accuracy: 0.7195 - val_loss: 0.6288\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 797ms/step - accuracy: 0.9589 - loss: 0.1613 - val_accuracy: 0.7805 - val_loss: 0.4906\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 804ms/step - accuracy: 0.9501 - loss: 0.1656 - val_accuracy: 0.7439 - val_loss: 0.5050\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 799ms/step - accuracy: 0.9499 - loss: 0.1466 - val_accuracy: 0.7439 - val_loss: 0.4968\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 810ms/step - accuracy: 0.9814 - loss: 0.0957 - val_accuracy: 0.7927 - val_loss: 0.5267\n",
      "Fold 1 Accuracy: 79.27%\n",
      "Fold 1 Loss: 0.5267\n",
      "\n",
      "Fold 2\n",
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 929ms/step - accuracy: 0.4744 - loss: 1.1668 - val_accuracy: 0.7160 - val_loss: 0.7177\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 821ms/step - accuracy: 0.7055 - loss: 0.6244 - val_accuracy: 0.6420 - val_loss: 0.7181\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 842ms/step - accuracy: 0.8402 - loss: 0.4170 - val_accuracy: 0.7284 - val_loss: 0.7232\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 850ms/step - accuracy: 0.8135 - loss: 0.4209 - val_accuracy: 0.7654 - val_loss: 0.5233\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 790ms/step - accuracy: 0.8861 - loss: 0.2466 - val_accuracy: 0.7407 - val_loss: 0.5235\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 791ms/step - accuracy: 0.9166 - loss: 0.2148 - val_accuracy: 0.7531 - val_loss: 0.6153\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 804ms/step - accuracy: 0.9014 - loss: 0.2212 - val_accuracy: 0.8025 - val_loss: 0.4947\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 797ms/step - accuracy: 0.9257 - loss: 0.2015 - val_accuracy: 0.7531 - val_loss: 0.6334\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 802ms/step - accuracy: 0.9533 - loss: 0.1527 - val_accuracy: 0.8148 - val_loss: 0.5727\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 794ms/step - accuracy: 0.9738 - loss: 0.1126 - val_accuracy: 0.7407 - val_loss: 0.6384\n",
      "Fold 2 Accuracy: 74.07%\n",
      "Fold 2 Loss: 0.6384\n",
      "\n",
      "Fold 3\n",
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 919ms/step - accuracy: 0.3926 - loss: 1.5306 - val_accuracy: 0.7160 - val_loss: 0.7126\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 809ms/step - accuracy: 0.7095 - loss: 0.6557 - val_accuracy: 0.6790 - val_loss: 0.6361\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 817ms/step - accuracy: 0.7630 - loss: 0.5972 - val_accuracy: 0.7654 - val_loss: 0.5621\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 835ms/step - accuracy: 0.8675 - loss: 0.3651 - val_accuracy: 0.7531 - val_loss: 0.5227\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 845ms/step - accuracy: 0.8949 - loss: 0.3035 - val_accuracy: 0.7654 - val_loss: 0.5157\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 832ms/step - accuracy: 0.8963 - loss: 0.2740 - val_accuracy: 0.7654 - val_loss: 0.6019\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 813ms/step - accuracy: 0.9654 - loss: 0.1643 - val_accuracy: 0.7654 - val_loss: 0.4784\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 832ms/step - accuracy: 0.9672 - loss: 0.1295 - val_accuracy: 0.7901 - val_loss: 0.4814\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 797ms/step - accuracy: 0.9447 - loss: 0.1415 - val_accuracy: 0.7654 - val_loss: 0.5177\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 800ms/step - accuracy: 0.9830 - loss: 0.1093 - val_accuracy: 0.7407 - val_loss: 0.5060\n",
      "Fold 3 Accuracy: 74.07%\n",
      "Fold 3 Loss: 0.5060\n",
      "\n",
      "Fold 4\n",
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 916ms/step - accuracy: 0.4425 - loss: 1.5905 - val_accuracy: 0.6543 - val_loss: 0.8074\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 800ms/step - accuracy: 0.7423 - loss: 0.6702 - val_accuracy: 0.6914 - val_loss: 0.7835\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 794ms/step - accuracy: 0.7545 - loss: 0.4999 - val_accuracy: 0.7531 - val_loss: 0.6888\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 798ms/step - accuracy: 0.8529 - loss: 0.3744 - val_accuracy: 0.7160 - val_loss: 0.7277\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 793ms/step - accuracy: 0.9094 - loss: 0.2997 - val_accuracy: 0.7778 - val_loss: 0.6733\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 830ms/step - accuracy: 0.9119 - loss: 0.2344 - val_accuracy: 0.7654 - val_loss: 0.6399\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 847ms/step - accuracy: 0.9526 - loss: 0.1850 - val_accuracy: 0.8148 - val_loss: 0.6415\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 811ms/step - accuracy: 0.9607 - loss: 0.1491 - val_accuracy: 0.8272 - val_loss: 0.6628\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 788ms/step - accuracy: 0.9557 - loss: 0.1247 - val_accuracy: 0.8148 - val_loss: 0.6618\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 812ms/step - accuracy: 0.9873 - loss: 0.0928 - val_accuracy: 0.7901 - val_loss: 0.6927\n",
      "Fold 4 Accuracy: 79.01%\n",
      "Fold 4 Loss: 0.6927\n",
      "\n",
      "Fold 5\n",
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 930ms/step - accuracy: 0.3939 - loss: 1.2932 - val_accuracy: 0.6420 - val_loss: 0.7661\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 794ms/step - accuracy: 0.7302 - loss: 0.6018 - val_accuracy: 0.6790 - val_loss: 0.6534\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 794ms/step - accuracy: 0.8101 - loss: 0.4260 - val_accuracy: 0.7531 - val_loss: 0.6022\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 810ms/step - accuracy: 0.8726 - loss: 0.3046 - val_accuracy: 0.7037 - val_loss: 0.5964\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 797ms/step - accuracy: 0.9274 - loss: 0.2260 - val_accuracy: 0.7160 - val_loss: 0.6808\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 794ms/step - accuracy: 0.9434 - loss: 0.1874 - val_accuracy: 0.7407 - val_loss: 0.6190\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 798ms/step - accuracy: 0.9343 - loss: 0.1785 - val_accuracy: 0.7037 - val_loss: 0.6967\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 872ms/step - accuracy: 0.9744 - loss: 0.1231 - val_accuracy: 0.7160 - val_loss: 0.8345\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 863ms/step - accuracy: 0.9436 - loss: 0.1612 - val_accuracy: 0.7778 - val_loss: 0.5472\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 829ms/step - accuracy: 0.9767 - loss: 0.1050 - val_accuracy: 0.7284 - val_loss: 0.5791\n",
      "Fold 5 Accuracy: 72.84%\n",
      "Fold 5 Loss: 0.5791\n",
      "Mean Accuracy: 75.85%, Mean Loss: 0.5886\n",
      "\n",
      "Testing batch_size=32, dropout=0.5, lr=0.0005\n",
      "\n",
      "Fold 1\n",
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 917ms/step - accuracy: 0.4464 - loss: 1.2620 - val_accuracy: 0.7195 - val_loss: 0.6723\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 865ms/step - accuracy: 0.6936 - loss: 0.7685 - val_accuracy: 0.6951 - val_loss: 0.6740\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 804ms/step - accuracy: 0.7935 - loss: 0.4882 - val_accuracy: 0.7317 - val_loss: 0.5864\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 792ms/step - accuracy: 0.7952 - loss: 0.4886 - val_accuracy: 0.7195 - val_loss: 0.6064\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 801ms/step - accuracy: 0.8365 - loss: 0.3970 - val_accuracy: 0.7195 - val_loss: 0.5603\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 821ms/step - accuracy: 0.8764 - loss: 0.3081 - val_accuracy: 0.7927 - val_loss: 0.5337\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 806ms/step - accuracy: 0.8693 - loss: 0.3398 - val_accuracy: 0.7805 - val_loss: 0.5197\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 796ms/step - accuracy: 0.9020 - loss: 0.2730 - val_accuracy: 0.7683 - val_loss: 0.5003\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 841ms/step - accuracy: 0.9120 - loss: 0.2516 - val_accuracy: 0.7317 - val_loss: 0.5420\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 852ms/step - accuracy: 0.9354 - loss: 0.2314 - val_accuracy: 0.7805 - val_loss: 0.5052\n",
      "Fold 1 Accuracy: 78.05%\n",
      "Fold 1 Loss: 0.5052\n",
      "\n",
      "Fold 2\n",
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 933ms/step - accuracy: 0.4364 - loss: 1.3197 - val_accuracy: 0.4938 - val_loss: 1.0987\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 805ms/step - accuracy: 0.5730 - loss: 0.9907 - val_accuracy: 0.6420 - val_loss: 0.8543\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 802ms/step - accuracy: 0.7503 - loss: 0.6156 - val_accuracy: 0.6667 - val_loss: 0.7241\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 807ms/step - accuracy: 0.8094 - loss: 0.5758 - val_accuracy: 0.7284 - val_loss: 0.6167\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 793ms/step - accuracy: 0.8071 - loss: 0.4857 - val_accuracy: 0.7654 - val_loss: 0.5854\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 797ms/step - accuracy: 0.8638 - loss: 0.3883 - val_accuracy: 0.7531 - val_loss: 0.5651\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 790ms/step - accuracy: 0.9107 - loss: 0.3113 - val_accuracy: 0.8025 - val_loss: 0.5188\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 796ms/step - accuracy: 0.9039 - loss: 0.2792 - val_accuracy: 0.8025 - val_loss: 0.5667\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 807ms/step - accuracy: 0.9118 - loss: 0.2784 - val_accuracy: 0.7654 - val_loss: 0.5223\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 837ms/step - accuracy: 0.9212 - loss: 0.2494 - val_accuracy: 0.7654 - val_loss: 0.5338\n",
      "Fold 2 Accuracy: 76.54%\n",
      "Fold 2 Loss: 0.5338\n",
      "\n",
      "Fold 3\n",
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 903ms/step - accuracy: 0.3946 - loss: 1.4326 - val_accuracy: 0.6543 - val_loss: 0.7819\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 807ms/step - accuracy: 0.6356 - loss: 0.8223 - val_accuracy: 0.7160 - val_loss: 0.6550\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 805ms/step - accuracy: 0.7628 - loss: 0.6541 - val_accuracy: 0.7284 - val_loss: 0.6450\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 806ms/step - accuracy: 0.7760 - loss: 0.5150 - val_accuracy: 0.7654 - val_loss: 0.5507\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 805ms/step - accuracy: 0.8278 - loss: 0.4687 - val_accuracy: 0.7901 - val_loss: 0.5050\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 795ms/step - accuracy: 0.8797 - loss: 0.3656 - val_accuracy: 0.7778 - val_loss: 0.4901\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 809ms/step - accuracy: 0.8722 - loss: 0.3116 - val_accuracy: 0.8148 - val_loss: 0.4843\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 809ms/step - accuracy: 0.8948 - loss: 0.2890 - val_accuracy: 0.7531 - val_loss: 0.4838\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 804ms/step - accuracy: 0.9141 - loss: 0.2281 - val_accuracy: 0.7901 - val_loss: 0.4687\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 803ms/step - accuracy: 0.9329 - loss: 0.2154 - val_accuracy: 0.8148 - val_loss: 0.4726\n",
      "Fold 3 Accuracy: 81.48%\n",
      "Fold 3 Loss: 0.4726\n",
      "\n",
      "Fold 4\n",
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 0.4061 - loss: 1.4040 - val_accuracy: 0.6296 - val_loss: 0.7930\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 856ms/step - accuracy: 0.6465 - loss: 0.7636 - val_accuracy: 0.6790 - val_loss: 0.7285\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 812ms/step - accuracy: 0.6975 - loss: 0.6741 - val_accuracy: 0.7531 - val_loss: 0.6777\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 841ms/step - accuracy: 0.8280 - loss: 0.4475 - val_accuracy: 0.7531 - val_loss: 0.6203\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 806ms/step - accuracy: 0.8307 - loss: 0.4563 - val_accuracy: 0.7654 - val_loss: 0.5880\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 808ms/step - accuracy: 0.8575 - loss: 0.3486 - val_accuracy: 0.7654 - val_loss: 0.5858\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 810ms/step - accuracy: 0.8531 - loss: 0.3565 - val_accuracy: 0.7778 - val_loss: 0.6395\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 804ms/step - accuracy: 0.9061 - loss: 0.2760 - val_accuracy: 0.8148 - val_loss: 0.5741\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 807ms/step - accuracy: 0.8889 - loss: 0.2930 - val_accuracy: 0.7901 - val_loss: 0.5792\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 794ms/step - accuracy: 0.9306 - loss: 0.2282 - val_accuracy: 0.8025 - val_loss: 0.5388\n",
      "Fold 4 Accuracy: 80.25%\n",
      "Fold 4 Loss: 0.5388\n",
      "\n",
      "Fold 5\n",
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 909ms/step - accuracy: 0.4662 - loss: 1.3650 - val_accuracy: 0.6420 - val_loss: 0.8169\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 806ms/step - accuracy: 0.6651 - loss: 0.8490 - val_accuracy: 0.6173 - val_loss: 0.7337\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 835ms/step - accuracy: 0.7338 - loss: 0.6055 - val_accuracy: 0.6296 - val_loss: 0.8486\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 838ms/step - accuracy: 0.7902 - loss: 0.5130 - val_accuracy: 0.7407 - val_loss: 0.5987\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 828ms/step - accuracy: 0.8252 - loss: 0.4396 - val_accuracy: 0.6914 - val_loss: 0.6460\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 803ms/step - accuracy: 0.8585 - loss: 0.3580 - val_accuracy: 0.7284 - val_loss: 0.6175\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 802ms/step - accuracy: 0.8932 - loss: 0.3184 - val_accuracy: 0.7037 - val_loss: 0.6012\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 791ms/step - accuracy: 0.9075 - loss: 0.2824 - val_accuracy: 0.7284 - val_loss: 0.6342\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 794ms/step - accuracy: 0.9199 - loss: 0.2489 - val_accuracy: 0.7531 - val_loss: 0.5834\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 807ms/step - accuracy: 0.9376 - loss: 0.2139 - val_accuracy: 0.7284 - val_loss: 0.5560\n",
      "Fold 5 Accuracy: 72.84%\n",
      "Fold 5 Loss: 0.5560\n",
      "Mean Accuracy: 77.83%, Mean Loss: 0.5213\n",
      "\n",
      "Testing batch_size=32, dropout=0.5, lr=0.001\n",
      "\n",
      "Fold 1\n",
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 930ms/step - accuracy: 0.4230 - loss: 1.3827 - val_accuracy: 0.6585 - val_loss: 0.7355\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 798ms/step - accuracy: 0.6799 - loss: 0.7763 - val_accuracy: 0.6463 - val_loss: 0.8899\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 803ms/step - accuracy: 0.7434 - loss: 0.6252 - val_accuracy: 0.6829 - val_loss: 0.6285\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 804ms/step - accuracy: 0.8366 - loss: 0.4567 - val_accuracy: 0.7561 - val_loss: 0.6149\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 849ms/step - accuracy: 0.8397 - loss: 0.3798 - val_accuracy: 0.7195 - val_loss: 0.6048\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 848ms/step - accuracy: 0.8898 - loss: 0.2817 - val_accuracy: 0.7073 - val_loss: 0.6176\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 812ms/step - accuracy: 0.8960 - loss: 0.2447 - val_accuracy: 0.7561 - val_loss: 0.5377\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 807ms/step - accuracy: 0.8794 - loss: 0.2948 - val_accuracy: 0.7195 - val_loss: 0.6469\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 803ms/step - accuracy: 0.9004 - loss: 0.2416 - val_accuracy: 0.6463 - val_loss: 0.7764\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 798ms/step - accuracy: 0.9031 - loss: 0.2308 - val_accuracy: 0.7683 - val_loss: 0.5538\n",
      "Fold 1 Accuracy: 76.83%\n",
      "Fold 1 Loss: 0.5538\n",
      "\n",
      "Fold 2\n",
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 917ms/step - accuracy: 0.3302 - loss: 1.5930 - val_accuracy: 0.6296 - val_loss: 0.7974\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 847ms/step - accuracy: 0.6981 - loss: 0.6938 - val_accuracy: 0.7654 - val_loss: 0.6467\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 801ms/step - accuracy: 0.8081 - loss: 0.5512 - val_accuracy: 0.6667 - val_loss: 0.6480\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 811ms/step - accuracy: 0.8215 - loss: 0.4943 - val_accuracy: 0.7407 - val_loss: 0.6031\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 797ms/step - accuracy: 0.8059 - loss: 0.3906 - val_accuracy: 0.7654 - val_loss: 0.5719\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 802ms/step - accuracy: 0.8989 - loss: 0.2945 - val_accuracy: 0.7901 - val_loss: 0.5164\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 853ms/step - accuracy: 0.9052 - loss: 0.2396 - val_accuracy: 0.8272 - val_loss: 0.5490\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 843ms/step - accuracy: 0.8822 - loss: 0.2710 - val_accuracy: 0.8148 - val_loss: 0.5511\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 816ms/step - accuracy: 0.9395 - loss: 0.1909 - val_accuracy: 0.7531 - val_loss: 0.7795\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 806ms/step - accuracy: 0.8491 - loss: 0.3502 - val_accuracy: 0.6543 - val_loss: 0.6702\n",
      "Fold 2 Accuracy: 65.43%\n",
      "Fold 2 Loss: 0.6702\n",
      "\n",
      "Fold 3\n",
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 930ms/step - accuracy: 0.4790 - loss: 1.1952 - val_accuracy: 0.7284 - val_loss: 0.6254\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 804ms/step - accuracy: 0.7445 - loss: 0.6507 - val_accuracy: 0.7284 - val_loss: 0.6172\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 791ms/step - accuracy: 0.7620 - loss: 0.5766 - val_accuracy: 0.7531 - val_loss: 0.5600\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 802ms/step - accuracy: 0.8092 - loss: 0.4570 - val_accuracy: 0.7654 - val_loss: 0.5166\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 813ms/step - accuracy: 0.7905 - loss: 0.4710 - val_accuracy: 0.7778 - val_loss: 0.5408\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 799ms/step - accuracy: 0.8791 - loss: 0.3155 - val_accuracy: 0.7654 - val_loss: 0.5136\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 813ms/step - accuracy: 0.8971 - loss: 0.2704 - val_accuracy: 0.7778 - val_loss: 0.4787\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 841ms/step - accuracy: 0.9064 - loss: 0.2235 - val_accuracy: 0.7654 - val_loss: 0.5038\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 846ms/step - accuracy: 0.9240 - loss: 0.1862 - val_accuracy: 0.7531 - val_loss: 0.5763\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 847ms/step - accuracy: 0.9541 - loss: 0.1630 - val_accuracy: 0.7407 - val_loss: 0.5543\n",
      "Fold 3 Accuracy: 74.07%\n",
      "Fold 3 Loss: 0.5543\n",
      "\n",
      "Fold 4\n",
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 0.4557 - loss: 1.4108 - val_accuracy: 0.6914 - val_loss: 0.8452\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 803ms/step - accuracy: 0.6573 - loss: 0.7532 - val_accuracy: 0.6914 - val_loss: 0.7468\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 818ms/step - accuracy: 0.6518 - loss: 0.8574 - val_accuracy: 0.7531 - val_loss: 0.6671\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 813ms/step - accuracy: 0.7617 - loss: 0.6028 - val_accuracy: 0.7037 - val_loss: 0.9298\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 809ms/step - accuracy: 0.7965 - loss: 0.4943 - val_accuracy: 0.7531 - val_loss: 0.6431\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 816ms/step - accuracy: 0.8802 - loss: 0.3271 - val_accuracy: 0.7778 - val_loss: 0.5753\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 801ms/step - accuracy: 0.8303 - loss: 0.3766 - val_accuracy: 0.7778 - val_loss: 0.6041\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 803ms/step - accuracy: 0.8761 - loss: 0.2726 - val_accuracy: 0.7901 - val_loss: 0.6392\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 808ms/step - accuracy: 0.8959 - loss: 0.2726 - val_accuracy: 0.8148 - val_loss: 0.6257\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 844ms/step - accuracy: 0.9363 - loss: 0.2161 - val_accuracy: 0.8025 - val_loss: 0.6259\n",
      "Fold 4 Accuracy: 80.25%\n",
      "Fold 4 Loss: 0.6259\n",
      "\n",
      "Fold 5\n",
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 917ms/step - accuracy: 0.4180 - loss: 1.5626 - val_accuracy: 0.5185 - val_loss: 1.4523\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 809ms/step - accuracy: 0.6396 - loss: 0.8856 - val_accuracy: 0.6173 - val_loss: 0.8396\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 812ms/step - accuracy: 0.7202 - loss: 0.6020 - val_accuracy: 0.7407 - val_loss: 0.6543\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 796ms/step - accuracy: 0.8278 - loss: 0.4281 - val_accuracy: 0.7160 - val_loss: 0.6387\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 796ms/step - accuracy: 0.8737 - loss: 0.3687 - val_accuracy: 0.7284 - val_loss: 0.6259\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 797ms/step - accuracy: 0.8136 - loss: 0.4565 - val_accuracy: 0.6543 - val_loss: 0.9919\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 803ms/step - accuracy: 0.8420 - loss: 0.3923 - val_accuracy: 0.7284 - val_loss: 0.5995\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 799ms/step - accuracy: 0.8855 - loss: 0.2835 - val_accuracy: 0.7654 - val_loss: 0.5930\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 800ms/step - accuracy: 0.9184 - loss: 0.2289 - val_accuracy: 0.7407 - val_loss: 0.6186\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 790ms/step - accuracy: 0.9335 - loss: 0.1783 - val_accuracy: 0.7531 - val_loss: 0.5978\n",
      "Fold 5 Accuracy: 75.31%\n",
      "Fold 5 Loss: 0.5978\n",
      "Mean Accuracy: 74.38%, Mean Loss: 0.6004\n",
      "\n",
      "Best Parameters:\n",
      "{'batch_size': 16, 'dropout': 0.3, 'learning_rate': 0.001, 'accuracy': 0.7857271909713746}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import itertools\n",
    "\n",
    "# ---- Load and Preprocess Data ----\n",
    "train_dir = 'D:/Lung_cancer/train'  # Training directory path\n",
    "target_size = (224, 224)  # Input size for MobileNetV2\n",
    "num_classes = 3\n",
    "\n",
    "# Extract file paths and labels\n",
    "train_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=target_size,\n",
    "    batch_size=32,  # Temporary batch size\n",
    "    class_mode='categorical',\n",
    "    shuffle=False  # To keep track of indices\n",
    ")\n",
    "X = np.array(train_generator.filepaths)  # File paths of images\n",
    "y = np.array(train_generator.classes)    # Corresponding class labels\n",
    "\n",
    "# ---- Hyperparameter Search Space ----\n",
    "batch_sizes = [16, 32]\n",
    "dropout_rates = [0.3, 0.5]\n",
    "learning_rates = [0.0005, 0.001]\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "best_params = {}\n",
    "best_accuracy = 0\n",
    "\n",
    "# Iterate over all combinations of hyperparameters\n",
    "for batch_size, dropout_rate, learning_rate in itertools.product(batch_sizes, dropout_rates, learning_rates):\n",
    "    print(f\"Testing batch_size={batch_size}, dropout={dropout_rate}, lr={learning_rate}\")\n",
    "    \n",
    "    fold_accuracies = []\n",
    "    fold_losses = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
    "        print(f\"\\nFold {fold + 1}\")\n",
    "        \n",
    "        # Split into training and validation sets\n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "        \n",
    "        # Load data dynamically\n",
    "        def load_data(file_paths, labels):\n",
    "            images = []\n",
    "            for file in file_paths:\n",
    "                img = load_img(file, target_size=target_size)\n",
    "                img = img_to_array(img)\n",
    "                images.append(img)\n",
    "            images = np.array(images) / 255.0\n",
    "            labels = np.eye(num_classes)[labels]\n",
    "            return images, labels\n",
    "        \n",
    "        X_train_images, y_train_labels = load_data(X_train, y_train)\n",
    "        X_val_images, y_val_labels = load_data(X_val, y_val)\n",
    "        \n",
    "        # ---- Define and Compile Model ----\n",
    "        base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "        base_model.trainable = False\n",
    "        \n",
    "        x = base_model.output\n",
    "        x = layers.GlobalAveragePooling2D()(x)\n",
    "        x = layers.Dense(512, activation='relu')(x)\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "        output = layers.Dense(num_classes, activation='softmax')(x)\n",
    "        model = models.Model(inputs=base_model.input, outputs=output)\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer=Adam(learning_rate=learning_rate),\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "        # ---- Train Model ----\n",
    "        history = model.fit(\n",
    "            X_train_images, y_train_labels,\n",
    "            validation_data=(X_val_images, y_val_labels),\n",
    "            epochs=10,\n",
    "            batch_size=batch_size,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # ---- Evaluate Model ----\n",
    "        val_loss, val_accuracy = model.evaluate(X_val_images, y_val_labels, verbose=0)\n",
    "        print(f\"Fold {fold + 1} Accuracy: {val_accuracy * 100:.2f}%\")\n",
    "        print(f\"Fold {fold + 1} Loss: {val_loss:.4f}\")\n",
    "        \n",
    "        fold_accuracies.append(val_accuracy)\n",
    "        fold_losses.append(val_loss)\n",
    "    \n",
    "    # Compute mean accuracy for the current hyperparameter combination\n",
    "    mean_accuracy = np.mean(fold_accuracies)\n",
    "    mean_loss = np.mean(fold_losses)\n",
    "    \n",
    "    print(f\"Mean Accuracy: {mean_accuracy * 100:.2f}%, Mean Loss: {mean_loss:.4f}\\n\")\n",
    "    \n",
    "    # Store best hyperparameters\n",
    "    if mean_accuracy > best_accuracy:\n",
    "        best_accuracy = mean_accuracy\n",
    "        best_params = {\n",
    "            \"batch_size\": batch_size,\n",
    "            \"dropout\": dropout_rate,\n",
    "            \"learning_rate\": learning_rate,\n",
    "            \"accuracy\": best_accuracy\n",
    "        }\n",
    "\n",
    "# ---- Final Best Parameters ----\n",
    "print(\"Best Parameters:\")\n",
    "print(best_params)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
