{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0cd4529-cf49-4826-9843-904e20ecdc9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 406 images belonging to 3 classes.\n",
      "Testing batch_size=16, dropout=0.3, lr=0.0005\n",
      "\n",
      "Fold 1\n",
      "Epoch 1/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 611ms/step - accuracy: 0.3334 - loss: 1.1807 - val_accuracy: 0.2927 - val_loss: 1.0971\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 479ms/step - accuracy: 0.3167 - loss: 1.1113 - val_accuracy: 0.2927 - val_loss: 1.0922\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 553ms/step - accuracy: 0.3246 - loss: 1.1255 - val_accuracy: 0.4634 - val_loss: 1.0864\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 632ms/step - accuracy: 0.3338 - loss: 1.1851 - val_accuracy: 0.2927 - val_loss: 1.1225\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 509ms/step - accuracy: 0.3396 - loss: 1.1360 - val_accuracy: 0.2927 - val_loss: 1.1228\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 482ms/step - accuracy: 0.3498 - loss: 1.1055 - val_accuracy: 0.2927 - val_loss: 1.1119\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 493ms/step - accuracy: 0.3136 - loss: 1.1274 - val_accuracy: 0.4634 - val_loss: 1.0629\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 492ms/step - accuracy: 0.3477 - loss: 1.1106 - val_accuracy: 0.2927 - val_loss: 1.1169\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 537ms/step - accuracy: 0.3031 - loss: 1.1185 - val_accuracy: 0.4634 - val_loss: 1.0817\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 503ms/step - accuracy: 0.3438 - loss: 1.0950 - val_accuracy: 0.4634 - val_loss: 1.0832\n",
      "Fold 1 Accuracy: 46.34%\n",
      "Fold 1 Loss: 1.0832\n",
      "\n",
      "Fold 2\n",
      "Epoch 1/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 575ms/step - accuracy: 0.3368 - loss: 1.1657 - val_accuracy: 0.3086 - val_loss: 1.1257\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 479ms/step - accuracy: 0.3538 - loss: 1.1265 - val_accuracy: 0.3086 - val_loss: 1.1731\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 528ms/step - accuracy: 0.2881 - loss: 1.1808 - val_accuracy: 0.3086 - val_loss: 1.1462\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 527ms/step - accuracy: 0.2914 - loss: 1.1553 - val_accuracy: 0.3086 - val_loss: 1.1128\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 531ms/step - accuracy: 0.3680 - loss: 1.1126 - val_accuracy: 0.3086 - val_loss: 1.0991\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 529ms/step - accuracy: 0.2766 - loss: 1.1337 - val_accuracy: 0.3827 - val_loss: 1.0976\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 528ms/step - accuracy: 0.3738 - loss: 1.0903 - val_accuracy: 0.3086 - val_loss: 1.1095\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 564ms/step - accuracy: 0.3287 - loss: 1.1269 - val_accuracy: 0.3086 - val_loss: 1.1029\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 563ms/step - accuracy: 0.3770 - loss: 1.1168 - val_accuracy: 0.3827 - val_loss: 1.1052\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 533ms/step - accuracy: 0.4033 - loss: 1.1094 - val_accuracy: 0.3086 - val_loss: 1.1228\n",
      "Fold 2 Accuracy: 30.86%\n",
      "Fold 2 Loss: 1.1228\n",
      "\n",
      "Fold 3\n",
      "Epoch 1/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 601ms/step - accuracy: 0.3665 - loss: 1.1904 - val_accuracy: 0.3333 - val_loss: 1.1732\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 484ms/step - accuracy: 0.3395 - loss: 1.1958 - val_accuracy: 0.3333 - val_loss: 1.1024\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 483ms/step - accuracy: 0.4107 - loss: 1.1084 - val_accuracy: 0.3827 - val_loss: 1.1030\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 480ms/step - accuracy: 0.3192 - loss: 1.1510 - val_accuracy: 0.3827 - val_loss: 1.0959\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 483ms/step - accuracy: 0.3421 - loss: 1.1284 - val_accuracy: 0.3333 - val_loss: 1.2151\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 487ms/step - accuracy: 0.3477 - loss: 1.1590 - val_accuracy: 0.3333 - val_loss: 1.1182\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 525ms/step - accuracy: 0.4101 - loss: 1.1043 - val_accuracy: 0.3333 - val_loss: 1.0989\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 538ms/step - accuracy: 0.3411 - loss: 1.1025 - val_accuracy: 0.3333 - val_loss: 1.1059\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 490ms/step - accuracy: 0.3071 - loss: 1.1029 - val_accuracy: 0.3333 - val_loss: 1.1039\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 482ms/step - accuracy: 0.3745 - loss: 1.0984 - val_accuracy: 0.3333 - val_loss: 1.1138\n",
      "Fold 3 Accuracy: 33.33%\n",
      "Fold 3 Loss: 1.1138\n",
      "\n",
      "Fold 4\n",
      "Epoch 1/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 577ms/step - accuracy: 0.3285 - loss: 1.1743 - val_accuracy: 0.3827 - val_loss: 1.1001\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 494ms/step - accuracy: 0.3037 - loss: 1.1408 - val_accuracy: 0.3086 - val_loss: 1.1574\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 494ms/step - accuracy: 0.3502 - loss: 1.1277 - val_accuracy: 0.3086 - val_loss: 1.1340\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 500ms/step - accuracy: 0.3634 - loss: 1.1344 - val_accuracy: 0.3086 - val_loss: 1.1408\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 491ms/step - accuracy: 0.3217 - loss: 1.1815 - val_accuracy: 0.3827 - val_loss: 1.1057\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 492ms/step - accuracy: 0.3431 - loss: 1.1287 - val_accuracy: 0.3827 - val_loss: 1.0954\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 569ms/step - accuracy: 0.3821 - loss: 1.0998 - val_accuracy: 0.3827 - val_loss: 1.1036\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 535ms/step - accuracy: 0.3076 - loss: 1.1243 - val_accuracy: 0.3827 - val_loss: 1.0945\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 520ms/step - accuracy: 0.3735 - loss: 1.1090 - val_accuracy: 0.3086 - val_loss: 1.1013\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 520ms/step - accuracy: 0.3932 - loss: 1.1010 - val_accuracy: 0.3827 - val_loss: 1.0941\n",
      "Fold 4 Accuracy: 38.27%\n",
      "Fold 4 Loss: 1.0941\n",
      "\n",
      "Fold 5\n",
      "Epoch 1/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 585ms/step - accuracy: 0.3535 - loss: 1.1941 - val_accuracy: 0.3333 - val_loss: 1.1333\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 489ms/step - accuracy: 0.3845 - loss: 1.1282 - val_accuracy: 0.3333 - val_loss: 1.1106\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 491ms/step - accuracy: 0.3618 - loss: 1.1108 - val_accuracy: 0.3333 - val_loss: 1.1313\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 491ms/step - accuracy: 0.3380 - loss: 1.1569 - val_accuracy: 0.3333 - val_loss: 1.1123\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 494ms/step - accuracy: 0.4056 - loss: 1.1071 - val_accuracy: 0.3333 - val_loss: 1.1139\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 521ms/step - accuracy: 0.2731 - loss: 1.1358 - val_accuracy: 0.3333 - val_loss: 1.1127\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 529ms/step - accuracy: 0.3518 - loss: 1.1082 - val_accuracy: 0.3333 - val_loss: 1.1025\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 535ms/step - accuracy: 0.3620 - loss: 1.0953 - val_accuracy: 0.3333 - val_loss: 1.1104\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 533ms/step - accuracy: 0.3805 - loss: 1.1024 - val_accuracy: 0.3333 - val_loss: 1.1084\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 502ms/step - accuracy: 0.3446 - loss: 1.1059 - val_accuracy: 0.3333 - val_loss: 1.1088\n",
      "Fold 5 Accuracy: 33.33%\n",
      "Fold 5 Loss: 1.1088\n",
      "Mean Accuracy: 36.43%, Mean Loss: 1.1045\n",
      "\n",
      "Testing batch_size=16, dropout=0.3, lr=0.001\n",
      "\n",
      "Fold 1\n",
      "Epoch 1/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 627ms/step - accuracy: 0.3498 - loss: 1.2229 - val_accuracy: 0.2439 - val_loss: 1.1142\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 534ms/step - accuracy: 0.3549 - loss: 1.1462 - val_accuracy: 0.2439 - val_loss: 1.2347\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 497ms/step - accuracy: 0.4339 - loss: 1.1236 - val_accuracy: 0.4634 - val_loss: 1.0697\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 502ms/step - accuracy: 0.3235 - loss: 1.1476 - val_accuracy: 0.4634 - val_loss: 1.0759\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 514ms/step - accuracy: 0.3611 - loss: 1.1535 - val_accuracy: 0.2439 - val_loss: 1.0951\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 539ms/step - accuracy: 0.3308 - loss: 1.1165 - val_accuracy: 0.4634 - val_loss: 1.0925\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 495ms/step - accuracy: 0.3065 - loss: 1.1231 - val_accuracy: 0.4634 - val_loss: 1.0795\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 496ms/step - accuracy: 0.3065 - loss: 1.1240 - val_accuracy: 0.2927 - val_loss: 1.0978\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 497ms/step - accuracy: 0.3803 - loss: 1.0955 - val_accuracy: 0.4634 - val_loss: 1.0833\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 500ms/step - accuracy: 0.2939 - loss: 1.1103 - val_accuracy: 0.4634 - val_loss: 1.0893\n",
      "Fold 1 Accuracy: 46.34%\n",
      "Fold 1 Loss: 1.0893\n",
      "\n",
      "Fold 2\n",
      "Epoch 1/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 599ms/step - accuracy: 0.2917 - loss: 1.2353 - val_accuracy: 0.3827 - val_loss: 1.2404\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 500ms/step - accuracy: 0.3307 - loss: 1.2387 - val_accuracy: 0.3827 - val_loss: 1.1919\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 516ms/step - accuracy: 0.3968 - loss: 1.1525 - val_accuracy: 0.3827 - val_loss: 1.1183\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 505ms/step - accuracy: 0.3393 - loss: 1.1522 - val_accuracy: 0.3827 - val_loss: 1.1329\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 539ms/step - accuracy: 0.3005 - loss: 1.1342 - val_accuracy: 0.3086 - val_loss: 1.0997\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 519ms/step - accuracy: 0.3610 - loss: 1.1187 - val_accuracy: 0.3827 - val_loss: 1.1035\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 497ms/step - accuracy: 0.3738 - loss: 1.1220 - val_accuracy: 0.3827 - val_loss: 1.0957\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 499ms/step - accuracy: 0.3475 - loss: 1.1089 - val_accuracy: 0.3827 - val_loss: 1.0952\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 500ms/step - accuracy: 0.3609 - loss: 1.1065 - val_accuracy: 0.3827 - val_loss: 1.1038\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 494ms/step - accuracy: 0.4012 - loss: 1.1126 - val_accuracy: 0.3827 - val_loss: 1.1013\n",
      "Fold 2 Accuracy: 38.27%\n",
      "Fold 2 Loss: 1.1013\n",
      "\n",
      "Fold 3\n",
      "Epoch 1/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 594ms/step - accuracy: 0.3667 - loss: 1.2687 - val_accuracy: 0.3333 - val_loss: 1.1869\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 499ms/step - accuracy: 0.3336 - loss: 1.1987 - val_accuracy: 0.2840 - val_loss: 1.2146\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 505ms/step - accuracy: 0.3175 - loss: 1.2089 - val_accuracy: 0.3827 - val_loss: 1.1084\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 514ms/step - accuracy: 0.3736 - loss: 1.1299 - val_accuracy: 0.3827 - val_loss: 1.0942\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 536ms/step - accuracy: 0.3337 - loss: 1.1238 - val_accuracy: 0.3333 - val_loss: 1.1112\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 500ms/step - accuracy: 0.2650 - loss: 1.1265 - val_accuracy: 0.3333 - val_loss: 1.1023\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 499ms/step - accuracy: 0.3342 - loss: 1.1043 - val_accuracy: 0.3333 - val_loss: 1.1344\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 500ms/step - accuracy: 0.3955 - loss: 1.1045 - val_accuracy: 0.3333 - val_loss: 1.1038\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 499ms/step - accuracy: 0.4285 - loss: 1.0871 - val_accuracy: 0.3333 - val_loss: 1.0969\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 505ms/step - accuracy: 0.3013 - loss: 1.1075 - val_accuracy: 0.3333 - val_loss: 1.1097\n",
      "Fold 3 Accuracy: 33.33%\n",
      "Fold 3 Loss: 1.1097\n",
      "\n",
      "Fold 4\n",
      "Epoch 1/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 607ms/step - accuracy: 0.3446 - loss: 1.2740 - val_accuracy: 0.3827 - val_loss: 1.1805\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 507ms/step - accuracy: 0.2581 - loss: 1.2313 - val_accuracy: 0.3086 - val_loss: 1.1421\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 507ms/step - accuracy: 0.2966 - loss: 1.1262 - val_accuracy: 0.3086 - val_loss: 1.1139\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 544ms/step - accuracy: 0.3828 - loss: 1.1090 - val_accuracy: 0.3827 - val_loss: 1.0939\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 514ms/step - accuracy: 0.3220 - loss: 1.1294 - val_accuracy: 0.3827 - val_loss: 1.1063\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 496ms/step - accuracy: 0.3802 - loss: 1.1164 - val_accuracy: 0.3086 - val_loss: 1.1182\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 502ms/step - accuracy: 0.2720 - loss: 1.1386 - val_accuracy: 0.3827 - val_loss: 1.1004\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 519ms/step - accuracy: 0.3705 - loss: 1.1062 - val_accuracy: 0.3827 - val_loss: 1.1008\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 503ms/step - accuracy: 0.3279 - loss: 1.1234 - val_accuracy: 0.3827 - val_loss: 1.0969\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 500ms/step - accuracy: 0.3842 - loss: 1.1016 - val_accuracy: 0.3827 - val_loss: 1.0969\n",
      "Fold 4 Accuracy: 38.27%\n",
      "Fold 4 Loss: 1.0969\n",
      "\n",
      "Fold 5\n",
      "Epoch 1/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 600ms/step - accuracy: 0.3700 - loss: 1.2047 - val_accuracy: 0.3333 - val_loss: 1.1427\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 500ms/step - accuracy: 0.4067 - loss: 1.1399 - val_accuracy: 0.3333 - val_loss: 1.1405\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 519ms/step - accuracy: 0.3657 - loss: 1.1193 - val_accuracy: 0.3333 - val_loss: 1.1138\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 535ms/step - accuracy: 0.3887 - loss: 1.1153 - val_accuracy: 0.3333 - val_loss: 1.1034\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 516ms/step - accuracy: 0.3882 - loss: 1.1056 - val_accuracy: 0.3333 - val_loss: 1.1152\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 503ms/step - accuracy: 0.3824 - loss: 1.1020 - val_accuracy: 0.3333 - val_loss: 1.1052\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 513ms/step - accuracy: 0.3177 - loss: 1.1249 - val_accuracy: 0.3333 - val_loss: 1.1113\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 511ms/step - accuracy: 0.3814 - loss: 1.1085 - val_accuracy: 0.3333 - val_loss: 1.1004\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 503ms/step - accuracy: 0.4343 - loss: 1.0825 - val_accuracy: 0.3333 - val_loss: 1.1045\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 503ms/step - accuracy: 0.3932 - loss: 1.0846 - val_accuracy: 0.3333 - val_loss: 1.1072\n",
      "Fold 5 Accuracy: 33.33%\n",
      "Fold 5 Loss: 1.1072\n",
      "Mean Accuracy: 37.91%, Mean Loss: 1.1009\n",
      "\n",
      "Testing batch_size=16, dropout=0.5, lr=0.0005\n",
      "\n",
      "Fold 1\n",
      "Epoch 1/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 600ms/step - accuracy: 0.3118 - loss: 1.1804 - val_accuracy: 0.4634 - val_loss: 1.0624\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 509ms/step - accuracy: 0.3656 - loss: 1.1217 - val_accuracy: 0.4634 - val_loss: 1.0891\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 537ms/step - accuracy: 0.3453 - loss: 1.1313 - val_accuracy: 0.4634 - val_loss: 1.1031\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 504ms/step - accuracy: 0.3454 - loss: 1.1412 - val_accuracy: 0.4634 - val_loss: 1.0675\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 499ms/step - accuracy: 0.3526 - loss: 1.1050 - val_accuracy: 0.2439 - val_loss: 1.1224\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 500ms/step - accuracy: 0.3309 - loss: 1.1174 - val_accuracy: 0.4634 - val_loss: 1.0721\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 500ms/step - accuracy: 0.3372 - loss: 1.1223 - val_accuracy: 0.2927 - val_loss: 1.0988\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 504ms/step - accuracy: 0.3236 - loss: 1.1129 - val_accuracy: 0.2927 - val_loss: 1.0996\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 499ms/step - accuracy: 0.3138 - loss: 1.1060 - val_accuracy: 0.2927 - val_loss: 1.0915\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 497ms/step - accuracy: 0.4109 - loss: 1.1005 - val_accuracy: 0.4634 - val_loss: 1.0846\n",
      "Fold 1 Accuracy: 46.34%\n",
      "Fold 1 Loss: 1.0846\n",
      "\n",
      "Fold 2\n",
      "Epoch 1/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 590ms/step - accuracy: 0.3782 - loss: 1.1251 - val_accuracy: 0.3827 - val_loss: 1.1124\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 516ms/step - accuracy: 0.3577 - loss: 1.1273 - val_accuracy: 0.3827 - val_loss: 1.0957\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 527ms/step - accuracy: 0.3275 - loss: 1.1559 - val_accuracy: 0.3827 - val_loss: 1.1260\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 499ms/step - accuracy: 0.3779 - loss: 1.1516 - val_accuracy: 0.3086 - val_loss: 1.1110\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 496ms/step - accuracy: 0.3219 - loss: 1.1111 - val_accuracy: 0.3086 - val_loss: 1.1144\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 495ms/step - accuracy: 0.2955 - loss: 1.1652 - val_accuracy: 0.3827 - val_loss: 1.1008\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 495ms/step - accuracy: 0.3840 - loss: 1.1395 - val_accuracy: 0.3086 - val_loss: 1.1340\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 496ms/step - accuracy: 0.3095 - loss: 1.1525 - val_accuracy: 0.3086 - val_loss: 1.1026\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 494ms/step - accuracy: 0.3706 - loss: 1.0983 - val_accuracy: 0.3827 - val_loss: 1.0960\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 495ms/step - accuracy: 0.3841 - loss: 1.1088 - val_accuracy: 0.3827 - val_loss: 1.0953\n",
      "Fold 2 Accuracy: 38.27%\n",
      "Fold 2 Loss: 1.0953\n",
      "\n",
      "Fold 3\n",
      "Epoch 1/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 594ms/step - accuracy: 0.3758 - loss: 1.1505 - val_accuracy: 0.3333 - val_loss: 1.1592\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 544ms/step - accuracy: 0.3656 - loss: 1.1854 - val_accuracy: 0.3333 - val_loss: 1.1012\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 505ms/step - accuracy: 0.3557 - loss: 1.1212 - val_accuracy: 0.3333 - val_loss: 1.1474\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 498ms/step - accuracy: 0.3104 - loss: 1.1710 - val_accuracy: 0.3333 - val_loss: 1.1030\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 498ms/step - accuracy: 0.3087 - loss: 1.1520 - val_accuracy: 0.3333 - val_loss: 1.1447\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 496ms/step - accuracy: 0.3713 - loss: 1.1597 - val_accuracy: 0.3827 - val_loss: 1.0921\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 499ms/step - accuracy: 0.2928 - loss: 1.1323 - val_accuracy: 0.3333 - val_loss: 1.1130\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 497ms/step - accuracy: 0.3965 - loss: 1.0968 - val_accuracy: 0.3333 - val_loss: 1.1008\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 546ms/step - accuracy: 0.3513 - loss: 1.1090 - val_accuracy: 0.3333 - val_loss: 1.0975\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 514ms/step - accuracy: 0.3434 - loss: 1.1074 - val_accuracy: 0.3333 - val_loss: 1.1048\n",
      "Fold 3 Accuracy: 33.33%\n",
      "Fold 3 Loss: 1.1048\n",
      "\n",
      "Fold 4\n",
      "Epoch 1/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 636ms/step - accuracy: 0.3970 - loss: 1.1409 - val_accuracy: 0.3086 - val_loss: 1.1161\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 513ms/step - accuracy: 0.3198 - loss: 1.1391 - val_accuracy: 0.3086 - val_loss: 1.1298\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 514ms/step - accuracy: 0.3330 - loss: 1.1477 - val_accuracy: 0.3827 - val_loss: 1.1088\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 523ms/step - accuracy: 0.3183 - loss: 1.1302 - val_accuracy: 0.3827 - val_loss: 1.0940\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 503ms/step - accuracy: 0.3233 - loss: 1.1223 - val_accuracy: 0.3827 - val_loss: 1.0958\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 499ms/step - accuracy: 0.3257 - loss: 1.1011 - val_accuracy: 0.3086 - val_loss: 1.1007\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 499ms/step - accuracy: 0.3840 - loss: 1.1097 - val_accuracy: 0.3827 - val_loss: 1.0967\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 504ms/step - accuracy: 0.3063 - loss: 1.1233 - val_accuracy: 0.3827 - val_loss: 1.0954\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 499ms/step - accuracy: 0.3739 - loss: 1.1096 - val_accuracy: 0.3827 - val_loss: 1.0948\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 539ms/step - accuracy: 0.3386 - loss: 1.1079 - val_accuracy: 0.3827 - val_loss: 1.0946\n",
      "Fold 4 Accuracy: 38.27%\n",
      "Fold 4 Loss: 1.0946\n",
      "\n",
      "Fold 5\n",
      "Epoch 1/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 596ms/step - accuracy: 0.3224 - loss: 1.2001 - val_accuracy: 0.3333 - val_loss: 1.1582\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 503ms/step - accuracy: 0.4186 - loss: 1.1122 - val_accuracy: 0.3333 - val_loss: 1.1057\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 504ms/step - accuracy: 0.3428 - loss: 1.1336 - val_accuracy: 0.3333 - val_loss: 1.1027\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 505ms/step - accuracy: 0.3485 - loss: 1.1218 - val_accuracy: 0.3333 - val_loss: 1.1011\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 570ms/step - accuracy: 0.3482 - loss: 1.0960 - val_accuracy: 0.3333 - val_loss: 1.1346\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 514ms/step - accuracy: 0.3798 - loss: 1.1301 - val_accuracy: 0.3333 - val_loss: 1.1068\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 500ms/step - accuracy: 0.3249 - loss: 1.1154 - val_accuracy: 0.3333 - val_loss: 1.1227\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 506ms/step - accuracy: 0.3124 - loss: 1.1167 - val_accuracy: 0.3333 - val_loss: 1.1065\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 527ms/step - accuracy: 0.3652 - loss: 1.1055 - val_accuracy: 0.3333 - val_loss: 1.1054\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 527ms/step - accuracy: 0.3391 - loss: 1.1133 - val_accuracy: 0.3333 - val_loss: 1.1069\n",
      "Fold 5 Accuracy: 33.33%\n",
      "Fold 5 Loss: 1.1069\n",
      "Mean Accuracy: 37.91%, Mean Loss: 1.0973\n",
      "\n",
      "Testing batch_size=16, dropout=0.5, lr=0.001\n",
      "\n",
      "Fold 1\n",
      "Epoch 1/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 671ms/step - accuracy: 0.3658 - loss: 1.2548 - val_accuracy: 0.2927 - val_loss: 1.2022\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 525ms/step - accuracy: 0.3331 - loss: 1.1755 - val_accuracy: 0.2927 - val_loss: 1.1224\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 524ms/step - accuracy: 0.3194 - loss: 1.1677 - val_accuracy: 0.2927 - val_loss: 1.0934\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 536ms/step - accuracy: 0.3004 - loss: 1.1194 - val_accuracy: 0.4634 - val_loss: 1.0759\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 537ms/step - accuracy: 0.3545 - loss: 1.1073 - val_accuracy: 0.2439 - val_loss: 1.1150\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 523ms/step - accuracy: 0.3069 - loss: 1.1072 - val_accuracy: 0.2927 - val_loss: 1.0882\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 524ms/step - accuracy: 0.3312 - loss: 1.1098 - val_accuracy: 0.4634 - val_loss: 1.0836\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 550ms/step - accuracy: 0.3247 - loss: 1.1216 - val_accuracy: 0.4634 - val_loss: 1.0887\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 538ms/step - accuracy: 0.3584 - loss: 1.0992 - val_accuracy: 0.4634 - val_loss: 1.0850\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 535ms/step - accuracy: 0.3778 - loss: 1.0950 - val_accuracy: 0.4634 - val_loss: 1.0813\n",
      "Fold 1 Accuracy: 46.34%\n",
      "Fold 1 Loss: 1.0813\n",
      "\n",
      "Fold 2\n",
      "Epoch 1/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 612ms/step - accuracy: 0.3705 - loss: 1.2127 - val_accuracy: 0.3827 - val_loss: 1.1059\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 512ms/step - accuracy: 0.3660 - loss: 1.1637 - val_accuracy: 0.3827 - val_loss: 1.1320\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 511ms/step - accuracy: 0.3338 - loss: 1.1740 - val_accuracy: 0.3086 - val_loss: 1.1111\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 524ms/step - accuracy: 0.3699 - loss: 1.1234 - val_accuracy: 0.3827 - val_loss: 1.0949\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 513ms/step - accuracy: 0.2655 - loss: 1.1761 - val_accuracy: 0.3827 - val_loss: 1.1003\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 509ms/step - accuracy: 0.3927 - loss: 1.1069 - val_accuracy: 0.3827 - val_loss: 1.0949\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 532ms/step - accuracy: 0.3753 - loss: 1.0874 - val_accuracy: 0.3827 - val_loss: 1.0994\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 545ms/step - accuracy: 0.3677 - loss: 1.1056 - val_accuracy: 0.3827 - val_loss: 1.0980\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 510ms/step - accuracy: 0.3670 - loss: 1.0998 - val_accuracy: 0.3827 - val_loss: 1.0940\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 514ms/step - accuracy: 0.3468 - loss: 1.1080 - val_accuracy: 0.3827 - val_loss: 1.0936\n",
      "Fold 2 Accuracy: 38.27%\n",
      "Fold 2 Loss: 1.0936\n",
      "\n",
      "Fold 3\n",
      "Epoch 1/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 600ms/step - accuracy: 0.3182 - loss: 1.2043 - val_accuracy: 0.3333 - val_loss: 1.0975\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 513ms/step - accuracy: 0.3522 - loss: 1.1743 - val_accuracy: 0.3333 - val_loss: 1.1743\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 509ms/step - accuracy: 0.3478 - loss: 1.1978 - val_accuracy: 0.3333 - val_loss: 1.1195\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 512ms/step - accuracy: 0.3420 - loss: 1.1437 - val_accuracy: 0.3333 - val_loss: 1.1252\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 512ms/step - accuracy: 0.3044 - loss: 1.1214 - val_accuracy: 0.3333 - val_loss: 1.0974\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 507ms/step - accuracy: 0.3462 - loss: 1.1121 - val_accuracy: 0.3333 - val_loss: 1.1149\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 550ms/step - accuracy: 0.3870 - loss: 1.1153 - val_accuracy: 0.3333 - val_loss: 1.0983\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 519ms/step - accuracy: 0.2931 - loss: 1.1274 - val_accuracy: 0.3333 - val_loss: 1.0993\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 518ms/step - accuracy: 0.3648 - loss: 1.0978 - val_accuracy: 0.3333 - val_loss: 1.1057\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 509ms/step - accuracy: 0.3788 - loss: 1.0966 - val_accuracy: 0.3333 - val_loss: 1.1095\n",
      "Fold 3 Accuracy: 33.33%\n",
      "Fold 3 Loss: 1.1095\n",
      "\n",
      "Fold 4\n",
      "Epoch 1/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 612ms/step - accuracy: 0.2839 - loss: 1.2799 - val_accuracy: 0.3086 - val_loss: 1.1344\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 518ms/step - accuracy: 0.3215 - loss: 1.1952 - val_accuracy: 0.3086 - val_loss: 1.1147\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 512ms/step - accuracy: 0.3029 - loss: 1.1648 - val_accuracy: 0.3827 - val_loss: 1.1173\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 519ms/step - accuracy: 0.4317 - loss: 1.0822 - val_accuracy: 0.4198 - val_loss: 1.1070\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 515ms/step - accuracy: 0.3453 - loss: 1.1317 - val_accuracy: 0.3827 - val_loss: 1.0975\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 556ms/step - accuracy: 0.3743 - loss: 1.0959 - val_accuracy: 0.3827 - val_loss: 1.0956\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 523ms/step - accuracy: 0.3593 - loss: 1.0971 - val_accuracy: 0.3827 - val_loss: 1.0948\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 513ms/step - accuracy: 0.3926 - loss: 1.0944 - val_accuracy: 0.3086 - val_loss: 1.0976\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 514ms/step - accuracy: 0.3424 - loss: 1.1081 - val_accuracy: 0.3827 - val_loss: 1.0957\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 516ms/step - accuracy: 0.3725 - loss: 1.0860 - val_accuracy: 0.3827 - val_loss: 1.0939\n",
      "Fold 4 Accuracy: 38.27%\n",
      "Fold 4 Loss: 1.0939\n",
      "\n",
      "Fold 5\n",
      "Epoch 1/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 624ms/step - accuracy: 0.3532 - loss: 1.1888 - val_accuracy: 0.3333 - val_loss: 1.1426\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 532ms/step - accuracy: 0.3519 - loss: 1.1675 - val_accuracy: 0.3333 - val_loss: 1.1327\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 536ms/step - accuracy: 0.3736 - loss: 1.1287 - val_accuracy: 0.3333 - val_loss: 1.1466\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 526ms/step - accuracy: 0.3192 - loss: 1.1806 - val_accuracy: 0.3333 - val_loss: 1.1264\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 569ms/step - accuracy: 0.3552 - loss: 1.1232 - val_accuracy: 0.3333 - val_loss: 1.1015\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 527ms/step - accuracy: 0.3474 - loss: 1.1127 - val_accuracy: 0.3333 - val_loss: 1.1074\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 528ms/step - accuracy: 0.3500 - loss: 1.1201 - val_accuracy: 0.3333 - val_loss: 1.1255\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 530ms/step - accuracy: 0.4009 - loss: 1.1044 - val_accuracy: 0.3333 - val_loss: 1.1056\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 529ms/step - accuracy: 0.4071 - loss: 1.0815 - val_accuracy: 0.3333 - val_loss: 1.1110\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 525ms/step - accuracy: 0.4132 - loss: 1.1052 - val_accuracy: 0.3333 - val_loss: 1.1172\n",
      "Fold 5 Accuracy: 33.33%\n",
      "Fold 5 Loss: 1.1172\n",
      "Mean Accuracy: 37.91%, Mean Loss: 1.0991\n",
      "\n",
      "Testing batch_size=32, dropout=0.3, lr=0.0005\n",
      "\n",
      "Fold 1\n",
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1s/step - accuracy: 0.3351 - loss: 1.1263 - val_accuracy: 0.4634 - val_loss: 1.0653\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 993ms/step - accuracy: 0.3462 - loss: 1.1370 - val_accuracy: 0.2439 - val_loss: 1.1221\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 980ms/step - accuracy: 0.3833 - loss: 1.1519 - val_accuracy: 0.4634 - val_loss: 1.0783\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.3572 - loss: 1.1561 - val_accuracy: 0.2439 - val_loss: 1.1470\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.3182 - loss: 1.1286 - val_accuracy: 0.4634 - val_loss: 1.0707\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 977ms/step - accuracy: 0.2882 - loss: 1.1196 - val_accuracy: 0.2927 - val_loss: 1.0878\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 982ms/step - accuracy: 0.2884 - loss: 1.1211 - val_accuracy: 0.4146 - val_loss: 1.0850\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 982ms/step - accuracy: 0.3390 - loss: 1.1212 - val_accuracy: 0.4634 - val_loss: 1.0898\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 976ms/step - accuracy: 0.3340 - loss: 1.1007 - val_accuracy: 0.4634 - val_loss: 1.0840\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 980ms/step - accuracy: 0.3104 - loss: 1.1243 - val_accuracy: 0.4634 - val_loss: 1.0782\n",
      "Fold 1 Accuracy: 46.34%\n",
      "Fold 1 Loss: 1.0782\n",
      "\n",
      "Fold 2\n",
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1s/step - accuracy: 0.3683 - loss: 1.1178 - val_accuracy: 0.3827 - val_loss: 1.1010\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 997ms/step - accuracy: 0.3652 - loss: 1.1155 - val_accuracy: 0.3086 - val_loss: 1.1108\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.3665 - loss: 1.1298 - val_accuracy: 0.3086 - val_loss: 1.1456\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.2653 - loss: 1.1966 - val_accuracy: 0.3827 - val_loss: 1.1239\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 987ms/step - accuracy: 0.3986 - loss: 1.1404 - val_accuracy: 0.3086 - val_loss: 1.1045\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.3328 - loss: 1.1276 - val_accuracy: 0.3827 - val_loss: 1.0956\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 986ms/step - accuracy: 0.3444 - loss: 1.1196 - val_accuracy: 0.3827 - val_loss: 1.0995\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 985ms/step - accuracy: 0.3957 - loss: 1.0992 - val_accuracy: 0.3086 - val_loss: 1.1063\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.3417 - loss: 1.1401 - val_accuracy: 0.3827 - val_loss: 1.1022\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 996ms/step - accuracy: 0.3614 - loss: 1.1326 - val_accuracy: 0.3827 - val_loss: 1.0941\n",
      "Fold 2 Accuracy: 38.27%\n",
      "Fold 2 Loss: 1.0941\n",
      "\n",
      "Fold 3\n",
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1s/step - accuracy: 0.3112 - loss: 1.1712 - val_accuracy: 0.3333 - val_loss: 1.2400\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.3847 - loss: 1.1546 - val_accuracy: 0.3827 - val_loss: 1.0935\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.3076 - loss: 1.1216 - val_accuracy: 0.3333 - val_loss: 1.1499\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.4193 - loss: 1.0970 - val_accuracy: 0.3827 - val_loss: 1.0916\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 995ms/step - accuracy: 0.3050 - loss: 1.1315 - val_accuracy: 0.3333 - val_loss: 1.1230\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.4075 - loss: 1.1018 - val_accuracy: 0.2840 - val_loss: 1.1145\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 989ms/step - accuracy: 0.3516 - loss: 1.1144 - val_accuracy: 0.3333 - val_loss: 1.1124\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 992ms/step - accuracy: 0.3625 - loss: 1.1169 - val_accuracy: 0.3333 - val_loss: 1.1091\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 999ms/step - accuracy: 0.3565 - loss: 1.1220 - val_accuracy: 0.3333 - val_loss: 1.1143\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 989ms/step - accuracy: 0.3530 - loss: 1.1085 - val_accuracy: 0.3333 - val_loss: 1.1008\n",
      "Fold 3 Accuracy: 33.33%\n",
      "Fold 3 Loss: 1.1008\n",
      "\n",
      "Fold 4\n",
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1s/step - accuracy: 0.3233 - loss: 1.1434 - val_accuracy: 0.3827 - val_loss: 1.1190\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.3444 - loss: 1.1384 - val_accuracy: 0.3827 - val_loss: 1.1077\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.3623 - loss: 1.0823 - val_accuracy: 0.3086 - val_loss: 1.1292\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.3006 - loss: 1.1596 - val_accuracy: 0.3827 - val_loss: 1.1043\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.3668 - loss: 1.1108 - val_accuracy: 0.3827 - val_loss: 1.0933\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 998ms/step - accuracy: 0.3685 - loss: 1.1309 - val_accuracy: 0.3086 - val_loss: 1.1011\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 999ms/step - accuracy: 0.3269 - loss: 1.1352 - val_accuracy: 0.3827 - val_loss: 1.0964\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.3358 - loss: 1.1140 - val_accuracy: 0.3827 - val_loss: 1.0944\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.3986 - loss: 1.1058 - val_accuracy: 0.3827 - val_loss: 1.0968\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 998ms/step - accuracy: 0.3582 - loss: 1.1080 - val_accuracy: 0.3827 - val_loss: 1.0982\n",
      "Fold 4 Accuracy: 38.27%\n",
      "Fold 4 Loss: 1.0982\n",
      "\n",
      "Fold 5\n",
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 0.3824 - loss: 1.1926 - val_accuracy: 0.3333 - val_loss: 1.2211\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.2824 - loss: 1.2081 - val_accuracy: 0.3333 - val_loss: 1.1957\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.4031 - loss: 1.1208 - val_accuracy: 0.3333 - val_loss: 1.1186\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.3278 - loss: 1.1172 - val_accuracy: 0.3333 - val_loss: 1.1187\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.3149 - loss: 1.1279 - val_accuracy: 0.3333 - val_loss: 1.1145\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.3879 - loss: 1.0738 - val_accuracy: 0.3333 - val_loss: 1.1014\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.4054 - loss: 1.1109 - val_accuracy: 0.3333 - val_loss: 1.0991\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.3606 - loss: 1.1088 - val_accuracy: 0.3333 - val_loss: 1.1331\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.3931 - loss: 1.0901 - val_accuracy: 0.3333 - val_loss: 1.1048\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.4381 - loss: 1.0813 - val_accuracy: 0.3333 - val_loss: 1.0992\n",
      "Fold 5 Accuracy: 33.33%\n",
      "Fold 5 Loss: 1.0992\n",
      "Mean Accuracy: 37.91%, Mean Loss: 1.0941\n",
      "\n",
      "Testing batch_size=32, dropout=0.3, lr=0.001\n",
      "\n",
      "Fold 1\n",
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 0.3492 - loss: 1.2785 - val_accuracy: 0.2927 - val_loss: 1.3706\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.3189 - loss: 1.2378 - val_accuracy: 0.2927 - val_loss: 1.1082\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.3504 - loss: 1.2222 - val_accuracy: 0.4634 - val_loss: 1.1564\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 998ms/step - accuracy: 0.3608 - loss: 1.1908 - val_accuracy: 0.2927 - val_loss: 1.2179\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.3786 - loss: 1.1600 - val_accuracy: 0.4634 - val_loss: 1.1242\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1000ms/step - accuracy: 0.3243 - loss: 1.1635 - val_accuracy: 0.2927 - val_loss: 1.1258\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.3305 - loss: 1.1419 - val_accuracy: 0.4634 - val_loss: 1.0788\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.3437 - loss: 1.1209 - val_accuracy: 0.4634 - val_loss: 1.0717\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1000ms/step - accuracy: 0.3763 - loss: 1.1076 - val_accuracy: 0.2439 - val_loss: 1.1144\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.3414 - loss: 1.1152 - val_accuracy: 0.2927 - val_loss: 1.1009\n",
      "Fold 1 Accuracy: 29.27%\n",
      "Fold 1 Loss: 1.1009\n",
      "\n",
      "Fold 2\n",
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 0.3091 - loss: 1.1530 - val_accuracy: 0.3827 - val_loss: 1.1349\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.3529 - loss: 1.1641 - val_accuracy: 0.3827 - val_loss: 1.1580\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.3583 - loss: 1.1795 - val_accuracy: 0.3086 - val_loss: 1.1181\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.3078 - loss: 1.1574 - val_accuracy: 0.3086 - val_loss: 1.1383\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.3605 - loss: 1.1228 - val_accuracy: 0.3827 - val_loss: 1.1056\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.3315 - loss: 1.1382 - val_accuracy: 0.3827 - val_loss: 1.0982\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.3713 - loss: 1.1010 - val_accuracy: 0.3086 - val_loss: 1.1138\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.3698 - loss: 1.1312 - val_accuracy: 0.3827 - val_loss: 1.1034\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.3555 - loss: 1.1563 - val_accuracy: 0.3827 - val_loss: 1.0932\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.3524 - loss: 1.1086 - val_accuracy: 0.3827 - val_loss: 1.1116\n",
      "Fold 2 Accuracy: 38.27%\n",
      "Fold 2 Loss: 1.1116\n",
      "\n",
      "Fold 3\n",
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 0.3311 - loss: 1.2618 - val_accuracy: 0.3333 - val_loss: 1.3794\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.4048 - loss: 1.1633 - val_accuracy: 0.3827 - val_loss: 1.1017\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.2936 - loss: 1.1337 - val_accuracy: 0.3333 - val_loss: 1.1093\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.3362 - loss: 1.1286 - val_accuracy: 0.3333 - val_loss: 1.1388\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.3684 - loss: 1.1548 - val_accuracy: 0.3333 - val_loss: 1.1188\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.3221 - loss: 1.1299 - val_accuracy: 0.3333 - val_loss: 1.0963\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.3198 - loss: 1.0991 - val_accuracy: 0.2840 - val_loss: 1.1307\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.3072 - loss: 1.1466 - val_accuracy: 0.3333 - val_loss: 1.1190\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.3720 - loss: 1.1321 - val_accuracy: 0.3333 - val_loss: 1.1073\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.3550 - loss: 1.1029 - val_accuracy: 0.3333 - val_loss: 1.0995\n",
      "Fold 3 Accuracy: 33.33%\n",
      "Fold 3 Loss: 1.0995\n",
      "\n",
      "Fold 4\n",
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 0.2855 - loss: 1.3564 - val_accuracy: 0.3827 - val_loss: 1.1795\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.3816 - loss: 1.1520 - val_accuracy: 0.3086 - val_loss: 1.1277\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.2980 - loss: 1.1537 - val_accuracy: 0.3086 - val_loss: 1.1003\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.3360 - loss: 1.1046 - val_accuracy: 0.3827 - val_loss: 1.0976\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.4015 - loss: 1.1052 - val_accuracy: 0.3827 - val_loss: 1.0944\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.3370 - loss: 1.1089 - val_accuracy: 0.4198 - val_loss: 1.1027\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.3078 - loss: 1.1229 - val_accuracy: 0.3827 - val_loss: 1.0946\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.3617 - loss: 1.1205 - val_accuracy: 0.3827 - val_loss: 1.0934\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.3451 - loss: 1.1212 - val_accuracy: 0.3086 - val_loss: 1.1045\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.3923 - loss: 1.0946 - val_accuracy: 0.3827 - val_loss: 1.0932\n",
      "Fold 4 Accuracy: 38.27%\n",
      "Fold 4 Loss: 1.0932\n",
      "\n",
      "Fold 5\n",
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - accuracy: 0.2951 - loss: 1.3413 - val_accuracy: 0.3333 - val_loss: 1.1177\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.3302 - loss: 1.1596 - val_accuracy: 0.3333 - val_loss: 1.1753\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.3438 - loss: 1.1146 - val_accuracy: 0.3333 - val_loss: 1.1092\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.3778 - loss: 1.1282 - val_accuracy: 0.3333 - val_loss: 1.1075\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.3763 - loss: 1.1202 - val_accuracy: 0.3333 - val_loss: 1.1260\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.3659 - loss: 1.1135 - val_accuracy: 0.3333 - val_loss: 1.0991\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.3169 - loss: 1.1461 - val_accuracy: 0.3333 - val_loss: 1.1170\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.3580 - loss: 1.1189 - val_accuracy: 0.3333 - val_loss: 1.1159\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.3337 - loss: 1.1030 - val_accuracy: 0.3333 - val_loss: 1.1072\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.4018 - loss: 1.1027 - val_accuracy: 0.3333 - val_loss: 1.1129\n",
      "Fold 5 Accuracy: 33.33%\n",
      "Fold 5 Loss: 1.1129\n",
      "Mean Accuracy: 34.50%, Mean Loss: 1.1036\n",
      "\n",
      "Testing batch_size=32, dropout=0.5, lr=0.0005\n",
      "\n",
      "Fold 1\n",
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 0.3277 - loss: 1.1288 - val_accuracy: 0.2439 - val_loss: 1.1216\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.2778 - loss: 1.1824 - val_accuracy: 0.2927 - val_loss: 1.0914\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.3180 - loss: 1.1482 - val_accuracy: 0.4634 - val_loss: 1.0972\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.2933 - loss: 1.1228 - val_accuracy: 0.2927 - val_loss: 1.0836\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.3066 - loss: 1.1519 - val_accuracy: 0.2439 - val_loss: 1.1106\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.3528 - loss: 1.1228 - val_accuracy: 0.4634 - val_loss: 1.0703\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.3891 - loss: 1.1022 - val_accuracy: 0.4634 - val_loss: 1.0866\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.3363 - loss: 1.1230 - val_accuracy: 0.4634 - val_loss: 1.0692\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.3489 - loss: 1.1384 - val_accuracy: 0.4634 - val_loss: 1.0745\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.3539 - loss: 1.1059 - val_accuracy: 0.4634 - val_loss: 1.0889\n",
      "Fold 1 Accuracy: 46.34%\n",
      "Fold 1 Loss: 1.0889\n",
      "\n",
      "Fold 2\n",
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 0.3242 - loss: 1.1464 - val_accuracy: 0.3827 - val_loss: 1.1756\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.3521 - loss: 1.1911 - val_accuracy: 0.3086 - val_loss: 1.1221\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.3203 - loss: 1.1979 - val_accuracy: 0.3827 - val_loss: 1.1482\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.3842 - loss: 1.2301 - val_accuracy: 0.3086 - val_loss: 1.1332\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.3154 - loss: 1.1764 - val_accuracy: 0.3827 - val_loss: 1.1032\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.3795 - loss: 1.1330 - val_accuracy: 0.3333 - val_loss: 1.0972\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.3241 - loss: 1.1230 - val_accuracy: 0.3086 - val_loss: 1.1043\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.2989 - loss: 1.1300 - val_accuracy: 0.3086 - val_loss: 1.1000\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.3613 - loss: 1.1083 - val_accuracy: 0.3827 - val_loss: 1.0939\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.3593 - loss: 1.1385 - val_accuracy: 0.3827 - val_loss: 1.0969\n",
      "Fold 2 Accuracy: 38.27%\n",
      "Fold 2 Loss: 1.0969\n",
      "\n",
      "Fold 3\n",
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 0.2801 - loss: 1.2106 - val_accuracy: 0.2840 - val_loss: 1.1062\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.2742 - loss: 1.1628 - val_accuracy: 0.3333 - val_loss: 1.1662\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.3617 - loss: 1.1587 - val_accuracy: 0.3827 - val_loss: 1.0973\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.3874 - loss: 1.1086 - val_accuracy: 0.3333 - val_loss: 1.1188\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.3739 - loss: 1.0962 - val_accuracy: 0.3333 - val_loss: 1.1021\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.2913 - loss: 1.1441 - val_accuracy: 0.3333 - val_loss: 1.1111\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.3653 - loss: 1.1187 - val_accuracy: 0.3333 - val_loss: 1.0991\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.3823 - loss: 1.1132 - val_accuracy: 0.3333 - val_loss: 1.0960\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.2999 - loss: 1.1107 - val_accuracy: 0.3333 - val_loss: 1.1203\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.3754 - loss: 1.1220 - val_accuracy: 0.3333 - val_loss: 1.1127\n",
      "Fold 3 Accuracy: 33.33%\n",
      "Fold 3 Loss: 1.1127\n",
      "\n",
      "Fold 4\n",
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 0.3386 - loss: 1.1891 - val_accuracy: 0.3086 - val_loss: 1.1725\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.3108 - loss: 1.1828 - val_accuracy: 0.3827 - val_loss: 1.1262\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.3164 - loss: 1.1515 - val_accuracy: 0.3827 - val_loss: 1.0965\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.3672 - loss: 1.1187 - val_accuracy: 0.3827 - val_loss: 1.0937\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.3687 - loss: 1.1347 - val_accuracy: 0.3086 - val_loss: 1.1149\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.3364 - loss: 1.1342 - val_accuracy: 0.3827 - val_loss: 1.0948\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.4028 - loss: 1.0985 - val_accuracy: 0.3827 - val_loss: 1.0985\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.3353 - loss: 1.1284 - val_accuracy: 0.3827 - val_loss: 1.0970\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.3652 - loss: 1.1130 - val_accuracy: 0.3827 - val_loss: 1.0947\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.3414 - loss: 1.1036 - val_accuracy: 0.3086 - val_loss: 1.1045\n",
      "Fold 4 Accuracy: 30.86%\n",
      "Fold 4 Loss: 1.1045\n",
      "\n",
      "Fold 5\n",
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 0.3627 - loss: 1.1926 - val_accuracy: 0.3333 - val_loss: 1.1208\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.3725 - loss: 1.1405 - val_accuracy: 0.3333 - val_loss: 1.1109\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.3399 - loss: 1.1509 - val_accuracy: 0.3333 - val_loss: 1.1256\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.3674 - loss: 1.1133 - val_accuracy: 0.3210 - val_loss: 1.0987\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.2690 - loss: 1.1634 - val_accuracy: 0.3333 - val_loss: 1.1065\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.3098 - loss: 1.1312 - val_accuracy: 0.3333 - val_loss: 1.1177\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.3788 - loss: 1.1289 - val_accuracy: 0.3333 - val_loss: 1.1176\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.3931 - loss: 1.0978 - val_accuracy: 0.3333 - val_loss: 1.1015\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.3609 - loss: 1.1205 - val_accuracy: 0.3333 - val_loss: 1.1165\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.2928 - loss: 1.1502 - val_accuracy: 0.3333 - val_loss: 1.1050\n",
      "Fold 5 Accuracy: 33.33%\n",
      "Fold 5 Loss: 1.1050\n",
      "Mean Accuracy: 36.43%, Mean Loss: 1.1016\n",
      "\n",
      "Testing batch_size=32, dropout=0.5, lr=0.001\n",
      "\n",
      "Fold 1\n",
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - accuracy: 0.2905 - loss: 1.2155 - val_accuracy: 0.2927 - val_loss: 1.2058\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.3855 - loss: 1.1842 - val_accuracy: 0.4634 - val_loss: 1.0769\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.3830 - loss: 1.1243 - val_accuracy: 0.2927 - val_loss: 1.0993\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.3225 - loss: 1.1579 - val_accuracy: 0.4634 - val_loss: 1.0663\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.3224 - loss: 1.1343 - val_accuracy: 0.2927 - val_loss: 1.1343\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.3442 - loss: 1.1186 - val_accuracy: 0.4634 - val_loss: 1.0683\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.3286 - loss: 1.1362 - val_accuracy: 0.4634 - val_loss: 1.0882\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.3591 - loss: 1.1154 - val_accuracy: 0.2439 - val_loss: 1.0955\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.3861 - loss: 1.1039 - val_accuracy: 0.4634 - val_loss: 1.0717\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 0.3638 - loss: 1.1157 - val_accuracy: 0.2439 - val_loss: 1.1014\n",
      "Fold 1 Accuracy: 24.39%\n",
      "Fold 1 Loss: 1.1014\n",
      "\n",
      "Fold 2\n",
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1s/step - accuracy: 0.3500 - loss: 1.2224 - val_accuracy: 0.3086 - val_loss: 1.1411\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.3730 - loss: 1.1660 - val_accuracy: 0.3827 - val_loss: 1.1676\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - accuracy: 0.3199 - loss: 1.2429 - val_accuracy: 0.3086 - val_loss: 1.1049\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.4017 - loss: 1.1434 - val_accuracy: 0.3827 - val_loss: 1.0950\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.2926 - loss: 1.1677 - val_accuracy: 0.3827 - val_loss: 1.1086\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.3514 - loss: 1.1335 - val_accuracy: 0.3086 - val_loss: 1.0985\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step - accuracy: 0.3453 - loss: 1.1001 - val_accuracy: 0.3827 - val_loss: 1.0932\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 0.3004 - loss: 1.1354 - val_accuracy: 0.3086 - val_loss: 1.1073\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2s/step - accuracy: 0.3567 - loss: 1.1019 - val_accuracy: 0.3827 - val_loss: 1.0943\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2s/step - accuracy: 0.3859 - loss: 1.1060 - val_accuracy: 0.3827 - val_loss: 1.0939\n",
      "Fold 2 Accuracy: 38.27%\n",
      "Fold 2 Loss: 1.0939\n",
      "\n",
      "Fold 3\n",
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 3s/step - accuracy: 0.4070 - loss: 1.1307 - val_accuracy: 0.3704 - val_loss: 1.1231\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2s/step - accuracy: 0.3521 - loss: 1.2473 - val_accuracy: 0.3827 - val_loss: 1.2010\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.3831 - loss: 1.2189 - val_accuracy: 0.2840 - val_loss: 1.1908\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.3111 - loss: 1.2126 - val_accuracy: 0.3704 - val_loss: 1.1034\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.3959 - loss: 1.1575 - val_accuracy: 0.3333 - val_loss: 1.1660\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2s/step - accuracy: 0.3741 - loss: 1.1176 - val_accuracy: 0.3827 - val_loss: 1.0938\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2s/step - accuracy: 0.3423 - loss: 1.1252 - val_accuracy: 0.3333 - val_loss: 1.1264\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.3249 - loss: 1.1335 - val_accuracy: 0.3333 - val_loss: 1.1144\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.3894 - loss: 1.0992 - val_accuracy: 0.3333 - val_loss: 1.1199\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.3885 - loss: 1.1176 - val_accuracy: 0.3333 - val_loss: 1.1067\n",
      "Fold 3 Accuracy: 33.33%\n",
      "Fold 3 Loss: 1.1067\n",
      "\n",
      "Fold 4\n",
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 3s/step - accuracy: 0.3494 - loss: 1.1807 - val_accuracy: 0.3827 - val_loss: 1.1283\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.3577 - loss: 1.1709 - val_accuracy: 0.3827 - val_loss: 1.0962\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.3958 - loss: 1.1474 - val_accuracy: 0.3827 - val_loss: 1.1099\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.3018 - loss: 1.2011 - val_accuracy: 0.3827 - val_loss: 1.1187\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - accuracy: 0.3349 - loss: 1.1753 - val_accuracy: 0.3827 - val_loss: 1.0933\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.3526 - loss: 1.1374 - val_accuracy: 0.3827 - val_loss: 1.1042\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.4162 - loss: 1.1016 - val_accuracy: 0.3086 - val_loss: 1.0994\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.3062 - loss: 1.1282 - val_accuracy: 0.3827 - val_loss: 1.0954\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.2971 - loss: 1.1170 - val_accuracy: 0.3827 - val_loss: 1.0952\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.3962 - loss: 1.0797 - val_accuracy: 0.3827 - val_loss: 1.0964\n",
      "Fold 4 Accuracy: 38.27%\n",
      "Fold 4 Loss: 1.0964\n",
      "\n",
      "Fold 5\n",
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 3s/step - accuracy: 0.3313 - loss: 1.2394 - val_accuracy: 0.3333 - val_loss: 1.2559\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2s/step - accuracy: 0.3816 - loss: 1.1162 - val_accuracy: 0.3333 - val_loss: 1.1182\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.3260 - loss: 1.1713 - val_accuracy: 0.3333 - val_loss: 1.1007\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2s/step - accuracy: 0.2989 - loss: 1.1434 - val_accuracy: 0.3333 - val_loss: 1.1086\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2s/step - accuracy: 0.3468 - loss: 1.1037 - val_accuracy: 0.3333 - val_loss: 1.1038\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.3467 - loss: 1.1134 - val_accuracy: 0.3333 - val_loss: 1.1116\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2s/step - accuracy: 0.3515 - loss: 1.1231 - val_accuracy: 0.3333 - val_loss: 1.1200\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2s/step - accuracy: 0.4062 - loss: 1.1168 - val_accuracy: 0.3333 - val_loss: 1.1033\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 2s/step - accuracy: 0.3701 - loss: 1.0794 - val_accuracy: 0.3333 - val_loss: 1.1144\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.4423 - loss: 1.0768 - val_accuracy: 0.3333 - val_loss: 1.1074\n",
      "Fold 5 Accuracy: 33.33%\n",
      "Fold 5 Loss: 1.1074\n",
      "Mean Accuracy: 33.52%, Mean Loss: 1.1012\n",
      "\n",
      "Best Parameters:\n",
      "{'batch_size': 16, 'dropout': 0.3, 'learning_rate': 0.001, 'accuracy': 0.37910268902778627}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import itertools\n",
    "\n",
    "# ---- Load and Preprocess Data ----\n",
    "train_dir = 'D:/Lung_cancer/train'  # Training directory path\n",
    "target_size = (224, 224)  # Input size for EfficientNetB0\n",
    "num_classes = 3\n",
    "\n",
    "# Extract file paths and labels\n",
    "train_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=target_size,\n",
    "    batch_size=32,  # Temporary batch size\n",
    "    class_mode='categorical',\n",
    "    shuffle=False  # To keep track of indices\n",
    ")\n",
    "X = np.array(train_generator.filepaths)  # File paths of images\n",
    "y = np.array(train_generator.classes)    # Corresponding class labels\n",
    "\n",
    "# ---- Hyperparameter Search Space ----\n",
    "batch_sizes = [16, 32]\n",
    "dropout_rates = [0.3, 0.5]\n",
    "learning_rates = [0.0005, 0.001]\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "best_params = {}\n",
    "best_accuracy = 0\n",
    "\n",
    "# Iterate over all combinations of hyperparameters\n",
    "for batch_size, dropout_rate, learning_rate in itertools.product(batch_sizes, dropout_rates, learning_rates):\n",
    "    print(f\"Testing batch_size={batch_size}, dropout={dropout_rate}, lr={learning_rate}\")\n",
    "    \n",
    "    fold_accuracies = []\n",
    "    fold_losses = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
    "        print(f\"\\nFold {fold + 1}\")\n",
    "        \n",
    "        # Split into training and validation sets\n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "        \n",
    "        # Load data dynamically\n",
    "        def load_data(file_paths, labels):\n",
    "            images = []\n",
    "            for file in file_paths:\n",
    "                img = load_img(file, target_size=target_size)\n",
    "                img = img_to_array(img)\n",
    "                images.append(img)\n",
    "            images = np.array(images) / 255.0\n",
    "            labels = np.eye(num_classes)[labels]\n",
    "            return images, labels\n",
    "        \n",
    "        X_train_images, y_train_labels = load_data(X_train, y_train)\n",
    "        X_val_images, y_val_labels = load_data(X_val, y_val)\n",
    "        \n",
    "        # ---- Define and Compile Model ----\n",
    "        base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "        base_model.trainable = False\n",
    "        \n",
    "        x = base_model.output\n",
    "        x = layers.GlobalAveragePooling2D()(x)\n",
    "        x = layers.Dense(512, activation='relu')(x)\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "        output = layers.Dense(num_classes, activation='softmax')(x)\n",
    "        model = models.Model(inputs=base_model.input, outputs=output)\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer=Adam(learning_rate=learning_rate),\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "        # ---- Train Model ----\n",
    "        history = model.fit(\n",
    "            X_train_images, y_train_labels,\n",
    "            validation_data=(X_val_images, y_val_labels),\n",
    "            epochs=10,  # Default to 10 epochs\n",
    "            batch_size=batch_size,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # ---- Evaluate Model ----\n",
    "        val_loss, val_accuracy = model.evaluate(X_val_images, y_val_labels, verbose=0)\n",
    "        print(f\"Fold {fold + 1} Accuracy: {val_accuracy * 100:.2f}%\")\n",
    "        print(f\"Fold {fold + 1} Loss: {val_loss:.4f}\")\n",
    "        \n",
    "        fold_accuracies.append(val_accuracy)\n",
    "        fold_losses.append(val_loss)\n",
    "    \n",
    "    # Compute mean accuracy for the current hyperparameter combination\n",
    "    mean_accuracy = np.mean(fold_accuracies)\n",
    "    mean_loss = np.mean(fold_losses)\n",
    "    \n",
    "    print(f\"Mean Accuracy: {mean_accuracy * 100:.2f}%, Mean Loss: {mean_loss:.4f}\\n\")\n",
    "    \n",
    "    # Store best hyperparameters\n",
    "    if mean_accuracy > best_accuracy:\n",
    "        best_accuracy = mean_accuracy\n",
    "        best_params = {\n",
    "            \"batch_size\": batch_size,\n",
    "            \"dropout\": dropout_rate,\n",
    "            \"learning_rate\": learning_rate,\n",
    "            \"accuracy\": best_accuracy\n",
    "        }\n",
    "\n",
    "# ---- Final Best Parameters ----\n",
    "print(\"Best Parameters:\")\n",
    "print(best_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
