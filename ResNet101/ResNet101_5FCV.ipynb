{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3ed0296-9269-438f-a6bd-0ef2c09f3241",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 406 images belonging to 3 classes.\n",
      "Testing batch_size=16, dropout=0.3, lr=0.0005\n",
      "\n",
      "Fold 1\n",
      "Epoch 1/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 4s/step - accuracy: 0.3337 - loss: 1.3371 - val_accuracy: 0.4634 - val_loss: 1.0652\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 2s/step - accuracy: 0.3173 - loss: 1.2542 - val_accuracy: 0.4634 - val_loss: 1.0869\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 2s/step - accuracy: 0.3680 - loss: 1.1013 - val_accuracy: 0.2561 - val_loss: 1.1595\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2s/step - accuracy: 0.3443 - loss: 1.1714 - val_accuracy: 0.4146 - val_loss: 1.0548\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 3s/step - accuracy: 0.3604 - loss: 1.1140 - val_accuracy: 0.4024 - val_loss: 1.0687\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 3s/step - accuracy: 0.4226 - loss: 1.0998 - val_accuracy: 0.4634 - val_loss: 1.0184\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 3s/step - accuracy: 0.4048 - loss: 1.1091 - val_accuracy: 0.2561 - val_loss: 1.0875\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.3899 - loss: 1.1000 - val_accuracy: 0.3902 - val_loss: 1.0764\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 2s/step - accuracy: 0.3935 - loss: 1.0948 - val_accuracy: 0.4268 - val_loss: 1.0319\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 2s/step - accuracy: 0.4706 - loss: 1.0537 - val_accuracy: 0.4756 - val_loss: 1.0180\n",
      "Fold 1 Accuracy: 47.56%\n",
      "Fold 1 Loss: 1.0180\n",
      "\n",
      "Fold 2\n",
      "Epoch 1/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 3s/step - accuracy: 0.3434 - loss: 1.2675 - val_accuracy: 0.3827 - val_loss: 1.1758\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2s/step - accuracy: 0.3603 - loss: 1.1901 - val_accuracy: 0.3210 - val_loss: 1.1724\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 2s/step - accuracy: 0.3452 - loss: 1.2734 - val_accuracy: 0.4074 - val_loss: 1.1011\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 3s/step - accuracy: 0.4345 - loss: 1.0605 - val_accuracy: 0.4568 - val_loss: 1.0930\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 3s/step - accuracy: 0.3878 - loss: 1.1176 - val_accuracy: 0.4568 - val_loss: 1.0724\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 3s/step - accuracy: 0.3944 - loss: 1.0930 - val_accuracy: 0.3704 - val_loss: 1.0749\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 3s/step - accuracy: 0.4287 - loss: 1.0686 - val_accuracy: 0.3827 - val_loss: 1.0806\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 2s/step - accuracy: 0.3596 - loss: 1.0869 - val_accuracy: 0.3827 - val_loss: 1.0909\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2s/step - accuracy: 0.4181 - loss: 1.0559 - val_accuracy: 0.4444 - val_loss: 1.0763\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.4556 - loss: 1.0660 - val_accuracy: 0.3827 - val_loss: 1.0669\n",
      "Fold 2 Accuracy: 38.27%\n",
      "Fold 2 Loss: 1.0669\n",
      "\n",
      "Fold 3\n",
      "Epoch 1/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 2s/step - accuracy: 0.3963 - loss: 1.2325 - val_accuracy: 0.3951 - val_loss: 1.0981\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.3983 - loss: 1.1293 - val_accuracy: 0.4444 - val_loss: 1.0636\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - accuracy: 0.3764 - loss: 1.1124 - val_accuracy: 0.3951 - val_loss: 1.0764\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.3299 - loss: 1.1339 - val_accuracy: 0.4568 - val_loss: 1.0518\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.4400 - loss: 1.0710 - val_accuracy: 0.3580 - val_loss: 1.0651\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.3468 - loss: 1.1300 - val_accuracy: 0.3333 - val_loss: 1.0747\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.4045 - loss: 1.0827 - val_accuracy: 0.4198 - val_loss: 1.0555\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.3819 - loss: 1.0797 - val_accuracy: 0.4198 - val_loss: 1.0708\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.3728 - loss: 1.0959 - val_accuracy: 0.4444 - val_loss: 1.0519\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.4342 - loss: 1.0649 - val_accuracy: 0.3827 - val_loss: 1.0834\n",
      "Fold 3 Accuracy: 38.27%\n",
      "Fold 3 Loss: 1.0834\n",
      "\n",
      "Fold 4\n",
      "Epoch 1/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 2s/step - accuracy: 0.3581 - loss: 1.1949 - val_accuracy: 0.3827 - val_loss: 1.1590\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.3667 - loss: 1.1562 - val_accuracy: 0.4568 - val_loss: 1.0633\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.3285 - loss: 1.1466 - val_accuracy: 0.3827 - val_loss: 1.0477\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.4342 - loss: 1.0986 - val_accuracy: 0.5309 - val_loss: 1.0412\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - accuracy: 0.3591 - loss: 1.1058 - val_accuracy: 0.4568 - val_loss: 1.0357\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.3411 - loss: 1.1469 - val_accuracy: 0.4815 - val_loss: 1.0261\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - accuracy: 0.3869 - loss: 1.0829 - val_accuracy: 0.4444 - val_loss: 1.0591\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.4094 - loss: 1.0848 - val_accuracy: 0.3827 - val_loss: 1.0402\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.3752 - loss: 1.0641 - val_accuracy: 0.3827 - val_loss: 1.0271\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.3804 - loss: 1.0979 - val_accuracy: 0.4198 - val_loss: 1.0172\n",
      "Fold 4 Accuracy: 41.98%\n",
      "Fold 4 Loss: 1.0172\n",
      "\n",
      "Fold 5\n",
      "Epoch 1/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 2s/step - accuracy: 0.3187 - loss: 1.2815 - val_accuracy: 0.3333 - val_loss: 1.0973\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.3816 - loss: 1.1168 - val_accuracy: 0.3333 - val_loss: 1.1179\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.4057 - loss: 1.1198 - val_accuracy: 0.4198 - val_loss: 1.0726\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.3765 - loss: 1.1458 - val_accuracy: 0.3827 - val_loss: 1.0740\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.3410 - loss: 1.1149 - val_accuracy: 0.4198 - val_loss: 1.0805\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.3847 - loss: 1.0765 - val_accuracy: 0.3580 - val_loss: 1.0993\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.4163 - loss: 1.0757 - val_accuracy: 0.3827 - val_loss: 1.0641\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.4034 - loss: 1.0742 - val_accuracy: 0.4198 - val_loss: 1.0616\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.4284 - loss: 1.0713 - val_accuracy: 0.3457 - val_loss: 1.0750\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.4270 - loss: 1.0685 - val_accuracy: 0.3580 - val_loss: 1.0641\n",
      "Fold 5 Accuracy: 35.80%\n",
      "Fold 5 Loss: 1.0641\n",
      "Mean Accuracy: 40.38%, Mean Loss: 1.0499\n",
      "\n",
      "Testing batch_size=16, dropout=0.3, lr=0.001\n",
      "\n",
      "Fold 1\n",
      "Epoch 1/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 2s/step - accuracy: 0.3778 - loss: 1.3364 - val_accuracy: 0.4512 - val_loss: 1.0828\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.2981 - loss: 1.1975 - val_accuracy: 0.4634 - val_loss: 1.0312\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - accuracy: 0.4279 - loss: 1.1163 - val_accuracy: 0.3659 - val_loss: 1.0979\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - accuracy: 0.4517 - loss: 1.0947 - val_accuracy: 0.3537 - val_loss: 1.0848\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.4042 - loss: 1.1464 - val_accuracy: 0.4390 - val_loss: 1.0663\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.3908 - loss: 1.0974 - val_accuracy: 0.4634 - val_loss: 1.0212\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.4074 - loss: 1.1085 - val_accuracy: 0.4268 - val_loss: 1.0254\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - accuracy: 0.3914 - loss: 1.0767 - val_accuracy: 0.4756 - val_loss: 1.0234\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.4302 - loss: 1.0595 - val_accuracy: 0.4756 - val_loss: 1.0236\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.3936 - loss: 1.0552 - val_accuracy: 0.4512 - val_loss: 1.0342\n",
      "Fold 1 Accuracy: 45.12%\n",
      "Fold 1 Loss: 1.0342\n",
      "\n",
      "Fold 2\n",
      "Epoch 1/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 2s/step - accuracy: 0.3312 - loss: 1.3501 - val_accuracy: 0.3210 - val_loss: 1.2009\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.3711 - loss: 1.1897 - val_accuracy: 0.3210 - val_loss: 1.1339\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.3805 - loss: 1.1482 - val_accuracy: 0.3333 - val_loss: 1.2231\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - accuracy: 0.3506 - loss: 1.1746 - val_accuracy: 0.4198 - val_loss: 1.1161\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - accuracy: 0.4126 - loss: 1.1361 - val_accuracy: 0.3704 - val_loss: 1.1190\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - accuracy: 0.3550 - loss: 1.1159 - val_accuracy: 0.3827 - val_loss: 1.0703\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - accuracy: 0.3947 - loss: 1.0951 - val_accuracy: 0.3704 - val_loss: 1.1111\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - accuracy: 0.3605 - loss: 1.1232 - val_accuracy: 0.3827 - val_loss: 1.0960\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.4164 - loss: 1.0608 - val_accuracy: 0.4074 - val_loss: 1.0694\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.4235 - loss: 1.0880 - val_accuracy: 0.4568 - val_loss: 1.0657\n",
      "Fold 2 Accuracy: 45.68%\n",
      "Fold 2 Loss: 1.0657\n",
      "\n",
      "Fold 3\n",
      "Epoch 1/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 2s/step - accuracy: 0.4108 - loss: 1.2598 - val_accuracy: 0.4074 - val_loss: 1.0811\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.3810 - loss: 1.1383 - val_accuracy: 0.4074 - val_loss: 1.0687\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.3642 - loss: 1.0891 - val_accuracy: 0.3333 - val_loss: 1.0892\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - accuracy: 0.4255 - loss: 1.0911 - val_accuracy: 0.4444 - val_loss: 1.0543\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - accuracy: 0.3832 - loss: 1.1234 - val_accuracy: 0.3333 - val_loss: 1.0844\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.3757 - loss: 1.0916 - val_accuracy: 0.4321 - val_loss: 1.0621\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.4548 - loss: 1.0835 - val_accuracy: 0.4444 - val_loss: 1.0455\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - accuracy: 0.3820 - loss: 1.1057 - val_accuracy: 0.5062 - val_loss: 1.0682\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - accuracy: 0.3773 - loss: 1.0773 - val_accuracy: 0.4938 - val_loss: 1.0542\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.4326 - loss: 1.0371 - val_accuracy: 0.3333 - val_loss: 1.1252\n",
      "Fold 3 Accuracy: 33.33%\n",
      "Fold 3 Loss: 1.1252\n",
      "\n",
      "Fold 4\n",
      "Epoch 1/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 2s/step - accuracy: 0.3540 - loss: 1.2882 - val_accuracy: 0.4691 - val_loss: 1.0748\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.3580 - loss: 1.1387 - val_accuracy: 0.3827 - val_loss: 1.0955\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.3306 - loss: 1.1888 - val_accuracy: 0.4074 - val_loss: 1.0675\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.3704 - loss: 1.1292 - val_accuracy: 0.4074 - val_loss: 1.1333\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - accuracy: 0.3448 - loss: 1.1766 - val_accuracy: 0.3827 - val_loss: 1.0301\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.2630 - loss: 1.1415 - val_accuracy: 0.3951 - val_loss: 1.0330\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.3925 - loss: 1.0897 - val_accuracy: 0.3827 - val_loss: 1.0212\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - accuracy: 0.4221 - loss: 1.0680 - val_accuracy: 0.4074 - val_loss: 1.0311\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - accuracy: 0.3829 - loss: 1.0640 - val_accuracy: 0.4321 - val_loss: 1.0287\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.4103 - loss: 1.0831 - val_accuracy: 0.3827 - val_loss: 1.0992\n",
      "Fold 4 Accuracy: 38.27%\n",
      "Fold 4 Loss: 1.0992\n",
      "\n",
      "Fold 5\n",
      "Epoch 1/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 2s/step - accuracy: 0.3601 - loss: 1.2080 - val_accuracy: 0.3333 - val_loss: 1.1622\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.3549 - loss: 1.2191 - val_accuracy: 0.3333 - val_loss: 1.0952\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.3864 - loss: 1.1388 - val_accuracy: 0.3333 - val_loss: 1.0918\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.3622 - loss: 1.1076 - val_accuracy: 0.4074 - val_loss: 1.1834\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - accuracy: 0.4076 - loss: 1.1438 - val_accuracy: 0.3333 - val_loss: 1.0867\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - accuracy: 0.3633 - loss: 1.0958 - val_accuracy: 0.4691 - val_loss: 1.0611\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - accuracy: 0.3386 - loss: 1.0821 - val_accuracy: 0.3333 - val_loss: 1.0611\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.3780 - loss: 1.0984 - val_accuracy: 0.3951 - val_loss: 1.0592\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - accuracy: 0.4113 - loss: 1.0485 - val_accuracy: 0.3827 - val_loss: 1.0688\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - accuracy: 0.3522 - loss: 1.1102 - val_accuracy: 0.4074 - val_loss: 1.0632\n",
      "Fold 5 Accuracy: 40.74%\n",
      "Fold 5 Loss: 1.0632\n",
      "Mean Accuracy: 40.63%, Mean Loss: 1.0775\n",
      "\n",
      "Testing batch_size=16, dropout=0.5, lr=0.0005\n",
      "\n",
      "Fold 1\n",
      "Epoch 1/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 2s/step - accuracy: 0.2887 - loss: 1.3935 - val_accuracy: 0.2927 - val_loss: 1.1457\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 2s/step - accuracy: 0.3299 - loss: 1.2675 - val_accuracy: 0.3171 - val_loss: 1.1018\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - accuracy: 0.3500 - loss: 1.1833 - val_accuracy: 0.4634 - val_loss: 1.0387\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - accuracy: 0.3598 - loss: 1.1526 - val_accuracy: 0.3171 - val_loss: 1.0737\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 2s/step - accuracy: 0.3396 - loss: 1.1285 - val_accuracy: 0.4756 - val_loss: 1.0918\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2s/step - accuracy: 0.3161 - loss: 1.1503 - val_accuracy: 0.4390 - val_loss: 1.0660\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - accuracy: 0.3463 - loss: 1.1237 - val_accuracy: 0.4634 - val_loss: 1.0451\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - accuracy: 0.3820 - loss: 1.1088 - val_accuracy: 0.4268 - val_loss: 1.0713\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - accuracy: 0.4282 - loss: 1.0621 - val_accuracy: 0.4268 - val_loss: 1.0523\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - accuracy: 0.3833 - loss: 1.0666 - val_accuracy: 0.4268 - val_loss: 1.0494\n",
      "Fold 1 Accuracy: 42.68%\n",
      "Fold 1 Loss: 1.0494\n",
      "\n",
      "Fold 2\n",
      "Epoch 1/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 2s/step - accuracy: 0.3590 - loss: 1.3049 - val_accuracy: 0.3210 - val_loss: 1.1642\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - accuracy: 0.3281 - loss: 1.2333 - val_accuracy: 0.3210 - val_loss: 1.1262\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - accuracy: 0.3073 - loss: 1.2131 - val_accuracy: 0.3951 - val_loss: 1.0764\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - accuracy: 0.3473 - loss: 1.1449 - val_accuracy: 0.3827 - val_loss: 1.0740\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - accuracy: 0.3696 - loss: 1.1120 - val_accuracy: 0.4568 - val_loss: 1.0680\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - accuracy: 0.4368 - loss: 1.0628 - val_accuracy: 0.3827 - val_loss: 1.0829\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - accuracy: 0.3586 - loss: 1.1280 - val_accuracy: 0.4321 - val_loss: 1.0794\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - accuracy: 0.3752 - loss: 1.0939 - val_accuracy: 0.3827 - val_loss: 1.1082\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - accuracy: 0.4039 - loss: 1.0835 - val_accuracy: 0.3333 - val_loss: 1.0889\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - accuracy: 0.3748 - loss: 1.1023 - val_accuracy: 0.3704 - val_loss: 1.0824\n",
      "Fold 2 Accuracy: 37.04%\n",
      "Fold 2 Loss: 1.0824\n",
      "\n",
      "Fold 3\n",
      "Epoch 1/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 2s/step - accuracy: 0.3916 - loss: 1.3278 - val_accuracy: 0.3951 - val_loss: 1.0829\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 2s/step - accuracy: 0.3068 - loss: 1.2174 - val_accuracy: 0.3086 - val_loss: 1.1237\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - accuracy: 0.3477 - loss: 1.1964 - val_accuracy: 0.3333 - val_loss: 1.1220\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - accuracy: 0.4278 - loss: 1.1003 - val_accuracy: 0.3333 - val_loss: 1.1385\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - accuracy: 0.3656 - loss: 1.1517 - val_accuracy: 0.4074 - val_loss: 1.0683\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - accuracy: 0.3784 - loss: 1.1571 - val_accuracy: 0.4568 - val_loss: 1.0575\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - accuracy: 0.3866 - loss: 1.0942 - val_accuracy: 0.4568 - val_loss: 1.0564\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - accuracy: 0.3704 - loss: 1.1205 - val_accuracy: 0.5062 - val_loss: 1.0687\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - accuracy: 0.3897 - loss: 1.0695 - val_accuracy: 0.3333 - val_loss: 1.0685\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - accuracy: 0.4156 - loss: 1.0898 - val_accuracy: 0.5309 - val_loss: 1.0674\n",
      "Fold 3 Accuracy: 53.09%\n",
      "Fold 3 Loss: 1.0674\n",
      "\n",
      "Fold 4\n",
      "Epoch 1/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 2s/step - accuracy: 0.3256 - loss: 1.2968 - val_accuracy: 0.3827 - val_loss: 1.0726\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 2s/step - accuracy: 0.3962 - loss: 1.2007 - val_accuracy: 0.3827 - val_loss: 1.1046\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - accuracy: 0.3737 - loss: 1.1585 - val_accuracy: 0.4568 - val_loss: 1.0492\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - accuracy: 0.3936 - loss: 1.1168 - val_accuracy: 0.4321 - val_loss: 1.0528\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - accuracy: 0.3268 - loss: 1.1437 - val_accuracy: 0.3827 - val_loss: 1.1033\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 2s/step - accuracy: 0.4078 - loss: 1.1271 - val_accuracy: 0.3827 - val_loss: 1.0382\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - accuracy: 0.3563 - loss: 1.1315 - val_accuracy: 0.4321 - val_loss: 1.0701\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 2s/step - accuracy: 0.4126 - loss: 1.0816 - val_accuracy: 0.4815 - val_loss: 1.0373\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 2s/step - accuracy: 0.4010 - loss: 1.1098 - val_accuracy: 0.3827 - val_loss: 1.0385\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - accuracy: 0.4202 - loss: 1.0730 - val_accuracy: 0.3827 - val_loss: 1.0690\n",
      "Fold 4 Accuracy: 38.27%\n",
      "Fold 4 Loss: 1.0690\n",
      "\n",
      "Fold 5\n",
      "Epoch 1/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 2s/step - accuracy: 0.3440 - loss: 1.2985 - val_accuracy: 0.3333 - val_loss: 1.1597\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 2s/step - accuracy: 0.3244 - loss: 1.2259 - val_accuracy: 0.3333 - val_loss: 1.2231\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2s/step - accuracy: 0.3754 - loss: 1.2302 - val_accuracy: 0.4074 - val_loss: 1.0783\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - accuracy: 0.3701 - loss: 1.1332 - val_accuracy: 0.3704 - val_loss: 1.0928\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 2s/step - accuracy: 0.3796 - loss: 1.1074 - val_accuracy: 0.3333 - val_loss: 1.1027\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - accuracy: 0.3847 - loss: 1.1189 - val_accuracy: 0.3333 - val_loss: 1.1014\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - accuracy: 0.3411 - loss: 1.1227 - val_accuracy: 0.4198 - val_loss: 1.0783\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - accuracy: 0.4993 - loss: 1.0367 - val_accuracy: 0.3827 - val_loss: 1.0683\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 2s/step - accuracy: 0.4054 - loss: 1.0752 - val_accuracy: 0.3704 - val_loss: 1.0719\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - accuracy: 0.3885 - loss: 1.0864 - val_accuracy: 0.3951 - val_loss: 1.0701\n",
      "Fold 5 Accuracy: 39.51%\n",
      "Fold 5 Loss: 1.0701\n",
      "Mean Accuracy: 42.12%, Mean Loss: 1.0676\n",
      "\n",
      "Testing batch_size=16, dropout=0.5, lr=0.001\n",
      "\n",
      "Fold 1\n",
      "Epoch 1/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 2s/step - accuracy: 0.3782 - loss: 1.4365 - val_accuracy: 0.3049 - val_loss: 1.2120\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2s/step - accuracy: 0.3601 - loss: 1.2356 - val_accuracy: 0.3171 - val_loss: 1.1432\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 2s/step - accuracy: 0.3514 - loss: 1.1983 - val_accuracy: 0.3659 - val_loss: 1.0711\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - accuracy: 0.3653 - loss: 1.1535 - val_accuracy: 0.3293 - val_loss: 1.1155\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 2s/step - accuracy: 0.3951 - loss: 1.1290 - val_accuracy: 0.4634 - val_loss: 1.0771\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - accuracy: 0.3779 - loss: 1.1787 - val_accuracy: 0.4634 - val_loss: 1.0456\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - accuracy: 0.4239 - loss: 1.0879 - val_accuracy: 0.2683 - val_loss: 1.0995\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 2s/step - accuracy: 0.4035 - loss: 1.0796 - val_accuracy: 0.4756 - val_loss: 1.0515\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 2s/step - accuracy: 0.3956 - loss: 1.0771 - val_accuracy: 0.4390 - val_loss: 1.0742\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - accuracy: 0.3847 - loss: 1.0872 - val_accuracy: 0.5244 - val_loss: 1.0414\n",
      "Fold 1 Accuracy: 52.44%\n",
      "Fold 1 Loss: 1.0414\n",
      "\n",
      "Fold 2\n",
      "Epoch 1/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 2s/step - accuracy: 0.3752 - loss: 1.3692 - val_accuracy: 0.3827 - val_loss: 1.0898\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 2s/step - accuracy: 0.4583 - loss: 1.1285 - val_accuracy: 0.3333 - val_loss: 1.1050\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - accuracy: 0.3686 - loss: 1.1289 - val_accuracy: 0.3333 - val_loss: 1.1034\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - accuracy: 0.3887 - loss: 1.1651 - val_accuracy: 0.3457 - val_loss: 1.1084\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 2s/step - accuracy: 0.3908 - loss: 1.0803 - val_accuracy: 0.4198 - val_loss: 1.0733\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - accuracy: 0.3729 - loss: 1.0942 - val_accuracy: 0.3580 - val_loss: 1.0925\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - accuracy: 0.3848 - loss: 1.0973 - val_accuracy: 0.4074 - val_loss: 1.0791\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - accuracy: 0.4472 - loss: 1.0556 - val_accuracy: 0.3210 - val_loss: 1.1093\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 2s/step - accuracy: 0.4335 - loss: 1.0643 - val_accuracy: 0.3827 - val_loss: 1.0802\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - accuracy: 0.4227 - loss: 1.0611 - val_accuracy: 0.3704 - val_loss: 1.0804\n",
      "Fold 2 Accuracy: 37.04%\n",
      "Fold 2 Loss: 1.0804\n",
      "\n",
      "Fold 3\n",
      "Epoch 1/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 2s/step - accuracy: 0.3533 - loss: 1.4500 - val_accuracy: 0.3951 - val_loss: 1.0712\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 2s/step - accuracy: 0.3921 - loss: 1.2369 - val_accuracy: 0.4074 - val_loss: 1.0842\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 2s/step - accuracy: 0.3327 - loss: 1.1757 - val_accuracy: 0.4691 - val_loss: 1.0594\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 2s/step - accuracy: 0.4000 - loss: 1.1351 - val_accuracy: 0.4568 - val_loss: 1.0946\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 2s/step - accuracy: 0.3223 - loss: 1.1713 - val_accuracy: 0.3333 - val_loss: 1.1414\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 2s/step - accuracy: 0.4118 - loss: 1.0956 - val_accuracy: 0.3333 - val_loss: 1.0912\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 2s/step - accuracy: 0.3259 - loss: 1.1517 - val_accuracy: 0.3333 - val_loss: 1.0977\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 2s/step - accuracy: 0.3693 - loss: 1.0851 - val_accuracy: 0.3333 - val_loss: 1.0855\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 2s/step - accuracy: 0.3900 - loss: 1.1033 - val_accuracy: 0.4444 - val_loss: 1.0564\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 2s/step - accuracy: 0.4289 - loss: 1.0703 - val_accuracy: 0.4568 - val_loss: 1.0575\n",
      "Fold 3 Accuracy: 45.68%\n",
      "Fold 3 Loss: 1.0575\n",
      "\n",
      "Fold 4\n",
      "Epoch 1/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 2s/step - accuracy: 0.3546 - loss: 1.4501 - val_accuracy: 0.3210 - val_loss: 1.1690\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 2s/step - accuracy: 0.3203 - loss: 1.2696 - val_accuracy: 0.3827 - val_loss: 1.0607\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - accuracy: 0.4093 - loss: 1.1344 - val_accuracy: 0.3827 - val_loss: 1.0435\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - accuracy: 0.3592 - loss: 1.1499 - val_accuracy: 0.4198 - val_loss: 1.0911\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 2s/step - accuracy: 0.2899 - loss: 1.1889 - val_accuracy: 0.4444 - val_loss: 1.0922\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - accuracy: 0.3064 - loss: 1.1741 - val_accuracy: 0.4321 - val_loss: 1.0934\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - accuracy: 0.3911 - loss: 1.1092 - val_accuracy: 0.4568 - val_loss: 1.0723\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - accuracy: 0.3296 - loss: 1.1165 - val_accuracy: 0.3827 - val_loss: 1.0570\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 2s/step - accuracy: 0.3559 - loss: 1.0773 - val_accuracy: 0.4198 - val_loss: 1.0551\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - accuracy: 0.3162 - loss: 1.0982 - val_accuracy: 0.3827 - val_loss: 1.0617\n",
      "Fold 4 Accuracy: 38.27%\n",
      "Fold 4 Loss: 1.0617\n",
      "\n",
      "Fold 5\n",
      "Epoch 1/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 2s/step - accuracy: 0.3315 - loss: 1.4264 - val_accuracy: 0.3333 - val_loss: 1.1465\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 2s/step - accuracy: 0.3620 - loss: 1.2585 - val_accuracy: 0.4321 - val_loss: 1.1030\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - accuracy: 0.3835 - loss: 1.1063 - val_accuracy: 0.4074 - val_loss: 1.0788\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 2s/step - accuracy: 0.4303 - loss: 1.0713 - val_accuracy: 0.3457 - val_loss: 1.0770\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 2s/step - accuracy: 0.3875 - loss: 1.1267 - val_accuracy: 0.3333 - val_loss: 1.0776\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 2s/step - accuracy: 0.4233 - loss: 1.0745 - val_accuracy: 0.4198 - val_loss: 1.0781\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - accuracy: 0.3570 - loss: 1.0938 - val_accuracy: 0.4321 - val_loss: 1.0771\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 2s/step - accuracy: 0.4051 - loss: 1.0936 - val_accuracy: 0.3333 - val_loss: 1.0797\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 2s/step - accuracy: 0.3984 - loss: 1.0925 - val_accuracy: 0.3827 - val_loss: 1.0762\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - accuracy: 0.3756 - loss: 1.0863 - val_accuracy: 0.3951 - val_loss: 1.0775\n",
      "Fold 5 Accuracy: 39.51%\n",
      "Fold 5 Loss: 1.0775\n",
      "Mean Accuracy: 42.59%, Mean Loss: 1.0637\n",
      "\n",
      "Testing batch_size=32, dropout=0.3, lr=0.0005\n",
      "\n",
      "Fold 1\n",
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 3s/step - accuracy: 0.3275 - loss: 1.3400 - val_accuracy: 0.2927 - val_loss: 1.2703\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 3s/step - accuracy: 0.3591 - loss: 1.2225 - val_accuracy: 0.4634 - val_loss: 1.0849\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 3s/step - accuracy: 0.3584 - loss: 1.1834 - val_accuracy: 0.3171 - val_loss: 1.1407\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 3s/step - accuracy: 0.4059 - loss: 1.1377 - val_accuracy: 0.4268 - val_loss: 1.0509\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 3s/step - accuracy: 0.3969 - loss: 1.0863 - val_accuracy: 0.5122 - val_loss: 1.0633\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 3s/step - accuracy: 0.3219 - loss: 1.2041 - val_accuracy: 0.3293 - val_loss: 1.1355\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 3s/step - accuracy: 0.3732 - loss: 1.1325 - val_accuracy: 0.5488 - val_loss: 1.0366\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 3s/step - accuracy: 0.3546 - loss: 1.1228 - val_accuracy: 0.4024 - val_loss: 1.1183\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 3s/step - accuracy: 0.3992 - loss: 1.0945 - val_accuracy: 0.4634 - val_loss: 1.0199\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 3s/step - accuracy: 0.3837 - loss: 1.1308 - val_accuracy: 0.3780 - val_loss: 1.0833\n",
      "Fold 1 Accuracy: 37.80%\n",
      "Fold 1 Loss: 1.0833\n",
      "\n",
      "Fold 2\n",
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 3s/step - accuracy: 0.3761 - loss: 1.2279 - val_accuracy: 0.3827 - val_loss: 1.0959\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 3s/step - accuracy: 0.2886 - loss: 1.1402 - val_accuracy: 0.3827 - val_loss: 1.0829\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 3s/step - accuracy: 0.3820 - loss: 1.1496 - val_accuracy: 0.3210 - val_loss: 1.1442\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 3s/step - accuracy: 0.3923 - loss: 1.1406 - val_accuracy: 0.3827 - val_loss: 1.1348\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3s/step - accuracy: 0.3664 - loss: 1.1933 - val_accuracy: 0.3333 - val_loss: 1.1222\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 3s/step - accuracy: 0.3185 - loss: 1.1633 - val_accuracy: 0.3333 - val_loss: 1.0821\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 3s/step - accuracy: 0.4553 - loss: 1.0894 - val_accuracy: 0.3827 - val_loss: 1.1392\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 3s/step - accuracy: 0.4268 - loss: 1.1138 - val_accuracy: 0.4074 - val_loss: 1.1058\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 3s/step - accuracy: 0.4068 - loss: 1.1061 - val_accuracy: 0.4938 - val_loss: 1.0666\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 3s/step - accuracy: 0.3780 - loss: 1.1118 - val_accuracy: 0.3827 - val_loss: 1.0994\n",
      "Fold 2 Accuracy: 38.27%\n",
      "Fold 2 Loss: 1.0994\n",
      "\n",
      "Fold 3\n",
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 3s/step - accuracy: 0.3017 - loss: 1.2461 - val_accuracy: 0.3333 - val_loss: 1.0807\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 3s/step - accuracy: 0.3689 - loss: 1.1175 - val_accuracy: 0.3333 - val_loss: 1.0886\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 3s/step - accuracy: 0.4138 - loss: 1.1070 - val_accuracy: 0.3580 - val_loss: 1.0995\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 3s/step - accuracy: 0.3688 - loss: 1.1371 - val_accuracy: 0.3333 - val_loss: 1.0857\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 3s/step - accuracy: 0.4233 - loss: 1.0767 - val_accuracy: 0.3086 - val_loss: 1.0904\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 3s/step - accuracy: 0.4435 - loss: 1.0935 - val_accuracy: 0.3333 - val_loss: 1.1324\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 3s/step - accuracy: 0.3981 - loss: 1.1234 - val_accuracy: 0.5185 - val_loss: 1.0547\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 3s/step - accuracy: 0.3827 - loss: 1.1100 - val_accuracy: 0.3333 - val_loss: 1.0731\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 3s/step - accuracy: 0.3473 - loss: 1.1039 - val_accuracy: 0.3827 - val_loss: 1.0741\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 3s/step - accuracy: 0.4027 - loss: 1.0649 - val_accuracy: 0.5062 - val_loss: 1.0576\n",
      "Fold 3 Accuracy: 50.62%\n",
      "Fold 3 Loss: 1.0576\n",
      "\n",
      "Fold 4\n",
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 3s/step - accuracy: 0.3445 - loss: 1.2633 - val_accuracy: 0.3086 - val_loss: 1.1943\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 3s/step - accuracy: 0.3491 - loss: 1.1851 - val_accuracy: 0.3827 - val_loss: 1.0657\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 3s/step - accuracy: 0.3380 - loss: 1.1695 - val_accuracy: 0.3827 - val_loss: 1.1001\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 3s/step - accuracy: 0.3876 - loss: 1.1303 - val_accuracy: 0.4691 - val_loss: 1.0630\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 3s/step - accuracy: 0.3928 - loss: 1.1218 - val_accuracy: 0.3827 - val_loss: 1.0443\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 3s/step - accuracy: 0.4078 - loss: 1.0964 - val_accuracy: 0.4815 - val_loss: 1.0399\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 3s/step - accuracy: 0.3455 - loss: 1.1193 - val_accuracy: 0.4321 - val_loss: 1.0267\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 3s/step - accuracy: 0.4170 - loss: 1.0678 - val_accuracy: 0.4568 - val_loss: 1.0194\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 3s/step - accuracy: 0.3975 - loss: 1.1042 - val_accuracy: 0.4568 - val_loss: 1.0225\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 3s/step - accuracy: 0.3848 - loss: 1.0962 - val_accuracy: 0.4321 - val_loss: 1.0417\n",
      "Fold 4 Accuracy: 43.21%\n",
      "Fold 4 Loss: 1.0417\n",
      "\n",
      "Fold 5\n",
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 3s/step - accuracy: 0.3602 - loss: 1.1649 - val_accuracy: 0.3333 - val_loss: 1.2052\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 3s/step - accuracy: 0.3400 - loss: 1.2069 - val_accuracy: 0.3333 - val_loss: 1.1086\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 3s/step - accuracy: 0.4355 - loss: 1.1078 - val_accuracy: 0.3580 - val_loss: 1.1367\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 3s/step - accuracy: 0.3361 - loss: 1.1979 - val_accuracy: 0.3333 - val_loss: 1.1507\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 3s/step - accuracy: 0.3356 - loss: 1.1919 - val_accuracy: 0.4074 - val_loss: 1.0730\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 3s/step - accuracy: 0.4169 - loss: 1.0880 - val_accuracy: 0.3951 - val_loss: 1.0713\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 3s/step - accuracy: 0.3612 - loss: 1.1311 - val_accuracy: 0.3827 - val_loss: 1.0719\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 3s/step - accuracy: 0.3566 - loss: 1.0825 - val_accuracy: 0.4074 - val_loss: 1.0632\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 3s/step - accuracy: 0.3741 - loss: 1.0985 - val_accuracy: 0.3827 - val_loss: 1.0739\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 3s/step - accuracy: 0.4232 - loss: 1.0971 - val_accuracy: 0.3827 - val_loss: 1.1080\n",
      "Fold 5 Accuracy: 38.27%\n",
      "Fold 5 Loss: 1.1080\n",
      "Mean Accuracy: 41.64%, Mean Loss: 1.0780\n",
      "\n",
      "Testing batch_size=32, dropout=0.3, lr=0.001\n",
      "\n",
      "Fold 1\n",
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 3s/step - accuracy: 0.3734 - loss: 1.2849 - val_accuracy: 0.2927 - val_loss: 1.4813\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 3s/step - accuracy: 0.3962 - loss: 1.2699 - val_accuracy: 0.2439 - val_loss: 1.5857\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 3s/step - accuracy: 0.3235 - loss: 1.4370 - val_accuracy: 0.4634 - val_loss: 1.1810\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 3s/step - accuracy: 0.3584 - loss: 1.2814 - val_accuracy: 0.2439 - val_loss: 1.3315\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 3s/step - accuracy: 0.3281 - loss: 1.1828 - val_accuracy: 0.4634 - val_loss: 1.0339\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 3s/step - accuracy: 0.3645 - loss: 1.1217 - val_accuracy: 0.3659 - val_loss: 1.0803\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 3s/step - accuracy: 0.3557 - loss: 1.1243 - val_accuracy: 0.4512 - val_loss: 1.0522\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 3s/step - accuracy: 0.4068 - loss: 1.0813 - val_accuracy: 0.4390 - val_loss: 1.0416\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 3s/step - accuracy: 0.3439 - loss: 1.1126 - val_accuracy: 0.4268 - val_loss: 1.0966\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 3s/step - accuracy: 0.4207 - loss: 1.0717 - val_accuracy: 0.4268 - val_loss: 1.0407\n",
      "Fold 1 Accuracy: 42.68%\n",
      "Fold 1 Loss: 1.0407\n",
      "\n",
      "Fold 2\n",
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 3s/step - accuracy: 0.3342 - loss: 1.3582 - val_accuracy: 0.3086 - val_loss: 1.1250\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 3s/step - accuracy: 0.3613 - loss: 1.1692 - val_accuracy: 0.3951 - val_loss: 1.0781\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3s/step - accuracy: 0.2968 - loss: 1.2086 - val_accuracy: 0.3951 - val_loss: 1.1630\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 3s/step - accuracy: 0.3425 - loss: 1.1743 - val_accuracy: 0.3580 - val_loss: 1.0977\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 3s/step - accuracy: 0.3628 - loss: 1.1349 - val_accuracy: 0.3827 - val_loss: 1.1798\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 3s/step - accuracy: 0.4028 - loss: 1.1477 - val_accuracy: 0.4198 - val_loss: 1.0920\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 3s/step - accuracy: 0.3926 - loss: 1.0817 - val_accuracy: 0.3951 - val_loss: 1.0734\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 3s/step - accuracy: 0.3612 - loss: 1.0776 - val_accuracy: 0.3827 - val_loss: 1.0990\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 3s/step - accuracy: 0.3971 - loss: 1.0842 - val_accuracy: 0.4815 - val_loss: 1.0670\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 3s/step - accuracy: 0.4251 - loss: 1.0543 - val_accuracy: 0.3704 - val_loss: 1.0816\n",
      "Fold 2 Accuracy: 37.04%\n",
      "Fold 2 Loss: 1.0816\n",
      "\n",
      "Fold 3\n",
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 3s/step - accuracy: 0.2957 - loss: 1.3143 - val_accuracy: 0.2840 - val_loss: 1.3680\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 3s/step - accuracy: 0.3297 - loss: 1.2298 - val_accuracy: 0.3333 - val_loss: 1.1320\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 3s/step - accuracy: 0.3225 - loss: 1.1745 - val_accuracy: 0.3333 - val_loss: 1.0960\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 3s/step - accuracy: 0.3605 - loss: 1.1123 - val_accuracy: 0.3086 - val_loss: 1.1511\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 3s/step - accuracy: 0.3755 - loss: 1.1085 - val_accuracy: 0.4321 - val_loss: 1.1160\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 3s/step - accuracy: 0.3686 - loss: 1.1624 - val_accuracy: 0.3827 - val_loss: 1.1181\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 3s/step - accuracy: 0.4188 - loss: 1.0849 - val_accuracy: 0.4444 - val_loss: 1.0503\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 3s/step - accuracy: 0.4256 - loss: 1.0854 - val_accuracy: 0.3457 - val_loss: 1.0729\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 3s/step - accuracy: 0.3636 - loss: 1.0931 - val_accuracy: 0.3333 - val_loss: 1.0974\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 3s/step - accuracy: 0.3926 - loss: 1.0622 - val_accuracy: 0.4691 - val_loss: 1.0506\n",
      "Fold 3 Accuracy: 46.91%\n",
      "Fold 3 Loss: 1.0506\n",
      "\n",
      "Fold 4\n",
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 3s/step - accuracy: 0.2956 - loss: 1.4145 - val_accuracy: 0.3827 - val_loss: 1.1354\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 3s/step - accuracy: 0.3265 - loss: 1.1831 - val_accuracy: 0.4568 - val_loss: 1.1060\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3s/step - accuracy: 0.3516 - loss: 1.1871 - val_accuracy: 0.4074 - val_loss: 1.0683\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3s/step - accuracy: 0.3855 - loss: 1.1411 - val_accuracy: 0.3827 - val_loss: 1.0454\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3s/step - accuracy: 0.3841 - loss: 1.1275 - val_accuracy: 0.4074 - val_loss: 1.0632\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3s/step - accuracy: 0.3787 - loss: 1.1083 - val_accuracy: 0.3827 - val_loss: 1.0492\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3s/step - accuracy: 0.3356 - loss: 1.1471 - val_accuracy: 0.3827 - val_loss: 1.0804\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3s/step - accuracy: 0.3610 - loss: 1.1645 - val_accuracy: 0.4321 - val_loss: 1.0494\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3s/step - accuracy: 0.3476 - loss: 1.1124 - val_accuracy: 0.3827 - val_loss: 1.0241\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 3s/step - accuracy: 0.3735 - loss: 1.0906 - val_accuracy: 0.4691 - val_loss: 1.0304\n",
      "Fold 4 Accuracy: 46.91%\n",
      "Fold 4 Loss: 1.0304\n",
      "\n",
      "Fold 5\n",
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 3s/step - accuracy: 0.3501 - loss: 1.3441 - val_accuracy: 0.3333 - val_loss: 1.1107\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3s/step - accuracy: 0.3802 - loss: 1.1649 - val_accuracy: 0.3457 - val_loss: 1.1334\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3s/step - accuracy: 0.3343 - loss: 1.1982 - val_accuracy: 0.3951 - val_loss: 1.0852\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3s/step - accuracy: 0.3760 - loss: 1.1329 - val_accuracy: 0.3704 - val_loss: 1.0721\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3s/step - accuracy: 0.4256 - loss: 1.0935 - val_accuracy: 0.3333 - val_loss: 1.0622\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3s/step - accuracy: 0.3698 - loss: 1.0921 - val_accuracy: 0.3704 - val_loss: 1.0850\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3s/step - accuracy: 0.3706 - loss: 1.1005 - val_accuracy: 0.3457 - val_loss: 1.1367\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3s/step - accuracy: 0.4168 - loss: 1.0718 - val_accuracy: 0.4568 - val_loss: 1.0530\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3s/step - accuracy: 0.3702 - loss: 1.1038 - val_accuracy: 0.4198 - val_loss: 1.0632\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 3s/step - accuracy: 0.4033 - loss: 1.0861 - val_accuracy: 0.3333 - val_loss: 1.0830\n",
      "Fold 5 Accuracy: 33.33%\n",
      "Fold 5 Loss: 1.0830\n",
      "Mean Accuracy: 41.38%, Mean Loss: 1.0573\n",
      "\n",
      "Testing batch_size=32, dropout=0.5, lr=0.0005\n",
      "\n",
      "Fold 1\n",
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 3s/step - accuracy: 0.3151 - loss: 1.2971 - val_accuracy: 0.3171 - val_loss: 1.1127\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3s/step - accuracy: 0.3341 - loss: 1.2497 - val_accuracy: 0.4390 - val_loss: 1.0675\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3s/step - accuracy: 0.4083 - loss: 1.1342 - val_accuracy: 0.4634 - val_loss: 1.0609\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3s/step - accuracy: 0.3892 - loss: 1.1282 - val_accuracy: 0.3415 - val_loss: 1.0906\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 3s/step - accuracy: 0.3400 - loss: 1.1423 - val_accuracy: 0.4634 - val_loss: 1.0364\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3s/step - accuracy: 0.3526 - loss: 1.1481 - val_accuracy: 0.3415 - val_loss: 1.1011\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 3s/step - accuracy: 0.3889 - loss: 1.1005 - val_accuracy: 0.4756 - val_loss: 1.0432\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 3s/step - accuracy: 0.3908 - loss: 1.1089 - val_accuracy: 0.3537 - val_loss: 1.0921\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 3s/step - accuracy: 0.3707 - loss: 1.1056 - val_accuracy: 0.4878 - val_loss: 1.0388\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 3s/step - accuracy: 0.3779 - loss: 1.0823 - val_accuracy: 0.4268 - val_loss: 1.0512\n",
      "Fold 1 Accuracy: 42.68%\n",
      "Fold 1 Loss: 1.0512\n",
      "\n",
      "Fold 2\n",
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 3s/step - accuracy: 0.3648 - loss: 1.3200 - val_accuracy: 0.3333 - val_loss: 1.1271\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3s/step - accuracy: 0.3395 - loss: 1.2826 - val_accuracy: 0.3827 - val_loss: 1.1037\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3s/step - accuracy: 0.4423 - loss: 1.0741 - val_accuracy: 0.3580 - val_loss: 1.1097\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3s/step - accuracy: 0.3673 - loss: 1.1885 - val_accuracy: 0.3333 - val_loss: 1.0855\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3s/step - accuracy: 0.3681 - loss: 1.1379 - val_accuracy: 0.3704 - val_loss: 1.0989\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3s/step - accuracy: 0.3757 - loss: 1.1468 - val_accuracy: 0.3951 - val_loss: 1.0796\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3s/step - accuracy: 0.3858 - loss: 1.1399 - val_accuracy: 0.3951 - val_loss: 1.0781\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3s/step - accuracy: 0.4128 - loss: 1.0762 - val_accuracy: 0.3951 - val_loss: 1.0726\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3s/step - accuracy: 0.3366 - loss: 1.1201 - val_accuracy: 0.3951 - val_loss: 1.0823\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 3s/step - accuracy: 0.4295 - loss: 1.0577 - val_accuracy: 0.4321 - val_loss: 1.0685\n",
      "Fold 2 Accuracy: 43.21%\n",
      "Fold 2 Loss: 1.0685\n",
      "\n",
      "Fold 3\n",
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 3s/step - accuracy: 0.3937 - loss: 1.2187 - val_accuracy: 0.3333 - val_loss: 1.1372\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3s/step - accuracy: 0.3677 - loss: 1.2217 - val_accuracy: 0.3333 - val_loss: 1.0825\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 3s/step - accuracy: 0.3816 - loss: 1.1760 - val_accuracy: 0.4321 - val_loss: 1.0659\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 3s/step - accuracy: 0.4266 - loss: 1.0975 - val_accuracy: 0.3333 - val_loss: 1.1341\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 3s/step - accuracy: 0.3153 - loss: 1.1457 - val_accuracy: 0.4938 - val_loss: 1.0632\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3s/step - accuracy: 0.4116 - loss: 1.0845 - val_accuracy: 0.3333 - val_loss: 1.0913\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3s/step - accuracy: 0.3481 - loss: 1.1259 - val_accuracy: 0.3333 - val_loss: 1.0860\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3s/step - accuracy: 0.3502 - loss: 1.1184 - val_accuracy: 0.4568 - val_loss: 1.0542\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3s/step - accuracy: 0.3654 - loss: 1.1330 - val_accuracy: 0.3704 - val_loss: 1.0849\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3s/step - accuracy: 0.4579 - loss: 1.0626 - val_accuracy: 0.4691 - val_loss: 1.0520\n",
      "Fold 3 Accuracy: 46.91%\n",
      "Fold 3 Loss: 1.0520\n",
      "\n",
      "Fold 4\n",
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 3s/step - accuracy: 0.3709 - loss: 1.2825 - val_accuracy: 0.4444 - val_loss: 1.0878\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 3s/step - accuracy: 0.3626 - loss: 1.1506 - val_accuracy: 0.3827 - val_loss: 1.0944\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3s/step - accuracy: 0.3306 - loss: 1.2371 - val_accuracy: 0.3827 - val_loss: 1.0675\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3s/step - accuracy: 0.3611 - loss: 1.1871 - val_accuracy: 0.4444 - val_loss: 1.0506\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 3s/step - accuracy: 0.4286 - loss: 1.1291 - val_accuracy: 0.3827 - val_loss: 1.0564\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3s/step - accuracy: 0.3392 - loss: 1.1573 - val_accuracy: 0.4691 - val_loss: 1.0631\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3s/step - accuracy: 0.3555 - loss: 1.1625 - val_accuracy: 0.4444 - val_loss: 1.0400\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3s/step - accuracy: 0.3871 - loss: 1.0915 - val_accuracy: 0.4568 - val_loss: 1.0354\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3s/step - accuracy: 0.3396 - loss: 1.1338 - val_accuracy: 0.3827 - val_loss: 1.0357\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3s/step - accuracy: 0.3584 - loss: 1.0981 - val_accuracy: 0.5309 - val_loss: 1.0359\n",
      "Fold 4 Accuracy: 53.09%\n",
      "Fold 4 Loss: 1.0359\n",
      "\n",
      "Fold 5\n",
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 4s/step - accuracy: 0.3395 - loss: 1.3268 - val_accuracy: 0.3704 - val_loss: 1.3071\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3s/step - accuracy: 0.3247 - loss: 1.2455 - val_accuracy: 0.3333 - val_loss: 1.1175\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3s/step - accuracy: 0.3835 - loss: 1.1272 - val_accuracy: 0.4198 - val_loss: 1.1008\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3s/step - accuracy: 0.3617 - loss: 1.1928 - val_accuracy: 0.3951 - val_loss: 1.0772\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3s/step - accuracy: 0.2946 - loss: 1.2192 - val_accuracy: 0.3333 - val_loss: 1.1370\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3s/step - accuracy: 0.3334 - loss: 1.1903 - val_accuracy: 0.3827 - val_loss: 1.0763\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3s/step - accuracy: 0.3114 - loss: 1.1375 - val_accuracy: 0.3704 - val_loss: 1.0910\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3s/step - accuracy: 0.3582 - loss: 1.1205 - val_accuracy: 0.4198 - val_loss: 1.0755\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 3s/step - accuracy: 0.3631 - loss: 1.0934 - val_accuracy: 0.3333 - val_loss: 1.0802\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3s/step - accuracy: 0.4097 - loss: 1.0802 - val_accuracy: 0.4198 - val_loss: 1.0841\n",
      "Fold 5 Accuracy: 41.98%\n",
      "Fold 5 Loss: 1.0841\n",
      "Mean Accuracy: 45.57%, Mean Loss: 1.0583\n",
      "\n",
      "Testing batch_size=32, dropout=0.5, lr=0.001\n",
      "\n",
      "Fold 1\n",
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 4s/step - accuracy: 0.3436 - loss: 1.5493 - val_accuracy: 0.2439 - val_loss: 1.2609\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 3s/step - accuracy: 0.2673 - loss: 1.3671 - val_accuracy: 0.4634 - val_loss: 1.0655\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 3s/step - accuracy: 0.2873 - loss: 1.2628 - val_accuracy: 0.4390 - val_loss: 1.0560\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3s/step - accuracy: 0.3985 - loss: 1.1167 - val_accuracy: 0.4390 - val_loss: 1.0745\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 3s/step - accuracy: 0.4378 - loss: 1.0833 - val_accuracy: 0.3537 - val_loss: 1.0990\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3s/step - accuracy: 0.3399 - loss: 1.1669 - val_accuracy: 0.4634 - val_loss: 1.0310\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3s/step - accuracy: 0.3629 - loss: 1.1103 - val_accuracy: 0.3902 - val_loss: 1.0711\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 3s/step - accuracy: 0.3841 - loss: 1.1118 - val_accuracy: 0.4024 - val_loss: 1.0951\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3s/step - accuracy: 0.3876 - loss: 1.1185 - val_accuracy: 0.4268 - val_loss: 1.0342\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3s/step - accuracy: 0.4092 - loss: 1.0917 - val_accuracy: 0.4268 - val_loss: 1.0815\n",
      "Fold 1 Accuracy: 42.68%\n",
      "Fold 1 Loss: 1.0815\n",
      "\n",
      "Fold 2\n",
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 4s/step - accuracy: 0.3367 - loss: 1.4795 - val_accuracy: 0.3210 - val_loss: 1.1453\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3s/step - accuracy: 0.3380 - loss: 1.2678 - val_accuracy: 0.3827 - val_loss: 1.1447\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3s/step - accuracy: 0.3729 - loss: 1.2498 - val_accuracy: 0.3086 - val_loss: 1.1081\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3s/step - accuracy: 0.2789 - loss: 1.2146 - val_accuracy: 0.3951 - val_loss: 1.0802\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3s/step - accuracy: 0.3698 - loss: 1.0966 - val_accuracy: 0.3333 - val_loss: 1.1032\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3s/step - accuracy: 0.3511 - loss: 1.1291 - val_accuracy: 0.3827 - val_loss: 1.1412\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3s/step - accuracy: 0.3954 - loss: 1.0995 - val_accuracy: 0.3704 - val_loss: 1.0972\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3s/step - accuracy: 0.4264 - loss: 1.1054 - val_accuracy: 0.3827 - val_loss: 1.0782\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3s/step - accuracy: 0.4335 - loss: 1.0800 - val_accuracy: 0.3827 - val_loss: 1.0776\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3s/step - accuracy: 0.3904 - loss: 1.1081 - val_accuracy: 0.3333 - val_loss: 1.1216\n",
      "Fold 2 Accuracy: 33.33%\n",
      "Fold 2 Loss: 1.1216\n",
      "\n",
      "Fold 3\n",
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 4s/step - accuracy: 0.3422 - loss: 1.3057 - val_accuracy: 0.4568 - val_loss: 1.1421\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3s/step - accuracy: 0.3516 - loss: 1.2585 - val_accuracy: 0.4568 - val_loss: 1.0753\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3s/step - accuracy: 0.3824 - loss: 1.1537 - val_accuracy: 0.3086 - val_loss: 1.1637\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 3s/step - accuracy: 0.3611 - loss: 1.1166 - val_accuracy: 0.3951 - val_loss: 1.0699\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3s/step - accuracy: 0.4291 - loss: 1.0744 - val_accuracy: 0.4815 - val_loss: 1.0612\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3s/step - accuracy: 0.4172 - loss: 1.0949 - val_accuracy: 0.4568 - val_loss: 1.0638\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3s/step - accuracy: 0.3958 - loss: 1.0763 - val_accuracy: 0.4815 - val_loss: 1.0572\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 3s/step - accuracy: 0.3755 - loss: 1.1086 - val_accuracy: 0.3333 - val_loss: 1.1180\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3s/step - accuracy: 0.3999 - loss: 1.1096 - val_accuracy: 0.4074 - val_loss: 1.0708\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3s/step - accuracy: 0.4066 - loss: 1.0838 - val_accuracy: 0.3333 - val_loss: 1.0695\n",
      "Fold 3 Accuracy: 33.33%\n",
      "Fold 3 Loss: 1.0695\n",
      "\n",
      "Fold 4\n",
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 5s/step - accuracy: 0.3704 - loss: 1.2968 - val_accuracy: 0.3827 - val_loss: 1.1702\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 3s/step - accuracy: 0.3488 - loss: 1.2382 - val_accuracy: 0.3704 - val_loss: 1.0698\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 3s/step - accuracy: 0.4060 - loss: 1.1595 - val_accuracy: 0.3457 - val_loss: 1.1569\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 3s/step - accuracy: 0.3548 - loss: 1.1947 - val_accuracy: 0.3704 - val_loss: 1.0606\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 3s/step - accuracy: 0.4098 - loss: 1.1238 - val_accuracy: 0.3827 - val_loss: 1.0818\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 3s/step - accuracy: 0.3758 - loss: 1.1761 - val_accuracy: 0.4074 - val_loss: 1.0590\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 3s/step - accuracy: 0.3431 - loss: 1.1267 - val_accuracy: 0.3827 - val_loss: 1.0616\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 3s/step - accuracy: 0.4188 - loss: 1.1087 - val_accuracy: 0.5062 - val_loss: 1.0420\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 3s/step - accuracy: 0.3619 - loss: 1.1090 - val_accuracy: 0.3827 - val_loss: 1.0522\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 3s/step - accuracy: 0.3799 - loss: 1.0990 - val_accuracy: 0.4568 - val_loss: 1.0462\n",
      "Fold 4 Accuracy: 45.68%\n",
      "Fold 4 Loss: 1.0462\n",
      "\n",
      "Fold 5\n",
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 4s/step - accuracy: 0.3124 - loss: 1.4048 - val_accuracy: 0.3333 - val_loss: 1.1057\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 3s/step - accuracy: 0.3735 - loss: 1.1849 - val_accuracy: 0.3580 - val_loss: 1.0952\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 3s/step - accuracy: 0.3646 - loss: 1.1160 - val_accuracy: 0.3704 - val_loss: 1.1154\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 3s/step - accuracy: 0.3939 - loss: 1.1434 - val_accuracy: 0.3951 - val_loss: 1.0713\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3s/step - accuracy: 0.4396 - loss: 1.0667 - val_accuracy: 0.3333 - val_loss: 1.0834\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 3s/step - accuracy: 0.3621 - loss: 1.1378 - val_accuracy: 0.3704 - val_loss: 1.1085\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 3s/step - accuracy: 0.3439 - loss: 1.1567 - val_accuracy: 0.3333 - val_loss: 1.1120\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 3s/step - accuracy: 0.4228 - loss: 1.0851 - val_accuracy: 0.4074 - val_loss: 1.0687\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 3s/step - accuracy: 0.3991 - loss: 1.0685 - val_accuracy: 0.3333 - val_loss: 1.0949\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 3s/step - accuracy: 0.4333 - loss: 1.0775 - val_accuracy: 0.4074 - val_loss: 1.0798\n",
      "Fold 5 Accuracy: 40.74%\n",
      "Fold 5 Loss: 1.0798\n",
      "Mean Accuracy: 39.15%, Mean Loss: 1.0797\n",
      "\n",
      "Best Parameters:\n",
      "{'batch_size': 32, 'dropout': 0.5, 'learning_rate': 0.0005, 'accuracy': 0.4557362198829651}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.applications import ResNet101\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import itertools\n",
    "\n",
    "# ---- Load and Preprocess Data ----\n",
    "train_dir = 'D:/Lung_cancer/train'  # Training directory path\n",
    "target_size = (224, 224)  # Input size for ResNet101\n",
    "num_classes = 3\n",
    "\n",
    "# Extract file paths and labels\n",
    "train_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=target_size,\n",
    "    batch_size=32,  # Temporary batch size\n",
    "    class_mode='categorical',\n",
    "    shuffle=False  # To keep track of indices\n",
    ")\n",
    "X = np.array(train_generator.filepaths)  # File paths of images\n",
    "y = np.array(train_generator.classes)    # Corresponding class labels\n",
    "\n",
    "# ---- Hyperparameter Search Space ----\n",
    "batch_sizes = [16, 32]\n",
    "dropout_rates = [0.3, 0.5]\n",
    "learning_rates = [0.0005, 0.001]\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "best_params = {}\n",
    "best_accuracy = 0\n",
    "\n",
    "# Iterate over all combinations of hyperparameters\n",
    "for batch_size, dropout_rate, learning_rate in itertools.product(batch_sizes, dropout_rates, learning_rates):\n",
    "    print(f\"Testing batch_size={batch_size}, dropout={dropout_rate}, lr={learning_rate}\")\n",
    "    \n",
    "    fold_accuracies = []\n",
    "    fold_losses = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
    "        print(f\"\\nFold {fold + 1}\")\n",
    "        \n",
    "        # Split into training and validation sets\n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "        \n",
    "        # Load data dynamically\n",
    "        def load_data(file_paths, labels):\n",
    "            images = []\n",
    "            for file in file_paths:\n",
    "                img = load_img(file, target_size=target_size)\n",
    "                img = img_to_array(img)\n",
    "                images.append(img)\n",
    "            images = np.array(images) / 255.0\n",
    "            labels = np.eye(num_classes)[labels]\n",
    "            return images, labels\n",
    "        \n",
    "        X_train_images, y_train_labels = load_data(X_train, y_train)\n",
    "        X_val_images, y_val_labels = load_data(X_val, y_val)\n",
    "        \n",
    "        # ---- Define and Compile Model ----\n",
    "        base_model = ResNet101(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "        base_model.trainable = False\n",
    "        \n",
    "        x = base_model.output\n",
    "        x = layers.GlobalAveragePooling2D()(x)\n",
    "        x = layers.Dense(512, activation='relu')(x)\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "        output = layers.Dense(num_classes, activation='softmax')(x)\n",
    "        model = models.Model(inputs=base_model.input, outputs=output)\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer=Adam(learning_rate=learning_rate),\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "        # ---- Train Model ----\n",
    "        history = model.fit(\n",
    "            X_train_images, y_train_labels,\n",
    "            validation_data=(X_val_images, y_val_labels),\n",
    "            epochs=10,  # Default to 10 epochs\n",
    "            batch_size=batch_size,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # ---- Evaluate Model ----\n",
    "        val_loss, val_accuracy = model.evaluate(X_val_images, y_val_labels, verbose=0)\n",
    "        print(f\"Fold {fold + 1} Accuracy: {val_accuracy * 100:.2f}%\")\n",
    "        print(f\"Fold {fold + 1} Loss: {val_loss:.4f}\")\n",
    "        \n",
    "        fold_accuracies.append(val_accuracy)\n",
    "        fold_losses.append(val_loss)\n",
    "    \n",
    "    # Compute mean accuracy for the current hyperparameter combination\n",
    "    mean_accuracy = np.mean(fold_accuracies)\n",
    "    mean_loss = np.mean(fold_losses)\n",
    "    \n",
    "    print(f\"Mean Accuracy: {mean_accuracy * 100:.2f}%, Mean Loss: {mean_loss:.4f}\\n\")\n",
    "    \n",
    "    # Store best hyperparameters\n",
    "    if mean_accuracy > best_accuracy:\n",
    "        best_accuracy = mean_accuracy\n",
    "        best_params = {\n",
    "            \"batch_size\": batch_size,\n",
    "            \"dropout\": dropout_rate,\n",
    "            \"learning_rate\": learning_rate,\n",
    "            \"accuracy\": best_accuracy\n",
    "        }\n",
    "\n",
    "# ---- Final Best Parameters ----\n",
    "print(\"Best Parameters:\")\n",
    "print(best_params)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
